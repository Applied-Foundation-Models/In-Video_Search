{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T07:49:19.923950Z",
     "start_time": "2024-06-10T07:49:06.096049Z"
    }
   },
   "source": [
    "import os\n",
    "from src.video_preprocessing.download_videos.youtube_download import preprocess_video\n",
    "from src.video_preprocessing.scene_detection.scene_detect import detect_scenes\n",
    "from src.video_preprocessing.scene_detection.ocr import extract_text_from_slide\n",
    "from src.video_preprocessing.download_videos.download_utils import (\n",
    "    transcribe_audio_files,\n",
    "    extract_and_store_audio,\n",
    "    transcription_to_text,\n",
    ")\n",
    "from src.ocr.pytesseract_image_to_text import extract_text_from_image\n",
    "from src.llm.ollama_implementation.ollama_experiment import (\n",
    "    prompt_llm_summary,\n",
    "    generate_caption_using_llava,\n",
    ")\n",
    "from transformers import CLIPProcessor, CLIPModel, CLIPTokenizer\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "from loguru import logger"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-06-10 09:49:18.352\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.ocr.pytesseract_image_to_text\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m17\u001B[0m - \u001B[1mExtracted text: Lecture overview\n",
      "\n",
      "1 R programming basics\n",
      "\n",
      "1. Get 2 Data wrangling\n",
      "3 Tidy data\n",
      "2. Look 4 Low dimensional visualization\n",
      "5 High dimensi i\n",
      "3. Conclude 7 Empirical Statistical Assessment\n",
      "\n",
      "8 Analytical Statistical Assessment\n",
      "9 Statistical Assessment for Big Data\n",
      "Case Study\n",
      "10 Linear regression\n",
      "11 Classification\n",
      "12 Supervised Learning\n",
      "\n",
      "Julien Gagneur Graphically supported hypotheses 3/70\n",
      "\n",
      "\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Pipeline\n",
    "Download a video from a specific URL on YouTube, then run:\n",
    "- Scene detection\n",
    "- Keyframe detection\n",
    "\n",
    "The resulting data will be stored under `/data/raw/<NAME>`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T07:49:30.286125Z",
     "start_time": "2024-06-10T07:49:30.254720Z"
    }
   },
   "source": [
    "# Define options and input for downloading a video from youtube\n",
    "\n",
    "# INSERT video name here\n",
    "name = \"biology_chapter_3_3\"\n",
    "# INSERT video URL here\n",
    "url = \"https://youtu.be/DZSEErNZ1d4?si=f6YxKQ9rP6iqgTfk\"\n",
    "# INSERT chunk length in seconds 30s --> 30, no splitting: None\n",
    "chunks = None\n",
    "\n",
    "opts_aud = {\"format\": \"mp3/bestaudio/best\", \"keep-video\": True}\n",
    "opts_vid = {\"format\": \"mp4/bestvideo/best\"}"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T07:49:34.239663Z",
     "start_time": "2024-06-10T07:49:31.063729Z"
    }
   },
   "source": [
    "# Downloads the video creates the relevant datafolders and transcribes the video\n",
    "data_path = preprocess_video(\n",
    "    download=True,\n",
    "    uploaded_vid=\"ignore\",  # path to local file\n",
    "    url=url,\n",
    "    name=name,\n",
    "    aud_opts=opts_aud,\n",
    "    vid_opts=opts_vid,  # Video download settings\n",
    "    audio_file=name + \".mp3\",\n",
    "    input_file=name + \".mp4\",\n",
    "    output=\"output.mp4\",\n",
    "    split_length=chunks,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-06-10 09:49:31.063\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.video_preprocessing.download_videos.youtube_download\u001B[0m:\u001B[36mpreprocess_video\u001B[0m:\u001B[36m49\u001B[0m - \u001B[1mStarting AutoCaptioning...\u001B[0m\n",
      "\u001B[32m2024-06-10 09:49:31.063\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.video_preprocessing.download_videos.youtube_download\u001B[0m:\u001B[36mpreprocess_video\u001B[0m:\u001B[36m50\u001B[0m - \u001B[1mResults will be stored in data/raw/biology_chapter_3_3\u001B[0m\n",
      "\u001B[32m2024-06-10 09:49:31.063\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.video_preprocessing.download_videos.youtube_download\u001B[0m:\u001B[36mpreprocess_video\u001B[0m:\u001B[36m58\u001B[0m - \u001B[1mCreated chunks folders\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://youtu.be/DZSEErNZ1d4?si=f6YxKQ9rP6iqgTfk\n",
      "[youtube] DZSEErNZ1d4: Downloading webpage\n",
      "[youtube] DZSEErNZ1d4: Downloading ios player API JSON\n",
      "[youtube] DZSEErNZ1d4: Downloading m3u8 information\n",
      "[info] DZSEErNZ1d4: Downloading 1 format(s): 22\n",
      "[download] C:\\Users\\baatout\\PycharmProjects\\afm-vlm\\data\\raw\\biology_chapter_3_3\\biology_chapter_3_3.mp4 has already been downloaded\n",
      "[download] 100% of  126.17MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-06-10 09:49:34.224\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.video_preprocessing.download_videos.youtube_download\u001B[0m:\u001B[36mpreprocess_video\u001B[0m:\u001B[36m91\u001B[0m - \u001B[1mVideo is not splitted:\u001B[0m\n",
      "\u001B[32m2024-06-10 09:49:34.224\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.video_preprocessing.download_videos.youtube_download\u001B[0m:\u001B[36mpreprocess_video\u001B[0m:\u001B[36m95\u001B[0m - \u001B[1mVideo downloaded successfully!\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-10T07:49:42.314242Z"
    }
   },
   "source": [
    "# Â Now that we have downloaded the video we want to perform scene_Detection:\n",
    "detect_scenes(data_path)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-06-10 09:49:42.322\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.video_preprocessing.scene_detection.scene_detect\u001B[0m:\u001B[36mdetect_scenes\u001B[0m:\u001B[36m29\u001B[0m - \u001B[1mFound file\u001B[0m\n",
      "\u001B[32m2024-06-10 09:49:42.322\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.video_preprocessing.scene_detection.scene_detect\u001B[0m:\u001B[36mdetect_scenes\u001B[0m:\u001B[36m33\u001B[0m - \u001B[1mName:biology_chapter_3_3.mp4,dirname:C:\\Users\\baatout\\PycharmProjects\\afm-vlm\\data/raw\\biology_chapter_3_3\\biology_chapter_3_3.mp4\u001B[0m\n",
      "\u001B[32m2024-06-10 09:49:42.322\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.video_preprocessing.scene_detection.scene_detect\u001B[0m:\u001B[36mdetect_scenes\u001B[0m:\u001B[36m35\u001B[0m - \u001B[1mRunning scene_detection:\u001B[0m\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the audio per detected scene\n",
    "extract_and_store_audio(\n",
    "    os.path.join(data_path, \"scene_snippets\"),\n",
    "    os.path.join(data_path, \"audio_chunks\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Transcription using Whisper\n",
    "\n",
    "For Faster Inference Please Use Tiny!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe the different snippets snippets:\n",
    "audio_dir = os.path.join(data_path, \"audio_chunks\")\n",
    "transcriptions_dir = os.path.join(data_path, \"transcriptions\")\n",
    "\n",
    "model_type = \"tiny\"  # change to 'large' if you want more accurate results,\n",
    "# change to 'medium.en' or 'large.en' for all english language tasks,\n",
    "# and change to 'small' or 'base' for faster inference\n",
    "lang = \"en\"\n",
    "\n",
    "# Run whisper on all .wav files in audio_dir\n",
    "transcribe_audio_files(audio_dir, transcriptions_dir, model_type=model_type, lang=lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting the Analysis of the Information Contained in the Video\n",
    "\n",
    "### Inputs\n",
    "\n",
    "* **Transcriptions**: [insert description or link to transcription]\n",
    "* **Extraction from Slides using OCR**: [insert description or link to extracted content]\n",
    "* **Textual Interpretation of Visual Information using LLAVA**: [insert description or link to \n",
    "interpreted information]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-06-07 19:28:50.613\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m27\u001B[0m - \u001B[1mElapsed Time: 42.34112215042114 seconds\u001B[0m\n",
      "\u001B[32m2024-06-07 19:28:50.617\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m31\u001B[0m - \u001B[1mLLM_Summary: Here is a summary of the lecture content:\n",
      "\n",
      "**Slide Summary:**\n",
      "The slide discusses micronutrients, specifically vitamins, which are organic substances that help speed up chemical reactions in the body. Most vitamins cannot be synthesized by the body and must be obtained from food. Vitamin D is an exception, as it can be synthesized with sunlight. The slide highlights the importance of micronutrients for maintaining bodily functions.\n",
      "\n",
      "**Key Topics:**\n",
      "Vitamins, micronutrients, organic substances, coenzymes, vitamin deficiencies, cancer prevention, heart disease prevention, aging process, sunlight, vitamin D synthesis, supplementation.\n",
      "\n",
      "**Queryable Information:**\n",
      "Tags: Vitamins, Micronutrients, Organic Substances, Coenzymes, Vitamin Deficiencies, Cancer Prevention, Heart Disease Prevention, Aging Process, Sunlight, Vitamin D Synthesis, Supplementation.\n",
      "Categories: Nutrition, Health, Biology\n",
      "Specific Concepts: Vitamin Functionality, Chemical Reactions, Body Functions, Nutrient Deficiencies.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summary of the lecture content:\n",
      "\n",
      "**Slide Summary:**\n",
      "The slide discusses micronutrients, specifically vitamins, which are organic substances that help speed up chemical reactions in the body. Most vitamins cannot be synthesized by the body and must be obtained from food. Vitamin D is an exception, as it can be synthesized with sunlight. The slide highlights the importance of micronutrients for maintaining bodily functions.\n",
      "\n",
      "**Key Topics:**\n",
      "Vitamins, micronutrients, organic substances, coenzymes, vitamin deficiencies, cancer prevention, heart disease prevention, aging process, sunlight, vitamin D synthesis, supplementation.\n",
      "\n",
      "**Queryable Information:**\n",
      "Tags: Vitamins, Micronutrients, Organic Substances, Coenzymes, Vitamin Deficiencies, Cancer Prevention, Heart Disease Prevention, Aging Process, Sunlight, Vitamin D Synthesis, Supplementation.\n",
      "Categories: Nutrition, Health, Biology\n",
      "Specific Concepts: Vitamin Functionality, Chemical Reactions, Body Functions, Nutrient Deficiencies.\n"
     ]
    }
   ],
   "source": [
    "transcription_file_path = \"/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/biology_chapter_3_3/transcriptions/biology_chapter_3_3-Scene-055.csv\"\n",
    "image_path = \"/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/biology_chapter_3_3/extracted_keyframes/biology_chapter_3_3-Scene-055-01.jpg\"\n",
    "\n",
    "start_time = time.time()\n",
    "# Transform transcription file\n",
    "transcription = transcription_to_text(transcription_file_path)\n",
    "logger.info(f\"Transcription_text: {transcription}\")\n",
    "\n",
    "# Extract text using OCR:\n",
    "ocr_extracted_text = extract_text_from_image(image_path)\n",
    "logger.info(f\"OCR_results: {ocr_extracted_text}\")\n",
    "\n",
    "# Extract textual understanding of Visual features using LLAVA:\n",
    "\n",
    "llava_results = generate_caption_using_llava(image_path)\n",
    "logger.info(f\"LLava_results: {llava_results}\")\n",
    "\n",
    "response = prompt_llm_summary(\n",
    "    slide_content=ocr_extracted_text,\n",
    "    transcription=transcription,\n",
    "    llava_output=llava_results,\n",
    ")\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "# Print the elapsed time\n",
    "logger.info(f\"Elapsed Time: {elapsed_time} seconds\")\n",
    "\n",
    "# print the resposne of the Slide:\n",
    "logger.info(f\"LLM_Summary: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (196 > 77). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "def get_model_info(model_ID, device):\n",
    "    # Save the model to device\n",
    "    model = CLIPModel.from_pretrained(model_ID).to(device)\n",
    "    # Get the processor\n",
    "    processor = CLIPProcessor.from_pretrained(model_ID)\n",
    "    # Get the tokenizer\n",
    "    tokenizer = CLIPTokenizer.from_pretrained(model_ID)\n",
    "    # Return model, processor & tokenizer\n",
    "    return model, processor, tokenizer\n",
    "\n",
    "\n",
    "# Set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Define the model ID\n",
    "model_ID = \"openai/clip-vit-base-patch32\"\n",
    "# Get model, processor & tokenizer\n",
    "model, processor, tokenizer = get_model_info(model_ID, device)\n",
    "\n",
    "\n",
    "def get_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    # Convert the image to RGB\n",
    "    rgb_image = image.convert(\"RGB\")\n",
    "    return rgb_image\n",
    "\n",
    "\n",
    "def get_single_image_embedding(text, my_image, processor, model, device):\n",
    "    image = processor(text=text, images=my_image, return_tensors=\"pt\")[\n",
    "        \"pixel_values\"\n",
    "    ].to(device)\n",
    "    embedding = model.get_image_features(image)\n",
    "    # convert the embeddings to numpy array\n",
    "    return embedding.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "one_image = get_image(\n",
    "    image_path=\"/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/biology_chapter_3_3/extracted_keyframes/biology_chapter_3_3-Scene-055-01.jpg\"\n",
    ")\n",
    "\n",
    "one_vector = get_single_image_embedding(\n",
    "    response, one_image, processor, model, device\n",
    ")  # Simple test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.92160636e-01  1.17445782e-01  2.37807691e-01  3.56596202e-01\n",
      "  -1.15230247e-01  3.00290510e-02  3.14957350e-02  1.24661297e-01\n",
      "   7.92421460e-01  2.04853714e-01 -1.33029491e-01  2.43656605e-01\n",
      "   1.50548339e-01 -6.20990276e-01 -6.07537255e-02  3.02564174e-01\n",
      "   2.77734697e-01  4.29132402e-01  1.79494053e-01  4.43889290e-01\n",
      "  -1.29297864e+00  4.07451212e-01 -1.65697247e-01  3.57256830e-03\n",
      "   4.37120080e-01 -7.21258521e-02  2.38586500e-01  2.18698323e-01\n",
      "  -3.34979206e-01  1.16147801e-01  7.78390914e-02 -5.59364915e-01\n",
      "   1.27671987e-01 -1.49906814e-01  4.41960812e-01 -1.45538524e-01\n",
      "  -2.98688948e-01 -1.57914698e-01  1.23107433e-03 -1.05231392e+00\n",
      "  -1.07995301e-01  4.40774336e-02 -5.25035799e-01 -1.05685741e-01\n",
      "  -6.65739998e-02 -2.97406018e-01  2.07281530e-01  1.82302266e-01\n",
      "  -6.35890126e-01 -8.69800568e-01  7.43384540e-01 -6.68020666e-01\n",
      "   3.35767508e-01 -4.33679044e-01  3.02345365e-01  2.06971914e-01\n",
      "  -3.19822848e-01 -4.21288460e-01  5.48620448e-02  2.46448308e-01\n",
      "   2.98584372e-01 -3.59180272e-01  3.93409699e-01 -4.65347171e-01\n",
      "  -4.23957646e-01 -3.01582068e-01  8.26559439e-02  7.96912909e-01\n",
      "  -5.03905833e-01 -3.32779914e-01  2.72060633e-02  6.87396228e-02\n",
      "  -9.70230103e-02 -2.06667840e-01  4.39703524e-01  3.42677534e-01\n",
      "  -4.58709240e-01  3.58215779e-01 -2.57097632e-01  3.33224833e-01\n",
      "   5.88856041e-01  2.67052352e-02 -1.69254065e-01  2.68383116e-01\n",
      "  -3.23051512e-02 -3.84140670e-01  1.10906470e+00  2.48409539e-01\n",
      "   3.66225481e-01  1.99516624e-01  5.22650719e-01  3.93178999e-01\n",
      "  -2.81969357e+00 -8.63915235e-02  6.45529509e-01  8.48414898e-02\n",
      "   4.96030182e-01 -4.70201552e-01 -4.61135775e-01  4.60577309e-01\n",
      "  -5.41659415e-01 -2.37067491e-01 -1.28529683e-01 -6.10124886e-01\n",
      "  -3.22068691e-01  1.75164714e-01 -3.79544377e-01  2.96771556e-01\n",
      "  -4.98102248e-01  6.57074302e-02  2.87449062e-01  5.70557356e-01\n",
      "  -5.23766518e-01  8.29563886e-02 -2.65081137e-01 -3.55589390e-02\n",
      "   1.67637110e-01 -3.62961382e-01 -2.64840961e-01 -2.51555145e-01\n",
      "  -2.97113597e-01  1.29864916e-01  1.35253966e-01  2.11882263e-01\n",
      "   1.92568988e-01  8.21668953e-02 -4.47224379e-02 -3.43992710e-02\n",
      "  -2.66251892e-01 -1.96205810e-01  1.49513438e-01  1.14710078e-01\n",
      "   2.86339968e-01  7.17326403e-01 -1.70201153e-01  3.51058602e-01\n",
      "  -1.56108618e-01 -3.42054129e-01 -1.76618531e-01  7.17724562e-02\n",
      "  -4.93317991e-02 -2.95149505e-01 -3.93312454e-01  2.59270817e-02\n",
      "  -5.72662652e-02  1.63796216e-01 -9.95594189e-02 -3.06928009e-02\n",
      "   2.37143114e-02 -1.75439194e-01 -4.40795898e-01  1.60908520e-01\n",
      "   6.84051275e-01  2.65076756e-01  4.16693628e-01  2.89577186e-01\n",
      "  -1.44682392e-01  3.29854578e-01 -4.25003082e-01  1.48830786e-02\n",
      "   4.57110345e-01 -1.00269914e-04  6.19176924e-01  8.45741928e-02\n",
      "  -2.60419309e-01  1.52184218e-01 -1.12902665e+00 -1.54364318e-01\n",
      "   1.65276751e-01  1.55179594e-02 -3.19763780e-01  5.39866276e-02\n",
      "   3.80704314e-01 -1.28532782e-01 -1.62033796e-01 -1.08547390e-01\n",
      "  -7.57501841e-01  1.96242556e-01  5.41416764e-01  2.69846737e-01\n",
      "  -2.67653465e-01 -6.47272915e-04 -6.53629720e-01 -1.09077454e-01\n",
      "  -1.39782757e-01  5.11579588e-03 -1.17293388e-01 -1.78971291e-02\n",
      "  -7.71606714e-03 -2.51235962e-01  2.13830471e-02  4.02764916e-01\n",
      "   6.38083518e-02 -2.29897529e-01  3.49084675e-01 -1.84223726e-01\n",
      "  -4.38064158e-01  4.18386981e-02  2.71259338e-01  1.59346998e-01\n",
      "   4.96992886e-01 -1.27922505e-01  9.86534357e-02 -1.40224636e-01\n",
      "   7.13455379e-02 -2.49573290e-01 -2.82270998e-01 -2.41767913e-02\n",
      "  -1.94239184e-01  4.49818134e-01 -5.13431467e-02  3.69017780e-01\n",
      "   1.16592497e-01 -2.23069340e-02  7.62222931e-02  6.65908933e-01\n",
      "   3.03290039e-02 -2.06151113e-01 -2.86521196e-01  3.80861647e-02\n",
      "   3.50217909e-01  6.77944273e-02  1.57939106e-01 -1.28944516e-01\n",
      "  -2.13742599e-01  2.01016217e-01  5.18358111e-01 -4.15198058e-01\n",
      "  -1.32655725e-02 -3.46251249e-01  7.92973489e-02 -2.90636510e-01\n",
      "  -2.66677663e-02 -4.06582117e-01 -8.28405619e-02  2.50523806e-01\n",
      "   1.96128100e-01  3.53280038e-01  7.98722506e-02 -1.83994770e-01\n",
      "   1.88745350e-01 -2.09272355e-01  5.10412455e-02 -3.07202756e-01\n",
      "  -2.32578933e-01  1.37596861e-01  2.37498865e-01  8.09753418e-01\n",
      "   2.43783563e-01 -6.99400008e-01  2.08518803e-01 -3.03250030e-02\n",
      "   1.88900530e-01 -3.94395858e-01  6.73937798e-01  2.54548490e-01\n",
      "  -5.06154537e-01 -1.22712508e-01  7.23991692e-02 -1.83709279e-01\n",
      "  -2.84220219e-01 -5.76158285e-01 -3.11532915e-02  3.96089494e-01\n",
      "   9.85442474e-02  3.61405402e-01  5.77191889e-01 -1.94334745e-01\n",
      "   1.33699164e-01  1.14875391e-01 -1.92766175e-01  1.44284323e-01\n",
      "  -5.73043406e-01  4.43769172e-02 -2.22233027e-01  1.43251419e-02\n",
      "  -5.76180220e-01  7.43952394e-02  3.62056643e-01  1.04978904e-01\n",
      "   5.94020247e-01  2.28908017e-01 -7.09255710e-02  1.72342837e-01\n",
      "  -2.91592091e-01 -2.99579293e-01 -1.79058588e+00 -3.02631557e-01\n",
      "   5.15254498e-01  9.54698026e-02 -2.50426769e-01 -1.34039819e-01\n",
      "   2.34625772e-01 -3.34208697e-01  2.97942847e-01  2.16137439e-01\n",
      "   2.86757529e-01 -1.74912572e-01  9.32729065e-01 -3.74956608e-01\n",
      "  -1.61670521e-03  3.33665788e-01 -2.49184072e-01  6.67101979e-01\n",
      "   3.25803608e-01  3.00488710e-01 -2.53174305e-01 -4.52215701e-01\n",
      "   8.89453650e-01  2.81780183e-01 -7.52531141e-02 -1.96838200e-01\n",
      "   7.17365265e-01  2.52106845e-01  3.19359094e-01  8.55678439e-01\n",
      "   1.31707311e-01  5.22867441e-02  4.18362647e-01  3.61394882e-03\n",
      "   3.48071009e-02  1.23575020e+00  3.79954755e-01 -1.38411745e-01\n",
      "   8.19000155e-02  2.02678487e-01 -3.84693205e-01 -4.55097109e-02\n",
      "   2.39301771e-01 -4.07181174e-01  1.47146761e-01 -2.32494980e-01\n",
      "   1.19759381e-01 -1.39435545e-01  3.36688191e-01 -2.68138826e-01\n",
      "   7.64960945e-02 -6.93338290e-02 -2.38184273e-01  9.26720351e-02\n",
      "  -6.64696038e-01 -2.85150737e-01  2.18758300e-01 -2.10952759e-02\n",
      "   3.11551452e-01 -2.15257809e-01 -4.90812957e-03  4.56875682e-01\n",
      "  -2.58386254e-01  6.31606638e-01  2.48044848e-01 -2.77103275e-01\n",
      "   2.26760611e-01 -5.36592722e-01 -1.51590049e-01  1.64791062e-01\n",
      "  -4.27758768e-02 -4.70855772e-01  2.66708434e-01  9.16901231e-03\n",
      "   3.81342053e-01 -3.09215486e-01 -5.50121069e-02 -6.77463233e-01\n",
      "  -1.60657093e-01  1.53256834e-01 -2.76760846e-01 -9.57863629e-01\n",
      "   1.13805078e-01  8.57274234e-02 -1.01895854e-01 -4.12763953e-01\n",
      "   6.47248685e-01  2.35225409e-01  3.69817838e-02  1.50605559e-01\n",
      "  -1.84924617e-01 -5.13774395e-01 -1.13879418e+00  5.59147485e-02\n",
      "  -2.44526565e-01 -3.24824274e-01 -5.02094865e-01 -2.26699188e-01\n",
      "   2.64596373e-01 -3.82743537e-01  8.75356644e-02 -3.48293215e-01\n",
      "   2.88142353e-01 -3.49171579e-01  2.37902820e-01 -2.41500437e-01\n",
      "   8.30120817e-02  4.57087547e-01  3.95545810e-02  1.07635558e-02\n",
      "  -3.03165019e-01  3.01514566e-01 -2.74476528e-01  2.93285251e-01\n",
      "   5.81863046e-01 -6.50727600e-02 -1.25595137e-01 -1.28729939e-02\n",
      "   5.09107262e-02  1.85320735e-01  1.43384486e-02 -4.41356063e-01\n",
      "   8.35996270e-01  3.09014976e-01 -1.77189469e-01  4.32992280e-01\n",
      "   5.63483000e-01  1.93139464e-01  2.58725107e-01  4.08713669e-01\n",
      "  -1.78142205e-01 -1.91377550e-02  2.15252340e-02 -3.55903059e-01\n",
      "  -2.02341437e-01  4.30890203e-01 -4.46438581e-01  1.86849982e-01\n",
      "  -2.65523493e-02 -9.02523398e-02 -1.16821527e-01 -3.33058804e-01\n",
      "  -1.89628470e+00 -1.04708090e-01 -7.80295208e-02  1.40642047e-01\n",
      "   4.80803967e-01 -4.80597436e-01  1.24497846e-01 -7.77373195e-01\n",
      "  -9.76108983e-02  2.73417622e-01  2.17768624e-01  7.70902783e-02\n",
      "   2.84357131e-01  2.75287271e-01  4.31421101e-01  2.72588015e-01\n",
      "   9.70786288e-02  3.07151288e-01  5.65078221e-02 -9.20171291e-03\n",
      "   4.14128780e-01  1.43834159e-01 -2.38001287e-01  7.31223300e-02\n",
      "  -1.79257542e-02 -8.97234529e-02  7.34990463e-02 -7.16036558e-02\n",
      "  -1.66332483e-01 -1.59917071e-01  3.40029538e-01  6.89675689e-01\n",
      "  -8.56862217e-03  3.09872091e-01 -1.13205068e-01  3.58899087e-01\n",
      "   3.27060789e-01  5.77338398e-01 -5.04167259e-01 -1.47472799e-01\n",
      "  -7.25439936e-02  4.63712364e-01  1.08015649e-01 -6.02132678e-02\n",
      "   1.06959179e-01  1.94174647e-02 -1.63224891e-01  2.61859745e-01\n",
      "  -8.82089257e-01  3.19492787e-01  2.45765716e-01  6.16865158e-01\n",
      "   7.51317441e-02 -5.74977845e-02 -2.07060546e-01  1.03675395e-01\n",
      "  -4.39921379e-01  2.83426881e-01  1.49134189e-01  9.72769856e-02\n",
      "   3.02094758e-01 -3.32417041e-02  3.33337069e-01 -9.27260704e-03\n",
      "   3.52230012e-01 -1.74012467e-01  2.46012121e-01 -3.60996097e-01\n",
      "   5.07422984e-02  4.21553075e-01  8.73383433e-02  1.38615251e-01\n",
      "  -2.42768317e-01  1.24593049e-01  4.02051270e-01  2.11522609e-01\n",
      "   1.87508285e-01 -4.87396121e-03  2.88689405e-01  3.96354944e-02\n",
      "  -4.73889112e-01  3.32799941e-01 -4.80940282e-01 -1.94431737e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Generated one embedding?\n",
    "\n",
    "print(one_vector)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Embeddings Generation using CLIP\n",
    "\n",
    "### Inputs\n",
    "\n",
    "* **Keyframes (images) **: [insert description or link to transcription]\n",
    "* **Extraction from Slides using OCR**: [insert description or link to extracted content]\n",
    "* **Prompt**: [insert description or link to \n",
    "interpreted information]"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:50:23.798178Z",
     "start_time": "2024-06-10T09:50:21.092579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:51:44.584932Z",
     "start_time": "2024-06-10T09:51:44.561886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from src.clip.image_dataset import image_urls\n",
    "\n",
    "#from src.clip.load_images import load_images_from_path\n",
    "\n",
    "base_dir = os.path.dirname(os.path.abspath(\".\"))\n",
    "\n",
    "relative_image_path_1 = os.path.join(base_dir, 'afm-vlm', 'data', 'raw', 'biology_chapter_3_3', 'extracted_keyframes',\n",
    "                                     'biology_chapter_3_3-Scene-039-01.jpg')\n",
    "relative_image_path_2 = os.path.join(base_dir, 'afm-vlm', 'data', 'raw', 'biology_chapter_3_3', 'extracted_keyframes',\n",
    "                                     'biology_chapter_3_3-Scene-099-01.jpg')\n",
    "relative_image_path_3 = os.path.join(base_dir, 'afm-vlm', 'data', 'raw', 'biology_chapter_3_3', 'extracted_keyframes',\n",
    "                                     'biology_chapter_3_3-Scene-016-01.jpg')\n",
    "\n",
    "image_paths = [relative_image_path_1, relative_image_path_2, relative_image_path_3]\n",
    "\n",
    "\n",
    "def load_images_from_path(image_paths):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        images.append(Image.open(path))\n",
    "    return images\n",
    "\n",
    "\n",
    "image_dataset = load_images_from_path(image_paths)\n",
    "\n",
    "image_dataset"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=966x720>,\n",
       " <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=966x720>,\n",
       " <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=966x720>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Generate OCR Captions"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:51:47.486776Z",
     "start_time": "2024-06-10T09:51:45.864569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ocr_extracted_text = []\n",
    "for path in image_paths:\n",
    "    extract_text_from_image(path)\n",
    "    ocr_extracted_text.append(extract_text_from_image(path))\n",
    "    logger.info(f\"OCR_results: {ocr_extracted_text}\")\n",
    "#logger.info(f\"OCR_results: {ocr_extracted_text}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-06-10 11:51:46.400\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m5\u001B[0m - \u001B[1mOCR_results: ['Nutrients: Macronutrients\\n\\nÂ¢ Fats: source of stored energy\\nâ Cushion and protect vital organs\\nâ Insulate the body in cold weather\\n']\u001B[0m\n",
      "\u001B[32m2024-06-10 11:51:47.097\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m5\u001B[0m - \u001B[1mOCR_results: ['Nutrients: Macronutrients\\n\\nÂ¢ Fats: source of stored energy\\nâ Cushion and protect vital organs\\nâ Insulate the body in cold weather\\n', 'Which Describes Active Transport?\\n\\nA. K+ will move from high concentration\\n\\nto low concentration; ATP is used. âRetive transport\\nK\\n\\nB. K+ will move from low Low concentration\\nconcentration to high\\nconcentration; ATP is used.\\n\\nC. K+ will move from high concentration\\nto low concentration; ATP is not\\nused.\\n\\nb\\nD. K+ will move from low concentration\\nto high concentration; ATP is not\\nused.\\n']\u001B[0m\n",
      "\u001B[32m2024-06-10 11:51:47.474\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m5\u001B[0m - \u001B[1mOCR_results: ['Nutrients: Macronutrients\\n\\nÂ¢ Fats: source of stored energy\\nâ Cushion and protect vital organs\\nâ Insulate the body in cold weather\\n', 'Which Describes Active Transport?\\n\\nA. K+ will move from high concentration\\n\\nto low concentration; ATP is used. âRetive transport\\nK\\n\\nB. K+ will move from low Low concentration\\nconcentration to high\\nconcentration; ATP is used.\\n\\nC. K+ will move from high concentration\\nto low concentration; ATP is not\\nused.\\n\\nb\\nD. K+ will move from low concentration\\nto high concentration; ATP is not\\nused.\\n', 'Bottled water is cleaner than tap water.\\n\\nA. True\\nB. False\\n\\n']\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:56:11.840086Z",
     "start_time": "2024-06-10T09:56:11.791744Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_images_preprocessed = torch.cat([preprocess(image).unsqueeze(0) for image in image_dataset], dim=0).to(device)",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:56:12.301661Z",
     "start_time": "2024-06-10T09:56:12.290571Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_images_preprocessed",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "          [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "          [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "          ...,\n",
       "          [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "          [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "          [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303]],\n",
       "\n",
       "         [[2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "          [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "          [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "          ...,\n",
       "          [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "          [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "          [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749]],\n",
       "\n",
       "         [[2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "          [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "          [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "          ...,\n",
       "          [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "          [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "          [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459]]],\n",
       "\n",
       "\n",
       "        [[[1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "          [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "          [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "          ...,\n",
       "          [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "          [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "          [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303]],\n",
       "\n",
       "         [[2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "          [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "          [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "          ...,\n",
       "          [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "          [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "          [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749]],\n",
       "\n",
       "         [[2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "          [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "          [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "          ...,\n",
       "          [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "          [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "          [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459]]],\n",
       "\n",
       "\n",
       "        [[[1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "          [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "          [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "          ...,\n",
       "          [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "          [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "          [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303]],\n",
       "\n",
       "         [[2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "          [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "          [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "          ...,\n",
       "          [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "          [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "          [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749]],\n",
       "\n",
       "         [[2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "          [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "          [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "          ...,\n",
       "          [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "          [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "          [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459]]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:56:13.400404Z",
     "start_time": "2024-06-10T09:56:13.244317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# generate embeddings\n",
    "with torch.no_grad():\n",
    "    dataset_image_embeddings  = model.encode_image(dataset_images_preprocessed)"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:59:40.877768Z",
     "start_time": "2024-06-10T09:59:40.714181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load test keyframe image\n",
    "test_image_path = os.path.join(base_dir, 'afm-vlm', 'data', 'raw', 'biology_chapter_3_3', 'extracted_keyframes',\n",
    "                                     'biology_chapter_3_3-Scene-099-01.jpg')\n",
    "test_image = Image.open(test_image_path)\n",
    "test_image_preprocessed = preprocess(test_image).unsqueeze(0).to(device)\n",
    "\n",
    "# generate embedding for the test keyframe image\n",
    "test_image_embedding = model.encode_image(test_image_preprocessed)"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:59:41.127514Z",
     "start_time": "2024-06-10T09:59:41.113428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute the cosine similarity between the test image embedding and each dataset image embedding\n",
    "cosine_similarity = torch.nn.functional.cosine_similarity(test_image_embedding, dataset_image_embeddings)\n",
    "\n",
    "# Get the index of the image with the highest similarity\n",
    "max_similarity_index = cosine_similarity.argmax().item()\n",
    "max_similarity_index\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afm-vlm-JEfTnAR4-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
