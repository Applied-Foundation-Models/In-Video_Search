{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-13T11:08:48.293667Z",
     "start_time": "2024-07-13T11:08:47.942630Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "\n",
    "from src.text_embedder.embedder import EmbeddingsModel\n",
    "\n",
    "from pathlib import Path\n",
    "import os"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ed097945bf783f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Data",
   "id": "18eb4cd1dfbcf75c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T11:08:48.587246Z",
     "start_time": "2024-07-13T11:08:48.293667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "notebook_path = Path().resolve().parent\n",
    "print(notebook_path)\n",
    "\n",
    "# Construct the filename relative to the new path\n",
    "filename = notebook_path / \"test_frames_math1.csv\"\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(filename)\n",
    "print(df)"
   ],
   "id": "4a36f9c86e3e18ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baatout\\PycharmProjects\\afm-vlm\\experiments\\second_experiment\n",
      "    ID                                             Prompt Length  GT_Keyframe\n",
      "0    1       what is a binomial probability distribution?   long           18\n",
      "1    2    x is a specific number of successes in n trials   long           25\n",
      "2    3                                       P(F) = 1 -p   short           23\n",
      "3    4  what procedures does the binomial probability ...   long           29\n",
      "4    5          What is the binomial probability formula?   long           58\n",
      "5    6  What is the method 2 for finding the binomial ...   long           80\n",
      "6    7  How many NFL Football games betweem 1974 and 2...   long           85\n",
      "7    8           What are the key concepts of the lecture   long            3\n",
      "8    9  What is the probability of failure in the twit...   long           46\n",
      "9   10                Using the given values of n x and q   long           65\n",
      "10  11  probability of success remains the same in all...   long           22\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T11:08:48.879666Z",
     "start_time": "2024-07-13T11:08:48.587246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create dataframe to save results of the experiments\n",
    "columns = ['Prompt', 'GT_Keyframe', 'Top_1', 'Top_2', 'Top_3']\n",
    "\n",
    "df_test = pd.DataFrame(columns=columns)\n",
    "\n",
    "df_ocr_only = df_test\n",
    "df_ocr_lava = df_test\n",
    "df_ocr_transcriptions = df_test\n",
    "\n",
    "df_short_llm_summary = df_test\n",
    "df_extensive_summary = df_test"
   ],
   "id": "64578e40fcd3a6ed",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T11:08:49.165739Z",
     "start_time": "2024-07-13T11:08:48.882038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_to_df(prompt, gt_keyframe, result):\n",
    "    # Create a new row with the provided data\n",
    "    return {\n",
    "        'Prompt': prompt,\n",
    "        'GT_Keyframe': gt_keyframe,\n",
    "        'Top_1': extract_keyframe_number(result[0]) if len(result) > 0 else None,\n",
    "        'Top_2': extract_keyframe_number(result[1]) if len(result) > 1 else None,\n",
    "        'Top_3': extract_keyframe_number(result[2]) if len(result) > 2 else None\n",
    "    }\n",
    "\n",
    "\n",
    "# ietrate over the dataframe and get the results\n",
    "def get_results(df):\n",
    "    for _, row in df.iterrows():\n",
    "        logger.info(row['Prompt'])\n",
    "        prompt = row['Prompt']\n",
    "        gt_keyframe = row['GT_Keyframe']\n",
    "\n",
    "        # Search for similar images\n",
    "        output = embedding_model.search_similar_images_top_k(prompt, gt_keyframe, 3)\n",
    "        res_row = add_to_df(prompt, gt_keyframe, output)\n",
    "        rows.append(res_row)\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "def extract_keyframe_number(path):\n",
    "    \"\"\"\n",
    "    Extracts the scene number from the given file path.\n",
    "\n",
    "    Parameters:\n",
    "    path (str): The full path of the file.\n",
    "\n",
    "    Returns:\n",
    "    str: The extracted scene number.\n",
    "    \"\"\"\n",
    "    # Get filename without extension\n",
    "    filename = os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "    # Extract '032' from filename\n",
    "    scene_number = filename.split('-Scene-')[-1].split('-')[0]\n",
    "\n",
    "    return scene_number"
   ],
   "id": "b9b4e99d4b8ea54",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T11:08:49.440504Z",
     "start_time": "2024-07-13T11:08:49.167832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#top_3 = []\n",
    "#embedding_model.check_proximity_keyframes(90, top_3)"
   ],
   "id": "c471d13af2b4719f",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "bd96b30ced9483bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LOAD MODEL ",
   "id": "b9f59e530248b7eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T11:08:52.774471Z",
     "start_time": "2024-07-13T11:08:49.442625Z"
    }
   },
   "cell_type": "code",
   "source": "embedding_model = EmbeddingsModel()",
   "id": "415087029f4c5533",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T11:08:53.114894Z",
     "start_time": "2024-07-13T11:08:52.777992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "csv = notebook_path / \"math_1.csv\"\n",
    "df_data_extensive = pd.read_csv(csv)\n",
    "df_data_extensive"
   ],
   "id": "f68a639265049b08",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                           Unnamed: 0  \\\n",
       "0                            img_path   \n",
       "1                          timestamps   \n",
       "2                       transcription   \n",
       "3                  ocr_extracted_text   \n",
       "4                        llava_result   \n",
       "5                           clip_text   \n",
       "6                    llm_long_summary   \n",
       "7                 clip_text_embedding   \n",
       "8                clip_image_embedding   \n",
       "9             standard_text_embedding   \n",
       "10           extensive_text_embedding   \n",
       "11                 ocr_text_embedding   \n",
       "12       transcription_text_embedding   \n",
       "13               llava_text_embedding   \n",
       "14        ocr_transcription_embedding   \n",
       "15  ocr_transcription_llava_embedding   \n",
       "\n",
       "                                                   80  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                   [1454.08, 1459.2]   \n",
       "2    Another way to find binomial probabilities is...   \n",
       "3   Method 2: Using Technology\\r\\n\\r\\nTechnologies...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Binomial probabilities, technology, spreadshee...   \n",
       "6   Method 2: Using Technology - The lecture discu...   \n",
       "7   tensor([[ 5.1960e-03,  5.5442e-02, -2.9637e-02...   \n",
       "8   tensor([[-1.6722e-02,  1.2606e-01, -3.9023e-02...   \n",
       "9   tensor([-8.5635e-02, -8.2966e-02, -2.1982e-01,...   \n",
       "10  tensor([-1.8073e-01,  1.8656e-02, -7.9516e-02,...   \n",
       "11  tensor([-1.7012e-01, -2.3376e-02, -6.5044e-02,...   \n",
       "12  tensor([-1.1286e-01, -3.6851e-02, -7.1103e-02,...   \n",
       "13  tensor([-5.5286e-02, -5.7482e-02,  2.3002e-02,...   \n",
       "14  tensor([-0.1558, -0.0281, -0.0629, -0.2853,  0...   \n",
       "15  tensor([-1.5069e-01, -4.7678e-02, -5.0572e-02,...   \n",
       "\n",
       "                                                   26  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                    [399.44, 404.48]   \n",
       "2    Notice that X can be any whole number between...   \n",
       "3   be any whole number between 0 and n, inclusive...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Bionomial probability distributions, notation,...   \n",
       "6   The slide explains notation for binomial proba...   \n",
       "7   tensor([[-2.2565e-02,  2.9402e-02, -6.4396e-02...   \n",
       "8   tensor([[-1.1037e-02,  4.2648e-02, -1.3678e-02...   \n",
       "9   tensor([ 3.5344e-02,  3.0355e-02,  7.1971e-03,...   \n",
       "10  tensor([-0.0751, -0.1122, -0.1110, -0.2555, -0...   \n",
       "11  tensor([-3.3976e-02, -5.2518e-02, -8.7697e-02,...   \n",
       "12  tensor([-0.2527,  0.0917, -0.0312, -0.0377, -0...   \n",
       "13  tensor([-0.0832,  0.0405,  0.0582, -0.1096,  0...   \n",
       "14  tensor([-2.8846e-02, -6.3873e-02, -1.1736e-01,...   \n",
       "15  tensor([-4.1617e-03, -4.7293e-02, -7.4943e-02,...   \n",
       "\n",
       "                                                   38  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                     [715.6, 716.92]   \n",
       "2                         I guess they'd set with RIP   \n",
       "3   The word success as used here is arbitrary and...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   success probability p, binomial distribution, ...   \n",
       "6   The concept of success as used here is arbitra...   \n",
       "7   tensor([[ 1.6784e-02,  8.1404e-03, -2.5032e-02...   \n",
       "8   tensor([[ 1.1816e-02,  7.1861e-02, -3.5468e-05...   \n",
       "9   tensor([ 2.2932e-01, -1.0410e-01, -1.6513e-01,...   \n",
       "10  tensor([ 1.4936e-01, -6.9109e-03, -1.8281e-01,...   \n",
       "11  tensor([ 4.7415e-02, -1.6109e-01, -2.1035e-01,...   \n",
       "12  tensor([-2.1935e-01, -1.0559e-01,  2.2703e-01,...   \n",
       "13  tensor([ 2.2215e-02, -1.0916e-01,  6.8139e-02,...   \n",
       "14  tensor([ 0.0047, -0.1774, -0.1902, -0.1306, -0...   \n",
       "15  tensor([ 5.7992e-03, -2.2144e-01, -1.7809e-01,...   \n",
       "\n",
       "                                                   45  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                     [783.36, 785.6]   \n",
       "2                               equals 5, x equals 3.   \n",
       "3   Solution\\r\\n\\r\\nb. Having concluded that the g...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Binomial distribution, Twitter data collection...   \n",
       "6   The lecture discussed a binomial distribution ...   \n",
       "7   tensor([[ 1.0491e-02,  1.8044e-02, -1.6795e-02...   \n",
       "8   tensor([[-3.8834e-02,  3.5723e-02, -2.2615e-02...   \n",
       "9   tensor([ 2.5956e-02, -1.6343e-01, -1.7768e-01,...   \n",
       "10  tensor([ 0.0142,  0.0795, -0.0884, -0.3639,  0...   \n",
       "11  tensor([-3.4410e-02,  1.3466e-02, -4.2267e-02,...   \n",
       "12  tensor([ 0.2134, -0.0186, -0.0360, -0.0049, -0...   \n",
       "13  tensor([-1.5370e-01,  1.8803e-01,  4.5884e-02,...   \n",
       "14  tensor([-0.0262, -0.0007, -0.0523, -0.2620, -0...   \n",
       "15  tensor([ 1.6927e-02, -3.4209e-02, -5.8822e-02,...   \n",
       "\n",
       "                                                   34  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                    [593.92, 599.04]   \n",
       "2    So here that is again, again the example we'r...   \n",
       "3   * Binomial Probability Distribution BS\\r\\n—Abi...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Binomial probability distribution, independent...   \n",
       "6   A binomial probability distribution results fr...   \n",
       "7   tensor([[-1.7205e-02,  3.4386e-02, -3.2124e-02...   \n",
       "8   tensor([[-1.7681e-02,  3.2758e-02, -1.0590e-02...   \n",
       "9   tensor([ 0.0245,  0.1300, -0.0587, -0.2838, -0...   \n",
       "10  tensor([ 6.5100e-02,  5.6179e-02, -9.4640e-02,...   \n",
       "11  tensor([ 2.0410e-02,  1.5192e-01, -1.8803e-01,...   \n",
       "12  tensor([ 0.0664, -0.1439,  0.0947,  0.1197,  0...   \n",
       "13  tensor([-0.1649, -0.1063, -0.0328, -0.2106,  0...   \n",
       "14  tensor([ 2.6093e-02,  1.2894e-01, -1.7960e-01,...   \n",
       "15  tensor([ 0.0422,  0.1119, -0.1470, -0.1917,  0...   \n",
       "\n",
       "                                                   49  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                    [798.72, 813.96]   \n",
       "2    that X and P both refer to the same concept o...   \n",
       "3   ple:\\r\\n\\r\\nSolution\\r\\n\\r\\nAgain, it is very ...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Twitter educational tool, share ideas/resource...   \n",
       "6   The lecture discussed the importance of using ...   \n",
       "7   tensor([[-1.0936e-02,  1.3913e-02, -9.5265e-03...   \n",
       "8   tensor([[-3.4967e-02,  1.1532e-02,  5.8089e-03...   \n",
       "9   tensor([-5.0663e-02, -1.9418e-01, -9.7258e-02,...   \n",
       "10  tensor([-0.0523, -0.0989, -0.0447, -0.1362, -0...   \n",
       "11  tensor([-3.4922e-02, -1.5838e-01,  1.7810e-02,...   \n",
       "12  tensor([-0.0280, -0.4231, -0.0143, -0.2034, -0...   \n",
       "13  tensor([-0.1994, -0.0615,  0.1766, -0.0913,  0...   \n",
       "14  tensor([-4.6075e-02, -1.8089e-01,  4.9301e-03,...   \n",
       "15  tensor([-4.6075e-02, -1.8089e-01,  4.9301e-03,...   \n",
       "\n",
       "                                                   57  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                   [977.92, 1083.88]   \n",
       "2    Right, I would be very surprised if anybody i...   \n",
       "3   Let’s develop the fo\\r\\n\\r\\ni\\r\\n\\r\\n+ On the ...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Probability calculation, probability of gettin...   \n",
       "6   The probability of getting exactly 3 right ans...   \n",
       "7   tensor([[ 8.6700e-03,  2.2865e-02, -1.4433e-02...   \n",
       "8   tensor([[-3.4798e-02,  4.2907e-02, -1.9039e-02...   \n",
       "9   tensor([ 1.6039e-01, -1.6502e-01, -1.2744e-02,...   \n",
       "10  tensor([ 0.4545, -0.3252, -0.0938, -0.2329, -0...   \n",
       "11  tensor([ 9.2679e-02, -2.2400e-01, -7.5917e-02,...   \n",
       "12  tensor([ 1.2617e-01, -2.9918e-01,  8.4224e-02,...   \n",
       "13  tensor([-1.0690e-01, -2.1193e-01, -5.2433e-02,...   \n",
       "14  tensor([ 0.0899, -0.2315, -0.0652, -0.2966, -0...   \n",
       "15  tensor([ 0.0899, -0.2315, -0.0652, -0.2966, -0...   \n",
       "\n",
       "                                                    2  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                      [10.12, 30.72]   \n",
       "2    Okay, so the binomial distribution, binomial ...   \n",
       "3   Key Concept\\r\\n\\r\\nThe focus of this section i...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Binomial probability distribution, discrete pr...   \n",
       "6   The binomial distribution, binomial probabilit...   \n",
       "7   tensor([[-4.5463e-03,  1.6110e-02, -2.0650e-02...   \n",
       "8   tensor([[-1.1023e-03,  4.4724e-02, -2.0930e-02...   \n",
       "9   tensor([ 1.0485e-01, -5.6872e-02,  1.0654e-01,...   \n",
       "10  tensor([-1.3679e-01,  1.0031e-02, -3.8077e-02,...   \n",
       "11  tensor([-9.7531e-02,  1.1729e-02, -4.8321e-02,...   \n",
       "12  tensor([-0.0970, -0.1151,  0.1323, -0.1864,  0...   \n",
       "13  tensor([-9.6267e-02, -1.4498e-01, -4.5661e-02,...   \n",
       "14  tensor([-1.3256e-01, -9.8598e-03,  4.0017e-03,...   \n",
       "15  tensor([-1.2094e-01, -2.1370e-02, -2.5478e-04,...   \n",
       "\n",
       "                                                   61  ...  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...  ...   \n",
       "1                                  [1190.28, 1231.16]  ...   \n",
       "2    Okay, so back to the Twitter example, and the...  ...   \n",
       "3   Example: Twitter (7 or\\r\\n\\r\\nGiven that there...  ...   \n",
       "4    The image you've provided appears to be a scr...  ...   \n",
       "5   Twitter probability binomial formula adults kn...  ...   \n",
       "6   Given that there is a 0.85 probability that a ...  ...   \n",
       "7   tensor([[-1.4731e-03,  1.6395e-02, -2.2071e-02...  ...   \n",
       "8   tensor([[-2.4954e-02,  2.8499e-02, -1.2477e-02...  ...   \n",
       "9   tensor([ 0.1081, -0.0920, -0.0017, -0.3471,  0...  ...   \n",
       "10  tensor([-2.8476e-02, -7.4902e-02,  7.4877e-02,...  ...   \n",
       "11  tensor([-8.1552e-02, -1.2928e-01,  5.2166e-02,...  ...   \n",
       "12  tensor([-0.0134, -0.2096,  0.1396, -0.3475,  0...  ...   \n",
       "13  tensor([ 4.6093e-03, -1.5259e-01,  1.8080e-02,...  ...   \n",
       "14  tensor([-8.1063e-02, -1.5291e-01,  6.1723e-02,...  ...   \n",
       "15  tensor([-8.1063e-02, -1.5291e-01,  6.1723e-02,...  ...   \n",
       "\n",
       "                                                   40  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                    [721.92, 763.32]   \n",
       "2    C major is a binomial distribution.  So let's...   \n",
       "3   ®\\r\\n\\r\\nple:\\r\\n\\r\\nWhen an adult is randomly...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Binomial distribution, probability of success ...   \n",
       "6   The lecture discusses a binomial distribution ...   \n",
       "7   tensor([[-8.6146e-03,  8.3915e-03, -3.9367e-02...   \n",
       "8   tensor([[-1.1230e-02,  5.8981e-02,  2.2850e-02...   \n",
       "9   tensor([ 8.9046e-02,  1.7294e-02, -1.7561e-01,...   \n",
       "10  tensor([ 1.2892e-02,  7.9248e-02, -9.0279e-02,...   \n",
       "11  tensor([-4.0876e-02, -3.4146e-02, -1.3483e-03,...   \n",
       "12  tensor([ 0.1395, -0.0910,  0.0794, -0.3907, -0...   \n",
       "13  tensor([-0.0205, -0.0816,  0.0323, -0.0862,  0...   \n",
       "14  tensor([-4.0876e-02, -3.4146e-02, -1.3483e-03,...   \n",
       "15  tensor([-4.0876e-02, -3.4146e-02, -1.3483e-03,...   \n",
       "\n",
       "                                                   23  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                    [313.64, 369.36]   \n",
       "2    Okay. Notation. So, P little P is what we alw...   \n",
       "3   Sand F (success and failure) denote the two\\r\\...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Binomial probability, notation P and Q, add up...   \n",
       "6   The lecture discussed binomial probability dis...   \n",
       "7   tensor([[ 5.3796e-03,  7.5618e-03, -2.3130e-02...   \n",
       "8   tensor([[ 5.0079e-03,  5.3988e-02, -3.3951e-02...   \n",
       "9   tensor([ 1.0437e-01, -7.3343e-03, -7.2010e-02,...   \n",
       "10  tensor([-0.1565,  0.1090, -0.1335, -0.2257, -0...   \n",
       "11  tensor([-0.2049, -0.2461,  0.1274, -0.0621, -0...   \n",
       "12  tensor([-4.8438e-03, -2.3021e-01,  3.5162e-02,...   \n",
       "13  tensor([-1.5808e-01, -1.1350e-01,  4.9287e-02,...   \n",
       "14  tensor([-1.8131e-01, -2.6552e-01,  1.4785e-01,...   \n",
       "15  tensor([-1.8131e-01, -2.6552e-01,  1.4785e-01,...   \n",
       "\n",
       "                                                   76  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                    [1408.0, 1433.6]   \n",
       "2    used your specific number or whatever you got...   \n",
       "3   X=number Frequency Relative freq. Theoretical ...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Probability theory observed vs theoretical fre...   \n",
       "6   The slide presents a quiz on observed vs theor...   \n",
       "7   tensor([[-3.4614e-02,  2.4161e-02, -4.2352e-02...   \n",
       "8   tensor([[ 5.8095e-03,  3.5173e-02, -1.5557e-02...   \n",
       "9   tensor([ 8.8447e-02, -1.1505e-02,  1.4052e-01,...   \n",
       "10  tensor([ 0.0728, -0.0427, -0.1030, -0.0830,  0...   \n",
       "11  tensor([-1.0861e-01,  8.0917e-02,  2.1251e-02,...   \n",
       "12  tensor([ 0.2031, -0.2477, -0.3101, -0.1122,  0...   \n",
       "13  tensor([-8.8247e-02, -4.4753e-02, -1.5758e-04,...   \n",
       "14  tensor([ 0.0035, -0.0956, -0.0396, -0.1699,  0...   \n",
       "15  tensor([ 0.0035, -0.0956, -0.0396, -0.1699,  0...   \n",
       "\n",
       "                                                   15  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                    [117.76, 150.28]   \n",
       "2    answers right or wrong. Number three is D. Nu...   \n",
       "3               The Answers — how did you do?\\r\\n\\r\\n   \n",
       "4    The slide appears to be from an academic lect...   \n",
       "5   Answers right or wrong, multiple-choice questi...   \n",
       "6   The lecture appears to be an assessment of und...   \n",
       "7   tensor([[ 1.7163e-03,  8.9570e-03,  2.8305e-03...   \n",
       "8   tensor([[-4.0929e-02,  4.3851e-02, -4.2689e-02...   \n",
       "9   tensor([ 4.4614e-01, -2.1112e-01,  3.4753e-02,...   \n",
       "10  tensor([ 1.4151e-01,  9.5755e-02, -8.1816e-02,...   \n",
       "11  tensor([ 5.0100e-01,  4.2088e-02,  2.4783e-01,...   \n",
       "12  tensor([ 0.2544, -0.2140, -0.1404, -0.0309, -0...   \n",
       "13  tensor([ 1.1979e-01, -1.1710e-01,  1.6335e-01,...   \n",
       "14  tensor([ 2.7631e-01, -1.1319e-01, -6.0725e-02,...   \n",
       "15  tensor([ 2.7631e-01, -1.1319e-01, -6.0725e-02,...   \n",
       "\n",
       "                                                   68  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                  [1345.12, 1346.56]   \n",
       "2                                                 NaN   \n",
       "3   2\\r\\n\\r\\n+ How many did you get right on the p...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Pop quiz probability, theoretical vs. observed...   \n",
       "6   The lecture discussed how many students got ri...   \n",
       "7   tensor([[-1.5380e-02, -2.8845e-03, -7.9334e-03...   \n",
       "8   tensor([[-1.9318e-02,  5.5134e-02, -6.3328e-02...   \n",
       "9   tensor([ 1.3634e-01, -3.0984e-02, -1.2701e-01,...   \n",
       "10  tensor([ 0.0550,  0.0839, -0.1225, -0.1555, -0...   \n",
       "11  tensor([ 9.9797e-02, -1.2169e-01, -1.7010e-02,...   \n",
       "12  tensor([ 2.2692e-01,  8.1784e-02,  2.3543e-02,...   \n",
       "13  tensor([ 4.5333e-02, -1.0781e-01,  9.9918e-02,...   \n",
       "14  tensor([ 9.9797e-02, -1.2169e-01, -1.7010e-02,...   \n",
       "15  tensor([ 0.0938, -0.2037, -0.0279, -0.1850, -0...   \n",
       "\n",
       "                                                   19  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                    [209.92, 252.48]   \n",
       "2    It has four requirements.  Number one, the pr...   \n",
       "3   ab\\r\\n\\r\\n* Binomial Probability Distribution\\...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Binomial probability distribution, fixed numbe...   \n",
       "6   The binomial probability distribution results ...   \n",
       "7   tensor([[-7.7309e-03,  1.8499e-02, -3.7852e-02...   \n",
       "8   tensor([[-0.0119,  0.0322, -0.0126,  0.0180, -...   \n",
       "9   tensor([ 1.7352e-02,  5.3766e-02, -7.4951e-03,...   \n",
       "10  tensor([ 0.0754,  0.1210, -0.0456, -0.2778, -0...   \n",
       "11  tensor([ 0.0068,  0.1454, -0.1894, -0.1955, -0...   \n",
       "12  tensor([ 1.4470e-01,  8.1109e-02, -7.0167e-02,...   \n",
       "13  tensor([-1.6687e-01, -6.3698e-02,  5.2310e-02,...   \n",
       "14  tensor([ 5.6154e-02,  1.4585e-01, -1.6363e-01,...   \n",
       "15  tensor([ 5.6154e-02,  1.4585e-01, -1.6363e-01,...   \n",
       "\n",
       "                                                   64  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                   [1264.64, 1306.4]   \n",
       "2    Okay, now I'm just going to go ahead and hit ...   \n",
       "3                                                 NaN   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Probability calculator math Twitter adults hea...   \n",
       "6   The lecture discussed calculators and mathemat...   \n",
       "7   tensor([[-1.2640e-03,  1.7357e-02, -1.5980e-02...   \n",
       "8   tensor([[ 2.1822e-02,  3.0071e-02,  9.9883e-03...   \n",
       "9   tensor([ 0.1213, -0.3609, -0.1789, -0.1939, -0...   \n",
       "10  tensor([ 3.3183e-02, -6.4988e-02, -2.0071e-01,...   \n",
       "11  tensor([ 2.2692e-01,  8.1784e-02,  2.3543e-02,...   \n",
       "12  tensor([ 1.3068e-02, -2.1405e-01,  3.1282e-02,...   \n",
       "13  tensor([-0.0403, -0.2010,  0.0270, -0.0218,  0...   \n",
       "14  tensor([ 1.3068e-02, -2.1405e-01,  3.1282e-02,...   \n",
       "15  tensor([ 1.0324e-03, -1.5084e-01,  6.6102e-02,...   \n",
       "\n",
       "                                                    7  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                      [61.44, 63.04]   \n",
       "2                                                 NaN   \n",
       "3   Pop quiz! i\\r\\n\\r\\n* Number your paper 1-10. T...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Pop quiz! 10 questions, each with 4 choices (A...   \n",
       "6   Pop quiz! The lecture appears to be an academi...   \n",
       "7   tensor([[ 8.0131e-03,  3.1325e-02,  7.0254e-03...   \n",
       "8   tensor([[ 8.8992e-04,  2.4442e-02, -6.5559e-02...   \n",
       "9   tensor([ 0.0854,  0.0739,  0.3152, -0.0486, -0...   \n",
       "10  tensor([ 0.0975,  0.2250,  0.0211, -0.1165, -0...   \n",
       "11  tensor([-1.4790e-01,  1.9107e-01,  1.5564e-01,...   \n",
       "12  tensor([ 2.2692e-01,  8.1784e-02,  2.3543e-02,...   \n",
       "13  tensor([ 1.2520e-02, -3.7925e-02,  1.5745e-01,...   \n",
       "14  tensor([-1.4790e-01,  1.9107e-01,  1.5564e-01,...   \n",
       "15  tensor([-0.1330,  0.0448,  0.2359, -0.1617,  0...   \n",
       "\n",
       "                                                   89  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                   [1820.88, 1861.8]   \n",
       "2    Our sort of working definition of what is an ...   \n",
       "3   Solution\\r\\n\\r\\nThe Excel display on the next ...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Unusual event probability <0.05, overtime coin...   \n",
       "6   The probability of 252 or more wins in 460 ove...   \n",
       "7   tensor([[-1.4216e-03, -2.0283e-02, -1.2192e-02...   \n",
       "8   tensor([[-1.1211e-02,  7.0335e-02, -4.6952e-02...   \n",
       "9   tensor([ 1.2005e-01, -2.1817e-01, -1.7670e-01,...   \n",
       "10  tensor([ 1.3362e-01, -2.1329e-01, -2.5612e-01,...   \n",
       "11  tensor([ 1.4016e-01, -2.5006e-02, -2.8691e-01,...   \n",
       "12  tensor([-4.4180e-02, -3.0056e-01, -1.0255e-01,...   \n",
       "13  tensor([ 2.0953e-02, -5.0737e-02, -1.3741e-01,...   \n",
       "14  tensor([ 1.4720e-01, -3.3228e-02, -2.8897e-01,...   \n",
       "15  tensor([ 1.4720e-01, -3.3228e-02, -2.8897e-01,...   \n",
       "\n",
       "                                                   85  \n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...  \n",
       "1                                  [1617.92, 1679.88]  \n",
       "2    Okay, so here's a good example for technology...  \n",
       "3   We previously noted that between 1974 and 2011...  \n",
       "4    The image you've provided appears to be a scr...  \n",
       "5   NFL games overtime coin toss wins probability ...  \n",
       "6   The lecture discussed NFL football games decid...  \n",
       "7   tensor([[ 2.6404e-03,  5.7825e-03, -4.9042e-03...  \n",
       "8   tensor([[-1.7590e-02,  2.9331e-02, -3.1065e-02...  \n",
       "9   tensor([-8.3826e-02, -1.5241e-01, -4.6781e-02,...  \n",
       "10  tensor([ 0.0451, -0.1206, -0.2157, -0.2854, -0...  \n",
       "11  tensor([ 3.3652e-03, -1.7468e-01, -1.2044e-01,...  \n",
       "12  tensor([ 3.9551e-02, -1.2612e-01, -4.5963e-02,...  \n",
       "13  tensor([-0.0257, -0.0809,  0.0372, -0.0814,  0...  \n",
       "14  tensor([ 3.3652e-03, -1.7468e-01, -1.2044e-01,...  \n",
       "15  tensor([ 3.3652e-03, -1.7468e-01, -1.2044e-01,...  \n",
       "\n",
       "[16 rows x 90 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>80</th>\n",
       "      <th>26</th>\n",
       "      <th>38</th>\n",
       "      <th>45</th>\n",
       "      <th>34</th>\n",
       "      <th>49</th>\n",
       "      <th>57</th>\n",
       "      <th>2</th>\n",
       "      <th>61</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>23</th>\n",
       "      <th>76</th>\n",
       "      <th>15</th>\n",
       "      <th>68</th>\n",
       "      <th>19</th>\n",
       "      <th>64</th>\n",
       "      <th>7</th>\n",
       "      <th>89</th>\n",
       "      <th>85</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_path</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>timestamps</td>\n",
       "      <td>[1454.08, 1459.2]</td>\n",
       "      <td>[399.44, 404.48]</td>\n",
       "      <td>[715.6, 716.92]</td>\n",
       "      <td>[783.36, 785.6]</td>\n",
       "      <td>[593.92, 599.04]</td>\n",
       "      <td>[798.72, 813.96]</td>\n",
       "      <td>[977.92, 1083.88]</td>\n",
       "      <td>[10.12, 30.72]</td>\n",
       "      <td>[1190.28, 1231.16]</td>\n",
       "      <td>...</td>\n",
       "      <td>[721.92, 763.32]</td>\n",
       "      <td>[313.64, 369.36]</td>\n",
       "      <td>[1408.0, 1433.6]</td>\n",
       "      <td>[117.76, 150.28]</td>\n",
       "      <td>[1345.12, 1346.56]</td>\n",
       "      <td>[209.92, 252.48]</td>\n",
       "      <td>[1264.64, 1306.4]</td>\n",
       "      <td>[61.44, 63.04]</td>\n",
       "      <td>[1820.88, 1861.8]</td>\n",
       "      <td>[1617.92, 1679.88]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transcription</td>\n",
       "      <td>Another way to find binomial probabilities is...</td>\n",
       "      <td>Notice that X can be any whole number between...</td>\n",
       "      <td>I guess they'd set with RIP</td>\n",
       "      <td>equals 5, x equals 3.</td>\n",
       "      <td>So here that is again, again the example we'r...</td>\n",
       "      <td>that X and P both refer to the same concept o...</td>\n",
       "      <td>Right, I would be very surprised if anybody i...</td>\n",
       "      <td>Okay, so the binomial distribution, binomial ...</td>\n",
       "      <td>Okay, so back to the Twitter example, and the...</td>\n",
       "      <td>...</td>\n",
       "      <td>C major is a binomial distribution.  So let's...</td>\n",
       "      <td>Okay. Notation. So, P little P is what we alw...</td>\n",
       "      <td>used your specific number or whatever you got...</td>\n",
       "      <td>answers right or wrong. Number three is D. Nu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It has four requirements.  Number one, the pr...</td>\n",
       "      <td>Okay, now I'm just going to go ahead and hit ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our sort of working definition of what is an ...</td>\n",
       "      <td>Okay, so here's a good example for technology...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ocr_extracted_text</td>\n",
       "      <td>Method 2: Using Technology\\r\\n\\r\\nTechnologies...</td>\n",
       "      <td>be any whole number between 0 and n, inclusive...</td>\n",
       "      <td>The word success as used here is arbitrary and...</td>\n",
       "      <td>Solution\\r\\n\\r\\nb. Having concluded that the g...</td>\n",
       "      <td>* Binomial Probability Distribution BS\\r\\n—Abi...</td>\n",
       "      <td>ple:\\r\\n\\r\\nSolution\\r\\n\\r\\nAgain, it is very ...</td>\n",
       "      <td>Let’s develop the fo\\r\\n\\r\\ni\\r\\n\\r\\n+ On the ...</td>\n",
       "      <td>Key Concept\\r\\n\\r\\nThe focus of this section i...</td>\n",
       "      <td>Example: Twitter (7 or\\r\\n\\r\\nGiven that there...</td>\n",
       "      <td>...</td>\n",
       "      <td>®\\r\\n\\r\\nple:\\r\\n\\r\\nWhen an adult is randomly...</td>\n",
       "      <td>Sand F (success and failure) denote the two\\r\\...</td>\n",
       "      <td>X=number Frequency Relative freq. Theoretical ...</td>\n",
       "      <td>The Answers — how did you do?\\r\\n\\r\\n</td>\n",
       "      <td>2\\r\\n\\r\\n+ How many did you get right on the p...</td>\n",
       "      <td>ab\\r\\n\\r\\n* Binomial Probability Distribution\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pop quiz! i\\r\\n\\r\\n* Number your paper 1-10. T...</td>\n",
       "      <td>Solution\\r\\n\\r\\nThe Excel display on the next ...</td>\n",
       "      <td>We previously noted that between 1974 and 2011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llava_result</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The slide appears to be from an academic lect...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clip_text</td>\n",
       "      <td>Binomial probabilities, technology, spreadshee...</td>\n",
       "      <td>Bionomial probability distributions, notation,...</td>\n",
       "      <td>success probability p, binomial distribution, ...</td>\n",
       "      <td>Binomial distribution, Twitter data collection...</td>\n",
       "      <td>Binomial probability distribution, independent...</td>\n",
       "      <td>Twitter educational tool, share ideas/resource...</td>\n",
       "      <td>Probability calculation, probability of gettin...</td>\n",
       "      <td>Binomial probability distribution, discrete pr...</td>\n",
       "      <td>Twitter probability binomial formula adults kn...</td>\n",
       "      <td>...</td>\n",
       "      <td>Binomial distribution, probability of success ...</td>\n",
       "      <td>Binomial probability, notation P and Q, add up...</td>\n",
       "      <td>Probability theory observed vs theoretical fre...</td>\n",
       "      <td>Answers right or wrong, multiple-choice questi...</td>\n",
       "      <td>Pop quiz probability, theoretical vs. observed...</td>\n",
       "      <td>Binomial probability distribution, fixed numbe...</td>\n",
       "      <td>Probability calculator math Twitter adults hea...</td>\n",
       "      <td>Pop quiz! 10 questions, each with 4 choices (A...</td>\n",
       "      <td>Unusual event probability &lt;0.05, overtime coin...</td>\n",
       "      <td>NFL games overtime coin toss wins probability ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llm_long_summary</td>\n",
       "      <td>Method 2: Using Technology - The lecture discu...</td>\n",
       "      <td>The slide explains notation for binomial proba...</td>\n",
       "      <td>The concept of success as used here is arbitra...</td>\n",
       "      <td>The lecture discussed a binomial distribution ...</td>\n",
       "      <td>A binomial probability distribution results fr...</td>\n",
       "      <td>The lecture discussed the importance of using ...</td>\n",
       "      <td>The probability of getting exactly 3 right ans...</td>\n",
       "      <td>The binomial distribution, binomial probabilit...</td>\n",
       "      <td>Given that there is a 0.85 probability that a ...</td>\n",
       "      <td>...</td>\n",
       "      <td>The lecture discusses a binomial distribution ...</td>\n",
       "      <td>The lecture discussed binomial probability dis...</td>\n",
       "      <td>The slide presents a quiz on observed vs theor...</td>\n",
       "      <td>The lecture appears to be an assessment of und...</td>\n",
       "      <td>The lecture discussed how many students got ri...</td>\n",
       "      <td>The binomial probability distribution results ...</td>\n",
       "      <td>The lecture discussed calculators and mathemat...</td>\n",
       "      <td>Pop quiz! The lecture appears to be an academi...</td>\n",
       "      <td>The probability of 252 or more wins in 460 ove...</td>\n",
       "      <td>The lecture discussed NFL football games decid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>clip_text_embedding</td>\n",
       "      <td>tensor([[ 5.1960e-03,  5.5442e-02, -2.9637e-02...</td>\n",
       "      <td>tensor([[-2.2565e-02,  2.9402e-02, -6.4396e-02...</td>\n",
       "      <td>tensor([[ 1.6784e-02,  8.1404e-03, -2.5032e-02...</td>\n",
       "      <td>tensor([[ 1.0491e-02,  1.8044e-02, -1.6795e-02...</td>\n",
       "      <td>tensor([[-1.7205e-02,  3.4386e-02, -3.2124e-02...</td>\n",
       "      <td>tensor([[-1.0936e-02,  1.3913e-02, -9.5265e-03...</td>\n",
       "      <td>tensor([[ 8.6700e-03,  2.2865e-02, -1.4433e-02...</td>\n",
       "      <td>tensor([[-4.5463e-03,  1.6110e-02, -2.0650e-02...</td>\n",
       "      <td>tensor([[-1.4731e-03,  1.6395e-02, -2.2071e-02...</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor([[-8.6146e-03,  8.3915e-03, -3.9367e-02...</td>\n",
       "      <td>tensor([[ 5.3796e-03,  7.5618e-03, -2.3130e-02...</td>\n",
       "      <td>tensor([[-3.4614e-02,  2.4161e-02, -4.2352e-02...</td>\n",
       "      <td>tensor([[ 1.7163e-03,  8.9570e-03,  2.8305e-03...</td>\n",
       "      <td>tensor([[-1.5380e-02, -2.8845e-03, -7.9334e-03...</td>\n",
       "      <td>tensor([[-7.7309e-03,  1.8499e-02, -3.7852e-02...</td>\n",
       "      <td>tensor([[-1.2640e-03,  1.7357e-02, -1.5980e-02...</td>\n",
       "      <td>tensor([[ 8.0131e-03,  3.1325e-02,  7.0254e-03...</td>\n",
       "      <td>tensor([[-1.4216e-03, -2.0283e-02, -1.2192e-02...</td>\n",
       "      <td>tensor([[ 2.6404e-03,  5.7825e-03, -4.9042e-03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>clip_image_embedding</td>\n",
       "      <td>tensor([[-1.6722e-02,  1.2606e-01, -3.9023e-02...</td>\n",
       "      <td>tensor([[-1.1037e-02,  4.2648e-02, -1.3678e-02...</td>\n",
       "      <td>tensor([[ 1.1816e-02,  7.1861e-02, -3.5468e-05...</td>\n",
       "      <td>tensor([[-3.8834e-02,  3.5723e-02, -2.2615e-02...</td>\n",
       "      <td>tensor([[-1.7681e-02,  3.2758e-02, -1.0590e-02...</td>\n",
       "      <td>tensor([[-3.4967e-02,  1.1532e-02,  5.8089e-03...</td>\n",
       "      <td>tensor([[-3.4798e-02,  4.2907e-02, -1.9039e-02...</td>\n",
       "      <td>tensor([[-1.1023e-03,  4.4724e-02, -2.0930e-02...</td>\n",
       "      <td>tensor([[-2.4954e-02,  2.8499e-02, -1.2477e-02...</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor([[-1.1230e-02,  5.8981e-02,  2.2850e-02...</td>\n",
       "      <td>tensor([[ 5.0079e-03,  5.3988e-02, -3.3951e-02...</td>\n",
       "      <td>tensor([[ 5.8095e-03,  3.5173e-02, -1.5557e-02...</td>\n",
       "      <td>tensor([[-4.0929e-02,  4.3851e-02, -4.2689e-02...</td>\n",
       "      <td>tensor([[-1.9318e-02,  5.5134e-02, -6.3328e-02...</td>\n",
       "      <td>tensor([[-0.0119,  0.0322, -0.0126,  0.0180, -...</td>\n",
       "      <td>tensor([[ 2.1822e-02,  3.0071e-02,  9.9883e-03...</td>\n",
       "      <td>tensor([[ 8.8992e-04,  2.4442e-02, -6.5559e-02...</td>\n",
       "      <td>tensor([[-1.1211e-02,  7.0335e-02, -4.6952e-02...</td>\n",
       "      <td>tensor([[-1.7590e-02,  2.9331e-02, -3.1065e-02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>standard_text_embedding</td>\n",
       "      <td>tensor([-8.5635e-02, -8.2966e-02, -2.1982e-01,...</td>\n",
       "      <td>tensor([ 3.5344e-02,  3.0355e-02,  7.1971e-03,...</td>\n",
       "      <td>tensor([ 2.2932e-01, -1.0410e-01, -1.6513e-01,...</td>\n",
       "      <td>tensor([ 2.5956e-02, -1.6343e-01, -1.7768e-01,...</td>\n",
       "      <td>tensor([ 0.0245,  0.1300, -0.0587, -0.2838, -0...</td>\n",
       "      <td>tensor([-5.0663e-02, -1.9418e-01, -9.7258e-02,...</td>\n",
       "      <td>tensor([ 1.6039e-01, -1.6502e-01, -1.2744e-02,...</td>\n",
       "      <td>tensor([ 1.0485e-01, -5.6872e-02,  1.0654e-01,...</td>\n",
       "      <td>tensor([ 0.1081, -0.0920, -0.0017, -0.3471,  0...</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor([ 8.9046e-02,  1.7294e-02, -1.7561e-01,...</td>\n",
       "      <td>tensor([ 1.0437e-01, -7.3343e-03, -7.2010e-02,...</td>\n",
       "      <td>tensor([ 8.8447e-02, -1.1505e-02,  1.4052e-01,...</td>\n",
       "      <td>tensor([ 4.4614e-01, -2.1112e-01,  3.4753e-02,...</td>\n",
       "      <td>tensor([ 1.3634e-01, -3.0984e-02, -1.2701e-01,...</td>\n",
       "      <td>tensor([ 1.7352e-02,  5.3766e-02, -7.4951e-03,...</td>\n",
       "      <td>tensor([ 0.1213, -0.3609, -0.1789, -0.1939, -0...</td>\n",
       "      <td>tensor([ 0.0854,  0.0739,  0.3152, -0.0486, -0...</td>\n",
       "      <td>tensor([ 1.2005e-01, -2.1817e-01, -1.7670e-01,...</td>\n",
       "      <td>tensor([-8.3826e-02, -1.5241e-01, -4.6781e-02,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>extensive_text_embedding</td>\n",
       "      <td>tensor([-1.8073e-01,  1.8656e-02, -7.9516e-02,...</td>\n",
       "      <td>tensor([-0.0751, -0.1122, -0.1110, -0.2555, -0...</td>\n",
       "      <td>tensor([ 1.4936e-01, -6.9109e-03, -1.8281e-01,...</td>\n",
       "      <td>tensor([ 0.0142,  0.0795, -0.0884, -0.3639,  0...</td>\n",
       "      <td>tensor([ 6.5100e-02,  5.6179e-02, -9.4640e-02,...</td>\n",
       "      <td>tensor([-0.0523, -0.0989, -0.0447, -0.1362, -0...</td>\n",
       "      <td>tensor([ 0.4545, -0.3252, -0.0938, -0.2329, -0...</td>\n",
       "      <td>tensor([-1.3679e-01,  1.0031e-02, -3.8077e-02,...</td>\n",
       "      <td>tensor([-2.8476e-02, -7.4902e-02,  7.4877e-02,...</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor([ 1.2892e-02,  7.9248e-02, -9.0279e-02,...</td>\n",
       "      <td>tensor([-0.1565,  0.1090, -0.1335, -0.2257, -0...</td>\n",
       "      <td>tensor([ 0.0728, -0.0427, -0.1030, -0.0830,  0...</td>\n",
       "      <td>tensor([ 1.4151e-01,  9.5755e-02, -8.1816e-02,...</td>\n",
       "      <td>tensor([ 0.0550,  0.0839, -0.1225, -0.1555, -0...</td>\n",
       "      <td>tensor([ 0.0754,  0.1210, -0.0456, -0.2778, -0...</td>\n",
       "      <td>tensor([ 3.3183e-02, -6.4988e-02, -2.0071e-01,...</td>\n",
       "      <td>tensor([ 0.0975,  0.2250,  0.0211, -0.1165, -0...</td>\n",
       "      <td>tensor([ 1.3362e-01, -2.1329e-01, -2.5612e-01,...</td>\n",
       "      <td>tensor([ 0.0451, -0.1206, -0.2157, -0.2854, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ocr_text_embedding</td>\n",
       "      <td>tensor([-1.7012e-01, -2.3376e-02, -6.5044e-02,...</td>\n",
       "      <td>tensor([-3.3976e-02, -5.2518e-02, -8.7697e-02,...</td>\n",
       "      <td>tensor([ 4.7415e-02, -1.6109e-01, -2.1035e-01,...</td>\n",
       "      <td>tensor([-3.4410e-02,  1.3466e-02, -4.2267e-02,...</td>\n",
       "      <td>tensor([ 2.0410e-02,  1.5192e-01, -1.8803e-01,...</td>\n",
       "      <td>tensor([-3.4922e-02, -1.5838e-01,  1.7810e-02,...</td>\n",
       "      <td>tensor([ 9.2679e-02, -2.2400e-01, -7.5917e-02,...</td>\n",
       "      <td>tensor([-9.7531e-02,  1.1729e-02, -4.8321e-02,...</td>\n",
       "      <td>tensor([-8.1552e-02, -1.2928e-01,  5.2166e-02,...</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor([-4.0876e-02, -3.4146e-02, -1.3483e-03,...</td>\n",
       "      <td>tensor([-0.2049, -0.2461,  0.1274, -0.0621, -0...</td>\n",
       "      <td>tensor([-1.0861e-01,  8.0917e-02,  2.1251e-02,...</td>\n",
       "      <td>tensor([ 5.0100e-01,  4.2088e-02,  2.4783e-01,...</td>\n",
       "      <td>tensor([ 9.9797e-02, -1.2169e-01, -1.7010e-02,...</td>\n",
       "      <td>tensor([ 0.0068,  0.1454, -0.1894, -0.1955, -0...</td>\n",
       "      <td>tensor([ 2.2692e-01,  8.1784e-02,  2.3543e-02,...</td>\n",
       "      <td>tensor([-1.4790e-01,  1.9107e-01,  1.5564e-01,...</td>\n",
       "      <td>tensor([ 1.4016e-01, -2.5006e-02, -2.8691e-01,...</td>\n",
       "      <td>tensor([ 3.3652e-03, -1.7468e-01, -1.2044e-01,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>transcription_text_embedding</td>\n",
       "      <td>tensor([-1.1286e-01, -3.6851e-02, -7.1103e-02,...</td>\n",
       "      <td>tensor([-0.2527,  0.0917, -0.0312, -0.0377, -0...</td>\n",
       "      <td>tensor([-2.1935e-01, -1.0559e-01,  2.2703e-01,...</td>\n",
       "      <td>tensor([ 0.2134, -0.0186, -0.0360, -0.0049, -0...</td>\n",
       "      <td>tensor([ 0.0664, -0.1439,  0.0947,  0.1197,  0...</td>\n",
       "      <td>tensor([-0.0280, -0.4231, -0.0143, -0.2034, -0...</td>\n",
       "      <td>tensor([ 1.2617e-01, -2.9918e-01,  8.4224e-02,...</td>\n",
       "      <td>tensor([-0.0970, -0.1151,  0.1323, -0.1864,  0...</td>\n",
       "      <td>tensor([-0.0134, -0.2096,  0.1396, -0.3475,  0...</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor([ 0.1395, -0.0910,  0.0794, -0.3907, -0...</td>\n",
       "      <td>tensor([-4.8438e-03, -2.3021e-01,  3.5162e-02,...</td>\n",
       "      <td>tensor([ 0.2031, -0.2477, -0.3101, -0.1122,  0...</td>\n",
       "      <td>tensor([ 0.2544, -0.2140, -0.1404, -0.0309, -0...</td>\n",
       "      <td>tensor([ 2.2692e-01,  8.1784e-02,  2.3543e-02,...</td>\n",
       "      <td>tensor([ 1.4470e-01,  8.1109e-02, -7.0167e-02,...</td>\n",
       "      <td>tensor([ 1.3068e-02, -2.1405e-01,  3.1282e-02,...</td>\n",
       "      <td>tensor([ 2.2692e-01,  8.1784e-02,  2.3543e-02,...</td>\n",
       "      <td>tensor([-4.4180e-02, -3.0056e-01, -1.0255e-01,...</td>\n",
       "      <td>tensor([ 3.9551e-02, -1.2612e-01, -4.5963e-02,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>llava_text_embedding</td>\n",
       "      <td>tensor([-5.5286e-02, -5.7482e-02,  2.3002e-02,...</td>\n",
       "      <td>tensor([-0.0832,  0.0405,  0.0582, -0.1096,  0...</td>\n",
       "      <td>tensor([ 2.2215e-02, -1.0916e-01,  6.8139e-02,...</td>\n",
       "      <td>tensor([-1.5370e-01,  1.8803e-01,  4.5884e-02,...</td>\n",
       "      <td>tensor([-0.1649, -0.1063, -0.0328, -0.2106,  0...</td>\n",
       "      <td>tensor([-0.1994, -0.0615,  0.1766, -0.0913,  0...</td>\n",
       "      <td>tensor([-1.0690e-01, -2.1193e-01, -5.2433e-02,...</td>\n",
       "      <td>tensor([-9.6267e-02, -1.4498e-01, -4.5661e-02,...</td>\n",
       "      <td>tensor([ 4.6093e-03, -1.5259e-01,  1.8080e-02,...</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor([-0.0205, -0.0816,  0.0323, -0.0862,  0...</td>\n",
       "      <td>tensor([-1.5808e-01, -1.1350e-01,  4.9287e-02,...</td>\n",
       "      <td>tensor([-8.8247e-02, -4.4753e-02, -1.5758e-04,...</td>\n",
       "      <td>tensor([ 1.1979e-01, -1.1710e-01,  1.6335e-01,...</td>\n",
       "      <td>tensor([ 4.5333e-02, -1.0781e-01,  9.9918e-02,...</td>\n",
       "      <td>tensor([-1.6687e-01, -6.3698e-02,  5.2310e-02,...</td>\n",
       "      <td>tensor([-0.0403, -0.2010,  0.0270, -0.0218,  0...</td>\n",
       "      <td>tensor([ 1.2520e-02, -3.7925e-02,  1.5745e-01,...</td>\n",
       "      <td>tensor([ 2.0953e-02, -5.0737e-02, -1.3741e-01,...</td>\n",
       "      <td>tensor([-0.0257, -0.0809,  0.0372, -0.0814,  0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ocr_transcription_embedding</td>\n",
       "      <td>tensor([-0.1558, -0.0281, -0.0629, -0.2853,  0...</td>\n",
       "      <td>tensor([-2.8846e-02, -6.3873e-02, -1.1736e-01,...</td>\n",
       "      <td>tensor([ 0.0047, -0.1774, -0.1902, -0.1306, -0...</td>\n",
       "      <td>tensor([-0.0262, -0.0007, -0.0523, -0.2620, -0...</td>\n",
       "      <td>tensor([ 2.6093e-02,  1.2894e-01, -1.7960e-01,...</td>\n",
       "      <td>tensor([-4.6075e-02, -1.8089e-01,  4.9301e-03,...</td>\n",
       "      <td>tensor([ 0.0899, -0.2315, -0.0652, -0.2966, -0...</td>\n",
       "      <td>tensor([-1.3256e-01, -9.8598e-03,  4.0017e-03,...</td>\n",
       "      <td>tensor([-8.1063e-02, -1.5291e-01,  6.1723e-02,...</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor([-4.0876e-02, -3.4146e-02, -1.3483e-03,...</td>\n",
       "      <td>tensor([-1.8131e-01, -2.6552e-01,  1.4785e-01,...</td>\n",
       "      <td>tensor([ 0.0035, -0.0956, -0.0396, -0.1699,  0...</td>\n",
       "      <td>tensor([ 2.7631e-01, -1.1319e-01, -6.0725e-02,...</td>\n",
       "      <td>tensor([ 9.9797e-02, -1.2169e-01, -1.7010e-02,...</td>\n",
       "      <td>tensor([ 5.6154e-02,  1.4585e-01, -1.6363e-01,...</td>\n",
       "      <td>tensor([ 1.3068e-02, -2.1405e-01,  3.1282e-02,...</td>\n",
       "      <td>tensor([-1.4790e-01,  1.9107e-01,  1.5564e-01,...</td>\n",
       "      <td>tensor([ 1.4720e-01, -3.3228e-02, -2.8897e-01,...</td>\n",
       "      <td>tensor([ 3.3652e-03, -1.7468e-01, -1.2044e-01,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ocr_transcription_llava_embedding</td>\n",
       "      <td>tensor([-1.5069e-01, -4.7678e-02, -5.0572e-02,...</td>\n",
       "      <td>tensor([-4.1617e-03, -4.7293e-02, -7.4943e-02,...</td>\n",
       "      <td>tensor([ 5.7992e-03, -2.2144e-01, -1.7809e-01,...</td>\n",
       "      <td>tensor([ 1.6927e-02, -3.4209e-02, -5.8822e-02,...</td>\n",
       "      <td>tensor([ 0.0422,  0.1119, -0.1470, -0.1917,  0...</td>\n",
       "      <td>tensor([-4.6075e-02, -1.8089e-01,  4.9301e-03,...</td>\n",
       "      <td>tensor([ 0.0899, -0.2315, -0.0652, -0.2966, -0...</td>\n",
       "      <td>tensor([-1.2094e-01, -2.1370e-02, -2.5478e-04,...</td>\n",
       "      <td>tensor([-8.1063e-02, -1.5291e-01,  6.1723e-02,...</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor([-4.0876e-02, -3.4146e-02, -1.3483e-03,...</td>\n",
       "      <td>tensor([-1.8131e-01, -2.6552e-01,  1.4785e-01,...</td>\n",
       "      <td>tensor([ 0.0035, -0.0956, -0.0396, -0.1699,  0...</td>\n",
       "      <td>tensor([ 2.7631e-01, -1.1319e-01, -6.0725e-02,...</td>\n",
       "      <td>tensor([ 0.0938, -0.2037, -0.0279, -0.1850, -0...</td>\n",
       "      <td>tensor([ 5.6154e-02,  1.4585e-01, -1.6363e-01,...</td>\n",
       "      <td>tensor([ 1.0324e-03, -1.5084e-01,  6.6102e-02,...</td>\n",
       "      <td>tensor([-0.1330,  0.0448,  0.2359, -0.1617,  0...</td>\n",
       "      <td>tensor([ 1.4720e-01, -3.3228e-02, -2.8897e-01,...</td>\n",
       "      <td>tensor([ 3.3652e-03, -1.7468e-01, -1.2044e-01,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 90 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T11:08:53.369346Z",
     "start_time": "2024-07-13T11:08:53.114894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get llm_long_summary \n",
    "llm_long_summary = df_data_extensive.iloc[6].to_dict().values()\n",
    "\n",
    "# convert to list\n",
    "llm_long_summary = list(llm_long_summary)\n",
    "llm_long_summary = llm_long_summary[1:]\n",
    "logger.info(llm_long_summary)"
   ],
   "id": "36b7d851b10032d2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-07-13 13:08:53.350\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m7\u001B[0m - \u001B[1m['Method 2: Using Technology - The lecture discussed how technology can be used to find binomial probabilities. It mentioned that technologies such as spreadsheets and calculators can help in this process. The slide provided an example of a binomial probability, where there are two possible outcomes (success or failure) and the probability of each outcome is known. The slide also included a visual aid, which seems to be a screenshot of a spreadsheet with a formula for calculating the probability of a binomial event.', 'The slide explains notation for binomial probability distributions, which model the number of successes in a series of independent trials. The notation includes P(x) - probability of getting exactly x successes among n trials, where 0 ≤ x ≤ n. The probability of success (P) and failure (q) are also defined. The bionomial formula is given as P(x; n) = (n choose x) * p^x * (1 - p)^(n - x), where p is the probability of success on any single trial.', 'The concept of success as used here is arbitrary and does not necessarily represent something good. The probability of a binomial distribution should be consistent with the category being called a success. The lecture focused on the importance of understanding the context and main points discussed on the slides, highlighting the most important ideas and concepts.', 'The lecture discussed a binomial distribution example related to Twitter data collection or sentiment analysis. The procedure involves identifying values of n, x, p, and q. With five randomly selected adults, we have n=5, and we want the probability of exactly three who know what Twitter is, so x = 3.', \"A binomial probability distribution results from a procedure that meets four requirements: a fixed number of trials, independent trials, a constant probability of success on each trial, and the outcome of any individual trial does not affect the probabilities in other trials. The distribution is characterized by two parameters: n (the number of trials) and p (the probability of success on each trial). It's commonly used in fields like finance, marketing, and quality control.\", \"The lecture discussed the importance of using Twitter effectively in an educational context. It emphasized that x and p both refer to the same concept of success, with x being the number of people who have heard of Twitter and p being the probability that a specific person has heard of Twitter. The slide highlighted the benefits of using Twitter as a professional tool for educators, including sharing resources, connecting with peers, and learning from others' successes.\", 'The probability of getting exactly 3 right answers out of 10 questions is about 1/4 or approximately 0.2503, not exactly. There are many different ways to get 3 right answers, and each outcome has a specific probability. The total number of ways to get exactly 3 right answers is 120, which is calculated using the combination formula (10 choose 3).', 'The binomial distribution, binomial probability distribution is a specific discrete probability distribution. This chapter focuses on discrete probability distributions. The concept of probability is defined as the distribution and methods for finding probabilities. The probability of an event occurring can be determined by considering the number of favorable outcomes divided by the total number of possible outcomes. The binomial distribution is a statistical model used to describe the probability of a certain number of successes in a fixed number of trials, where each trial has only two possible outcomes: success or failure. Easy methods for finding the mean and standard deviation of a binomial distribution are presented. Interpreting probability values is important to determine whether events are significantly low or high.', 'Given that there is a 0.85 probability that a randomly selected adult knows what Twitter is, use the binomial probability formula to find the probability that when five adults are randomly selected, exactly three of them know what Twitter is. The concept being explained here is the calculation of probabilities from percentages, which is a fundamental skill in statistics and probability theory.', 'Pop quiz! The lecture started with a pop quiz, where students had to guess the answers without any questions. The lecturer forgot to bring the questions, but still wanted students to participate. The quiz was meant to be fun and interactive, and students were encouraged to just make their guesses and then grade their papers.', \"The slide appears to be part of a quiz activity where students are asked to observe and compare theoretical probabilities with actual observed frequencies. The table shows the frequency of different events or outcomes, with two columns for 'Observed' and 'Theoretical.' The slide seems to be summarizing a statistical analysis or comparison between observed and theoretical probabilities for different events or outcomes, possibly within an educational context such as a lecture on probability theory or statistics.\", 'The concept of success as used here is arbitrary and does not necessarily represent something good. The probability of a binomial distribution should be consistent with the category being called a success. When using a binomial probability distribution, ensure that x and p are consistent and refer to the same category being called a success.', 'The lecture discusses developing a formula to find the probability of getting exactly 3 right answers out of 4 on a pop quiz. The formula involves calculating the probability of getting the first three right as (1/4)^(3) and the probability of getting the last seven wrong as (3/4)^(7). The outcome is calculated as (1/4)^(3) * (3/4)^(7), which equals approximately 0.00208.', 'The lecture discussed Binomial Probability Distribution, which models the number of successes in a fixed number of independent trials with a constant probability of success for each trial. The concept was explained through an example of calculating the probability of obtaining exactly 4 successes in 10 trials with a 50% chance of success for each trial. The importance of independence and replacement in the trials was highlighted, as well as the application of this distribution to real-world scenarios.', 'The lecture discussed the use of Twitter for educational purposes. It highlighted the benefits of using Twitter as a platform for sharing ideas, asking questions, and learning from others. The slide presented three scenarios: scenario 1 where a teacher uses Twitter to solve problems or discuss with others; scenario 2 where they search for information related to their problem; and scenario 3 where they share resources or knowledge with others. The lecture emphasized that Twitter can be used as a valuable tool for teachers to enhance their teaching practices and engage with students or colleagues in a more interactive way.', \"The lecture discussed binomial probability distributions, explaining how to calculate the probability of getting exactly x successes among n trials. The notation includes X representing a specific number of successes in n trials, p representing the probability of success in one trial, and q representing the probability of failure in one trial. The probability distribution is represented by P(X=k) = C(n, k) * p^k * (1-p)^(n-k), where 'C' represents the binomial coefficient, 'p' is the probability of success, and 'k' is the number of successes. The total number of possible outcomes for a binomial experiment with n trials and k successes is given by C(n, k).\", 'The lecture discussed methods for finding binomial probabilities, specifically focusing on the binomial probability formula (P(x) = Cm,x) p* qh ™). The formula calculates the probability of success in a binomial experiment. The lecturer mentioned that there are two main methods: formula 1 and formula 2, which involve multiplying the number of successes by the probability of success and relating to the binomial distribution respectively. The slide included a mathematical expression for the binomial probability formula, highlighting its importance in the lecture.', \"The lecture discussed how many students got right on a pop quiz and calculated the probability of getting that many right by chance, using the formula. The class observed that nobody got 6 right, so they compared theoretical probabilities to results. The slide showed a question prompt asking for the number of right answers one would get on a pop quiz if they got right on 8 out of 10 questions and used the 'right answer' strategy to find the correct answer in 6 out of 7 questions instead of using the 'chance' strategy.\", \"The lecture appears to be about a pop quiz or exam, featuring a humorous take on the challenges of taking a test. The slide includes a scenario where the person has forgotten their number and is trying to remember it. The lecturer's tone is light-hearted and relatable, acknowledging the stress and frustration students face during exams. The main points discussed include the importance of remembering one's number, the need for honesty when grading one's own paper, and the humorous approach taken by the lecturer to make the experience more enjoyable.\", 'The lecture discussed micronutrients, specifically vitamins. Vitamins are organic substances that primarily function as coenzymes, aiding in chemical reactions. Most vitamins cannot be synthesized by the body and must be obtained from food, except for Vitamin D which requires sunlight for synthesis. In regions with low sunlight, Vitamin D deficiency is more common, and supplementation is often recommended. The lecture highlighted the importance of vitamins for bodily functions and disease prevention.', 'The lecture discussed methods for finding binomial probabilities using technology. The slide presented an example of how to calculate the probability of a binomial event using a specific method, displaying the result on the screen as a table. The lecturer also mentioned Excel as their favorite tool for finding binomial probabilities.', 'The probability of getting exactly three adults who know Twitter among five randomly selected adults is 0.138. The solution involves using the binomial probability formula, where n=5, x=3, p=0.614128, and q=0.0225. The result is rounded to three significant digits.', 'The lecture discussed methods for finding binomial probabilities, specifically Method 2: Using Technology. Technologies can be used to find binomial probabilities, with examples provided on the slide. The screen displays a list of binomial probabilities for each display, showing the probability distribution as a table.', 'The lecture focused on binomial probability distribution and methods for finding probabilities. The focus of this section is the binomial probability distribution and methods for finding probabilities. Easy methods for finding the mean and standard deviation of a binomial distribution are also presented. As in other sections, we stress the importance of interpreting probability values to determine whether events are significantly low or significantly high.', 'The lecture discusses relative frequency and theoretical probabilities, presenting a table comparing observed and theoretical probabilities of six events. The lecturer highlights the importance of understanding these concepts, particularly in statistics and probability.', 'The lecture appears to be an interactive presentation that involves a quiz with multiple-choice questions. The slide asks learners to number their paper 1-10, with each question having four options. The presence of a quiz suggests an interactive element in the lecture, which could be used to engage the audience and assess their understanding of the topic being discussed.', \"The lecture discussed a recent class who did an experiment on cent class. The results showed that some students scored 0, while others scored 4 or 8. The lecturer mentioned that they've already done this experiment and will be discussing the main points. The slide contains tables and figures showing the frequency of scores and relative frequencies. The LLAVA output suggests that the slide is part of an academic lecture on cent class, with a title and subtitle indicating the topic. The main content area likely includes the main body of text and accompanying figures or diagrams.\", 'The lecture discussed Twitter, specifically a solution to determine whether each of 5 randomly selected adults knows what Twitter is or not. Each trial has two categories of outcomes: the selected person knows what Twitter is or that person does not know what Twitter is. The probability of knowing what Twitter is remains the same for each of the five selected people at 0.85.', 'The slide explains the binomial probability distribution, a statistical model used to predict the number of successes in a fixed number of independent trials with a constant probability of success for each trial. The procedure requires four conditions: each trial has a success or failure outcome, trials are independent, the probability of success is constant, and there is a fixed number of trials. The slide provides an example of a binomial distribution with four trials, where each trial has a 50% chance of success or failure. A graph represents the binomial probability distribution, showing the probability of obtaining a certain number of successes in a fixed number of independent trials.', \"When sampling without replacement and the sample size is no more than 5% of the population, treat the selections as being independent (even though they are actually dependent). This guideline is often referred to as the '6% guideline for cumbersome calculations.' The slide also discusses confidence intervals, including a 95% confidence interval and a 100% confidence interval. The lecture appears to be discussing statistical methods and the use of confidence intervals when dealing with dependent events.\", 'When an adult is randomly selected with replacement, there is a 0.85 probability that this person knows what Twitter is. The procedure aims to find the probability that exactly 3 of 5 randomly selected adults know what Twitter is. This procedure results in a binomial distribution. The values of n (number of trials), x (number of successes), p (probability of success), and q (probability of failure) are not explicitly stated, but the example illustrates how to calculate probabilities using conditional probability formulas.', 'The lecture discusses binomial probabilities to find the sum of all probabilities for each value of x from 252 through 460, using technology instead of the formula. The notation for binomial probabilities involves n = 460, p=0.5, and q=0.5. The solution is not practical with the formula, as it would require applying it 209 times. Instead, technology is used to find the sum of all probabilities.', 'The lecture discussed the probability of 252 or more successes using the cumulative version of the formula. The lecturer used Excel to calculate the probability, applying the complement rule to find the probability of 251 or fewer wins. The result was approximately 0.976, which means the probability of 252 or more wins is about 0.0224. The lecture also touched on a hypothetical scenario related to overtime rules in football, discussing possession and scores during different overtime periods.', 'Between 1974 and 2011, there were 460 NFL football games decided in overtime, with 252 of them won by the team that won the overtime coin toss. The lecture discusses whether this result is equivalent to random chance or significantly high. It finds the probability of 252 wins or more in 460 games, assuming wins and losses are equally likely.', 'The lecture discussed a pop quiz, focusing on probability theory. The slide presented a question about getting questions right by chance, using the formula to find P(6), the probability of getting 6 right. The lecturer emphasized the importance of understanding chance and how it affects test results.', nan, 'The lecture discussed probability theory, focusing on the comparison between theoretical probabilities and observed frequencies. The slide presented a table showing the relative frequency of different events or outcomes, with two columns for observed and theoretical probabilities. The lecturer emphasized the importance of understanding probability concepts to predict outcomes and highlighted the difference between theoretical and observed probabilities.', \"Pop quiz! The lecture appears to be an interactive educational activity designed to test students' understanding of a topic or concept. Students are asked to number their answers for 10 questions, each with four choices (A, B, C, or D). The main instruction is to arrange the numbers from 1-9 in a specific order for each question.\", 'The lecture discussed probability theory using Twitter as an example. The slide presented a mathematical problem to calculate the probability of getting exactly three adults among five selected adults who know Twitter, given values of x, p, and q. The formula used was P(x) = (n choose k) * p^k * q^(n-k), where n is the total number of adults, k is the number of adults selected, and p and q are the probabilities of selecting an adult or not. The probability calculated was 0.138.', \"The binomial probability distribution results from a procedure that meets four requirements: the procedure has a fixed number of trials, the trials must be independent, the outcome of any individual trial doesn't affect the probabilities in other trials, and the probability of success on each trial is constant. The slide explains how to calculate the probability of obtaining a certain number of successes in a fixed number of trials using the binomial distribution formula.\", 'The concept of success as used here is arbitrary and does not necessarily represent something good. Either of the two possible categories may be called the success S, as long as its probability is identified as p. CAUTION: When using a binomial probability distribution, always ensure that x and p are consistent in the sense that they both refer to the same category being called a success.', 'When sampling without replacement and the sample size is no more than 5% of the population, treat the selections as being independent (even though they are actually dependent). This guideline helps simplify cumbersome calculations by assuming that events are independent when they are not. The selection process can be treated as if it were independent, even though the actual events are dependent.', 'A binomial probability distribution results from a procedure that meets four requirements: each trial must have all outcomes classified into exactly two categories, commonly referred to as success and failure. The probability of a success remains the same in all trials. This distribution describes the number of successes in a fixed number of independent Bernoulli trials, where each trial has only two possible outcomes: success or failure. It provides a clear definition and context for understanding this distribution.', 'The lecture discusses Twitter data analysis, specifically a solution that satisfies the requirements for a binomial distribution. The procedure involves 5 independent trials, where the probability of an adult knowing Twitter is not affected by results from other selected adults.', 'The binomial probability formula P(x) = (nCx) * p^x * q^(n-x) calculates the probability of success in a binomial experiment. The number of trials (n), number of successes (x), probability of success (p), and probability of failure (q) are used to determine the probability. The formula works for any value of x from 0 to n, with p and q staying constant throughout the problem. The focus is on finding the probability of a specific number of successes among n trials.', 'The lecture focused on binomial probability distribution and methods for finding probabilities. Easy methods for finding the mean and standard deviation of a binomial distribution were presented. The importance of interpreting probability values to determine whether events are significantly low or high was stressed.', 'The lecture discussed how many students got right on a pop quiz, using the formula to find the probability of getting that many right by chance. The class observed results were compared to theoretical probabilities. The lecturer asked students to pause and try the problem, then come back to compare notes.', 'The slide presents the results of a recent class experiment, showing the scores of individual students with relative frequency. The lecturer discussed the performance of students in a particular class, highlighting the scores ranging from 6 to 9. No additional context or analysis was provided beyond the raw data presented in the table.', 'The lecture discusses a procedure that results in a binomial distribution, with values of n=5, x=3, p, and q. The example uses Twitter as a source of data, collecting information on the frequency of certain words or phrases. The equation θ = 1/n * sum(λ_i) is used to estimate parameters based on observed values. The lecture highlights the importance of identifying these values in statistical analysis.', 'When an adult is randomly selected (with replacement), there is a 0.85 probability that this person knows what Twitter is. Suppose that we want to find the probability that exactly three of five randomly selected adults know what Twitter is. This procedure results in a binomial distribution with n=5, x=3, p=0.85, and g=1.', 'The binomial distribution is used to model the number of successes in a fixed number of trials. The notation P(x) represents the probability of getting exactly x successes among n trials, where p is the probability of success and q is the probability of failure in one trial. The binomial distribution is discrete, meaning it only takes on integer values for k, and the sum of all probabilities from 0 to n equals 1. The mean (μ) and variance (σ^2) can be calculated using the formulas: μ = np and σ^2 = np(1 - p).', \"The lecture discussed probability theory, specifically the binomial distribution. The slide presented an equation related to the probability of getting exactly 3 right out of 10 trials with a certain probability of success for each trial. The equation includes variables such as 'n', 'k', and 'p'. The presenter explained that there are multiple ways to get 3 right, but the probability of this exact outcome is approximately 0.00208. The slide also included a visual aid, possibly a graph or chart, related to the binomial distribution.\", 'Again, it is very important to be sure that x and p both refer to the same concept of “success.” In this example, we use x to count the number of people who know what Twitter is, so p must be the probability that the selected person knows what Twitter is. Therefore, x and p do use the same concept of success: knowing what Twitter is. The slide emphasizes that Twitter can be used as an educational tool, suggesting it for sharing information, updates on assignments, and communication among students and instructors. It provides a visual representation of the Twitter interface, which includes the search bar, tweet composition box, user profile icon, and timeline of tweets.', 'The lecture discussed Binomial Probability Distribution, a statistical method used to predict the outcome of a series of independent trials. The procedure has a fixed number of trials, which must be independent. The lecturer gave an example of asking five adults if they have heard of Twitter, illustrating how this concept applies in real-life scenarios.', 'The lecture discussed Method 2: Using Technology to find binomial probabilities. It explained that technologies can be used to calculate binomial probabilities, using a formula that includes the binomial coefficient, probability of success (p), and probability of failure (q). The example provided showed how to calculate binomial probabilities for n=5 and p = 0.85, with a table demonstrating the calculation process.', \"The lecture discussed Method 2: Using Technology to find binomial probabilities. The presenter explained how to use Excel's formula, `binom.dist(x, n, p, false)`, to calculate a binomial probability. The inputs are X (number of successes), n (number of trials), and p (probability of success). The formula is used to calculate the probability of exactly X successes in n trials, without making it cumulative. If the `false` input is changed to `true`, the formula calculates the probability of X or fewer successes.\", \"The slide appears to be from an academic lecture discussing organizational behavior and human resources management. The lecture covers various concepts, including employee motivation, team development, organizational culture, job satisfaction, turnover, leadership styles, performance, and job stress. The correct answers are based on theories such as Maslow's Hierarchy of Needs, Tuckman's model of team development, Herzberg's Two-Factor Theory, the expectancy theory of motivation, the Job Demands-Resources (JD-R) model, and others.\", 'The lecture discussed a method for calculating the probability of getting certain results based on the number of correct answers from a quiz or test. The speaker asked students to find the probability of getting 6 right out of 8, using the formula and comparing it to the observed results in class.', 'This lecture focused on probability distributions, specifically binomial, Poisson, and normal distributions. Binomial distribution models the number of successes in a fixed number of trials, while Poisson distribution models the number of events occurring within a fixed interval of time or space. Normal distribution is symmetric about the mean and often used to model continuous data that are normally distributed.', nan, 'The lecture discussed binomial probability distributions, focusing on notation and examples. The slide introduced the concept of binomial probability distributions, using mathematical notation to represent the probability of a success or failure in each trial. The notation included P(X=k), p, n, q=1-p, and the binomial coefficient. The example provided was flipping a coin n times and finding the probability that exactly k heads appear. The slide also featured a visual aid showing the probabilities for different numbers of successes out of n trials.', \"When sampling without replacement and the sample size is no more than 5% of the population, treat the selections as being independent (even though they are actually dependent). This guideline suggests that there is a specific threshold for when it's acceptable to treat dependent events as independent in certain statistical analyses. The lecturer emphasized that even though technically they're not independent, picking out a person and then not putting them back doesn't really change the probability of selecting another person with similar characteristics.\", \"The word 'success' as used here is arbitrary and does not necessarily represent something good. Either of the two possible categories may be called the success category, as long as its probability is identified as p. CAUTION: When using a binomial probability distribution, always be sure that x and p are consistent in the sense that they both refer to the same category being called a success.\", 'The lecture discussed two methods for finding binomial probabilities: Method 1 uses the formula P(x) = (nCx) * p^x * q^(n-x), where n is the total number of trials, x is the number of successful outcomes, p is the probability of success in each trial, and q is the probability of failure. Method 2 is a shortcut for small values of x, using the approximation formula: p^x * q^(n-x) = (p + q)^n. The lecture also mentioned that there are n-choose x ways to choose x successful outcomes from n total trials.', 'The lecture discusses biomimetic probability distributions, which model the number of successes in a series of independent trials with two possible outcomes. The notation P(x; n, p) = (nCx) * p^x * (1 - p)^(n - x) represents the probability mass function of a binomial distribution, where X is the specific number of successes, n is the total number of trials, and p is the probability of success. The lecture also covers examples of using this notation to calculate probabilities, such as finding the probability of getting exactly three questions right.', 'The slide discusses Twitter as an example of probability theory. The probability of success (getting a person who knows what Twitter is) for one selection is 0.85, while the probability of failure (not getting someone who knows what Twitter is) is 0.15.', 'The lecture discusses the overtime rule in football, explaining that the probability of 252 or more wins in 460 games is low (less than 0.05). This suggests that it is unlikely to get 252 or more wins by chance, and therefore, the team winning the overtime coin toss has a better chance of winning the game.', \"The binomial probability distribution results from a procedure that meets four requirements: each trial must have all outcomes classified into exactly two categories, commonly referred to as success and failure. The probability of a success remains the same in all trials. A binomial probability distribution is used to predict the outcome of an event that can result in either success or failure. It's based on the binomial theorem and is commonly used in fields like finance, marketing, and quality control.\", 'The lecture discussed a hypothetical scenario or problem set related to Twitter, possibly in the context of statistics, research methodology, or data analysis. The solution involves a binomial distribution and independent trials, with certain conditions specified for the number of trials and the independence of the results from other selected adults. The procedure satisfies the requirements for a binomial distribution, as shown below.', 'A binomial probability distribution results from a procedure that meets four requirements: a fixed number of trials, independent trials, a constant probability of success on each trial, and the outcome of any individual trial does not affect the probabilities in other trials. The distribution is characterized by two parameters: n (the number of trials) and p (the probability of success on each trial). It results in a discrete distribution, meaning that the outcomes are countable. The binomial distribution can be applied to real-world scenarios, such as a biomolecular assay with a 95% success rate.', 'When sampling without replacement and the sample size is no more than 5% of the population, treat the selections as being independent (even though they are actually dependent). This guideline applies to cumbersome calculations and ensures that the sample size is treated as exactly the same as the selection rate, despite their actual dependence.', \"The lecture discussed the concept of a 'Pop quiz!' and highlighted the importance of understanding certain concepts. The slide presented a question asking students to identify the difference between two blank spaces, suggesting an educational session where students are being tested on their knowledge. The lecturer emphasized the significance of grasping key ideas and concepts, but the specific context and content of the question were not visible in the provided image.\", 'The slide compares pop quizzes observed versus theoretical probabilities. The left column lists various numbers representing correct answers on a pop quiz, while the right column shows corresponding theoretical probabilities. The comparison may be used to evaluate the accuracy of theories or models and understand discrepancies between observed data and theoretical probabilities.', 'The slide presents a mathematical problem related to probability and combinatorics, illustrating how these concepts can be applied to understand the likelihood of certain outcomes in a given scenario, such as selecting a specific number of adults from a group of individuals on Twitter. The problem involves using the binomial probability formula to calculate the probability of getting exactly three adults among five randomly selected individuals. The solution is 0.138, indicating that the probability of this outcome is approximately 13.8%. The slide also references a paper or article discussing the application of combinatorial mathematics in real-world scenarios, specifically in the context of social media usage for scientific dissemination.', 'The results of a recent class who did this experiment show that 3 students got zero right, 4 students got one right, 9 students got two right, 5 students got three right, and 3 students got four or five right. The distribution appears to be binomial. The lecturer discussed the importance of understanding frequency distributions and how they can be used to analyze data.', \"The slide announces a pop quiz with 10 questions, each with four choices (A, B, C, or D). The quiz will be structured so that students must number their answers from 1 to 10. The figure on the slide appears to be a flowchart or decision-making process guiding the viewer through a series of steps or decisions. The lecture does not provide specific information about the content of the questions or the flowchart's decision points, but rather provides general information about the quiz structure.\", 'The slide presents a comparison between observed and theoretical probabilities for various demographic variables such as student number, gender, and age group. This type of analysis is commonly used in statistical studies to evaluate the accuracy of predictions made about certain populations based on observed data. The slide seems to be part of an educational presentation or lecture, possibly discussing concepts like hypothesis testing, chi-squared tests for goodness of fit, or other statistical methods that compare observed and expected frequencies.', 'When sampling without replacement and the sample size is no more than 5% of the size of the population, treat the selections as being independent (even though they are actually dependent). This guideline helps to provide a more accurate representation of the population by considering small samples or sampling without replacement. The concept of treating dependent events as independent can be applied in certain statistical contexts.', \"The concept of success as used here is arbitrary and does not necessarily represent something good. The binomial probability distribution is a statistical model used to describe the probability of obtaining a certain number of successes in a fixed number of independent trials, where each trial has only two possible outcomes: success or failure. When using this distribution, it's crucial to ensure that X and P are consistent throughout the problem, with X representing the number of successes and P being the probability of success. The lecture also highlights the importance of sticking to a specific category of outcomes and not switching between them. Additionally, the binomial distribution can be used to calculate probabilities for real-world scenarios.\", 'The lecture discusses a binomial distribution problem where an adult is randomly selected with replacement to find the probability that exactly three of five adults know what Twitter is. The procedure results in a binomial distribution, with n=5, x=3, p=0.85 (probability of success), and q=0.15 (probability of failure).', 'The lecture discussed binomial probability distributions, focusing on notation and formulas. The binomial distribution models the number of successes in a fixed number of independent Bernoulli trials, where each trial results in one of two possible outcomes: success or failure. The probability mass function (PMF) is given by the formula P(X=k) = (nCk) * p^k * (1-p)^(n-k), where n represents the number of trials, k represents the number of successes, and p represents the probability of success. The lecture also touched on the importance of notation, using P for the probability of success and Q for the probability of failure, with P + Q = 1.', 'The slide presents a quiz on observed vs theoretical probabilities, comparing actual frequencies with expected values. The lecturer discussed how to analyze and interpret data related to probability theory, highlighting the importance of understanding both observed and expected values. The main points include: 0.056 is the probability of getting non-right answers, 0.188 is the probability of getting one right answer, and there are differences between observed and expected probabilities.', 'The lecture appears to be an assessment of understanding on a particular topic or subject matter. The lecturer asked the class to answer multiple-choice questions, with options A, B, C, and D. The answers were not provided, but the lecturer asked the class to share how they did and counted the number of people who got zero right, one right, two right, etc.', 'The lecture discussed how many students got right on a pop quiz, finding the probability of getting that many right by chance using the formula. Theoretical probabilities were compared to observed results in class. The slide presented a method or strategy for improving performance on pop quizzes, emphasizing the importance of identifying problems and using the right approach.', \"The binomial probability distribution results from a procedure that meets four requirements: the procedure has a fixed number of trials, the trials must be independent, the outcome of any individual trial doesn't affect the probabilities in other trials, and the probability of success for each trial remains constant. The procedure is used to calculate the probability of obtaining a certain number of successes (or failures) in a series of independent trials. The binomial distribution is a discrete probability distribution that models the number of successes in a fixed number of trials with constant probability of success for each trial.\", 'The lecture discussed calculators and mathematical calculations. The presenter used a calculator to demonstrate how to calculate the probability of exactly 3 out of 5 adults having heard of Twitter. The calculation involved raising 0.85 to the power of 3, multiplying by 0.15 squared, and then subtracting 3 from 5. The result was approximately 0.138. The lecture likely focused on calculators or mathematical computations, possibly teaching mathematical concepts.', 'Pop quiz! The lecture appears to be an academic presentation discussing a pop quiz with 10 questions, each with four multiple-choice answers. The quiz requires students to number their papers from 1-10 and answer the questions. The slide does not provide specific details about the content of the quiz or the correct answers.', \"The probability of 252 or more wins in 460 overtime games is 0.0224 (rounded), which is low, indicating that it's unlikely to get 252 or more wins by chance. This suggests that the team winning the overtime coin toss has a better chance of winning the game. The working definition of an unusual event is anything with a probability of 0.05 or less, and since this probability is less than 0.05, we can conclude that 252 is unusually high. This may indicate that my assumption that wins and losses are equally likely was wrong, and maybe it's true that the team winning the overtime coin toss has an advantage in actually winning the game.\", 'The lecture discussed NFL football games decided in overtime between 1974 and 2011. It was found that 252 of these games were won by the team that won the overtime coin toss, which raises the question of whether this result is equivalent to random chance or significantly high. Assuming wins and losses are equally likely, the probability of 252 wins or more in 460 games was calculated.']\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T11:08:53.715706Z",
     "start_time": "2024-07-13T11:08:53.371397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get ocr_only\n",
    "# Since ocr_only embeddings can't be mapped to floats due to e-02, e-01, we're generating new embeddings \n",
    "ocr_only = df_data_extensive.iloc[3].to_dict().values()\n",
    "\n",
    "# convert to list\n",
    "ocr_only = list(ocr_only)\n",
    "\n",
    "ocr_only = ocr_only[1:]\n",
    "\n",
    "for i in ocr_only:\n",
    "    logger.info(i)"
   ],
   "id": "11272fdcf7b8bc3b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-07-13 13:08:53.626\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mMethod 2: Using Technology\r\n",
      "\r\n",
      "Technologies can be used to find binomial probabilities. The\r\n",
      "screen displays on the next slide list binomial probabilities for\r\n",
      "n=5 and p = 0.85, as in the previous example. Notice that in\r\n",
      "each display, the probability distribution is given as a table.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearton Education,\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.633\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mbe any whole number between 0 and n, inclusive\r\n",
      "Pp - probability of success in one of the n trials\r\n",
      "\r\n",
      "q- probability of failure in one of the n trials\r\n",
      "\r\n",
      "P(x) - probability of getting exactly x successes among\r\n",
      "\r\n",
      "the n trials\r\n",
      "\r\n",
      "CCopyiht © 2048, 2014, 2012 Pearson Education, Ine. Al Rights Reserved\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.633\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mThe word success as used here is arbitrary and does\r\n",
      "not necessarily represent something good. Either of the\r\n",
      "two possible categories may be called the success S as\r\n",
      "long as its probability is identified as p.\r\n",
      "\r\n",
      "CAUTION When using a binomial probability distribution,\r\n",
      "always be sure that x and p are consistent in the sense\r\n",
      "\r\n",
      "that they both refer to the same category being called a\r\n",
      "success.\r\n",
      "\r\n",
      "CCopyrit © 2038, 2014, 2012 Pearson Edueation, Ine, Al Rights Reserved\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.635\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mSolution\r\n",
      "\r\n",
      "b. Having concluded that the given procedure does\r\n",
      "result in a binomial distribution, we now proceed to\r\n",
      "identify the values of n, x, p, and q\r\n",
      "\r\n",
      "1. With five randomly selected adults, we have n= 5.\r\n",
      "\r\n",
      "2. We want the probability of exactly three who know what\r\n",
      "Twitter is, so x = 3.\r\n",
      "\r\n",
      "‘Copy © 2048, 2014, 2012 Pearson Education, Ine. Al Rights Reserved Oran\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.635\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1m* Binomial Probability Distribution BS\r\n",
      "—Abinomial probability distribution results from a\r\n",
      "procedure that meets these four requirements:\r\n",
      "The procedure has a fixed number of trials. (A\r\n",
      "trial is a single observation.)\r\n",
      "\r\n",
      "2. The trials must be independent, meaning that the\r\n",
      "‘outcome of any individual trial doesn't affect the\r\n",
      "probabilities in the other trials.\r\n",
      "\r\n",
      "‘Copy © 2048, 2014, 2012 Pearson Education, Inc. Al Rights Reserved\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.635\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mple:\r\n",
      "\r\n",
      "Solution\r\n",
      "\r\n",
      "Again, it is very important to be sure that x and p both refer\r\n",
      "to the same concept of “success.” In this example, we use x\r\n",
      "to count the number of people who know what Twitter is, so\r\n",
      "p must be the probability that the selected person knows\r\n",
      "what Twitter is. Therefore, x and p do use the same concept\r\n",
      "of success: knowing what Twitter is.\r\n",
      "\r\n",
      "Ccopyiht © 2088, 2014, 2012 Pearson Education,\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.638\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mLet’s develop the fo\r\n",
      "\r\n",
      "i\r\n",
      "\r\n",
      "+ On the pop quiz you took earlier, what is the probability of getting et\r\n",
      "exactly 3 right?\r\n",
      "\r\n",
      "+ One way to get three right is RRRWWWWWWW (R = right, W =\r\n",
      "wrong)\r\n",
      "\r\n",
      "+ The probability of this exact outcome is (2) (2) ~ 00208\r\n",
      "\r\n",
      "* But this isn't the only way to get three right. There are (10,3)\r\n",
      "120 different ways to get 3 right (choose 3 spots for the R's)\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Education, In. All Rights Reserved Orin\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.639\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mKey Concept\r\n",
      "\r\n",
      "The focus of this section is the binomial probability\r\n",
      "distribution and methods for finding probabilities.\r\n",
      "\r\n",
      "Easy methods for finding the mean and standard\r\n",
      "deviation of a binomial distribution are also presented.\r\n",
      "\r\n",
      "As in other sections, we stress the importance of\r\n",
      "interpreting probability values to determine whether\r\n",
      "events are significantly low or significantly high.\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.639\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mExample: Twitter (7 or\r\n",
      "\r\n",
      "Given that there is a 0.85 probability that a randomly\r\n",
      "selected adult knows what Twitter is, use the binomial\r\n",
      "probability formula to find the probability that when five\r\n",
      "adults are randomly selected, exactly three of them know\r\n",
      "what Twitter is. That is, apply the previous formula to find\r\n",
      "P(3) given that n = 5, x = 3, p = 0.85, and q=0.15.\r\n",
      "\r\n",
      "2018, 2014, 2012 Pearson Edueation, Ine. All\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.640\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mPop quiz!\r\n",
      "\r\n",
      "» Number your paper 1-10. There will be 10\r\n",
      "questions, each with four choices (A, B, C, or D).\r\n",
      "\r\n",
      "* Oops! | forgot to bring the questions. But we\r\n",
      "have to have the quiz today, so you'll just have to\r\n",
      "guess, Aaaaand GO!\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.640\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1m4\r\n",
      "X=number Frequency Relative req. Theoretical -\r\n",
      "taht prob,\r\n",
      "\r\n",
      "0 a a 056\r\n",
      "\r\n",
      "1 4 148 128\r\n",
      "\r\n",
      "2 9 333 282\r\n",
      "\r\n",
      "3 5 195 250\r\n",
      "\r\n",
      "4 3 i\" 146\r\n",
      "\r\n",
      "5 a 1 058\r\n",
      "\r\n",
      "6 Q 000 a6\r\n",
      "\r\n",
      "7 o 00 as\r\n",
      "\r\n",
      "8 9 60 004\r\n",
      "\r\n",
      "9 0 000 00003\r\n",
      "\r\n",
      "10 0 000 00004\r\n",
      "\r\n",
      "Copyright © 2018, 2014, 2012 Pearson Edveation, In, Al Rights Reserved\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.642\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mThe word success as used here is arbitrary and does\r\n",
      "not necessarily represent something good. Either of the\r\n",
      "two possible categories may be called the success S as\r\n",
      "long as its probability is identified as p.\r\n",
      "\r\n",
      "CAUTION When using a binomial probability distribution,\r\n",
      "always be sure that x and p are consistent in the sense\r\n",
      "\r\n",
      "that they both refer to the same category being called a\r\n",
      "success.\r\n",
      "\r\n",
      "© 2018, 2018, 2012 Pearson Education, Inc. Al Rights Reserves\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.643\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1m's develop t mula\r\n",
      "\r\n",
      "+ On the pop quiz you took earlier, what is the probability of getting\r\n",
      "exactly 3 right?\r\n",
      "\r\n",
      "+ One way to get three right is RRRWWWWWWW (R = right, W =\r\n",
      "wrong)\r\n",
      "\r\n",
      "+ The probability of this exact outcome is (2) (2) ~ .00208\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Education, Inc.All Rights Reserved Orann\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.643\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mProba\r\n",
      "\r\n",
      "* Binomial Probability Distribution\r\n",
      "—Abinomial probability distribution results from a\r\n",
      "\r\n",
      "copyiht\r\n",
      "\r\n",
      "procedure that meets these four requirements:\r\n",
      "\r\n",
      "3. Each trial must have all outcomes classified into\r\n",
      "exactly two categories, commonly referred to as\r\n",
      "success and failure.\r\n",
      "\r\n",
      "4. The probability of a success remains the same in\r\n",
      "all trials.\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.645\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mSolution\r\n",
      "\r\n",
      "Again, it is very important to be sure that x and p both refer\r\n",
      "to the same concept of “success.” In this example, we use x\r\n",
      "to count the number of people who know what Twitter is, so\r\n",
      "p must be the probability that the selected person knows\r\n",
      "what Twitter is. Therefore, x and p do use the same concept\r\n",
      "of success: knowing what Twitter is\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Education, Inc, All Rights Reserved Orne\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.645\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mX-a specific number of successes in n trials, so x can\r\n",
      "be any whole number between 0 and n, inclusive\r\n",
      "\r\n",
      "p- probability of success in one of the n trials\r\n",
      "q- probability of failure in one of the n trials\r\n",
      "\r\n",
      "P(x) - probability of getting exactly x successes among\r\n",
      "the n trials\r\n",
      "\r\n",
      "CCopyiht © 2088, 2014, 2012 Pearson Education, Inc. Al Rights Reserved @ arson\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.645\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mMethod 1: Binomial Probability Formula\r\n",
      "\r\n",
      "P(x) = Cm, x) p* qh ™\r\n",
      "forx=0,1,2,...,n\r\n",
      "where\r\n",
      "n= number of trials\r\n",
      "x = number of successes among m trials\r\n",
      "Pp = probability of success in any one trial\r\n",
      "q = probability of failure in any one trial (q = 1 - p)\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Education, In. Al Rights Reserved Oranwn\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.645\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1m+ How many did you get right on the pop quiz? Find the\r\n",
      "probability of getting that many right by chance, using the\r\n",
      "formula. If you got three right, we already did that\r\n",
      "problem, so find P(6) instead, the probability of getting 6\r\n",
      "right. We'll compare these theoretical probabilities to the\r\n",
      "results we observed in our class.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Edueation, Inc.All Rights Reserved pearson\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.648\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mPop quiz! Ee\r\n",
      "\r\n",
      "» Number your paper 1-10. There will be 10 4\r\n",
      "questions, each with four choices (A, B, C, or D).\r\n",
      "\r\n",
      "* Oops! | forgot to bring the questions. But we\r\n",
      "have to have the quiz today, so you'll just have to\r\n",
      "guess, Aaaaand GO!\r\n",
      "\r\n",
      "+ Alldone? | feel bad about that “forgot the\r\n",
      "questions’ thing, so I'll let you grade your own\r\n",
      "paper. (Be honest!) Here are the answers..\r\n",
      "\r\n",
      "CCopyrit © 2038, 2014, 2012 Pearson Eaueation, Inc.All Rights Reserved rare\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.648\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mnan\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.648\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mMetr\r\n",
      "\r\n",
      "rob\r\n",
      "\r\n",
      "Method 2: Using Technology\r\n",
      "\r\n",
      "Technologies can be used to find binomial probabilities. The\r\n",
      "screen displays on the next slide list binomial probabilities for\r\n",
      "n=5 and p = 0.85, as in the previous example. Notice that in\r\n",
      "each display, the probability distribution is given as a table.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 PeartonEdueation, Oran\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.650\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mSolution\r\n",
      "\r\n",
      "Using the given values of n, x, p, and q in the binomial\r\n",
      "probability formula, we get\r\n",
      "\r\n",
      "5!\r\n",
      "P(3)=\r\n",
      "= Gaya\r\n",
      "\r\n",
      "85°.0.15°*\r\n",
      "\r\n",
      "= 2! .0.614128-0.0225\r\n",
      "2131\r\n",
      "\r\n",
      "= (10)(0.614125)(0.0225)\r\n",
      "= 0.138178\r\n",
      "= 0.138 (round to three significant digits)\r\n",
      "The probability of getting exactly three adults who know\r\n",
      "\r\n",
      "Twitter among five randomly selected adults is 0.138.\r\n",
      "\r\n",
      "All RightsReserved parse,\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1momial\r\n",
      "\r\n",
      "Method 2: Using Technology\r\n",
      "\r\n",
      "Technologies can be used to find binomial probabilities. The\r\n",
      "screen displays on the next slide list binomial probabilities for\r\n",
      "n=5 and p = 0.85, as in the previous example. Notice that in\r\n",
      "each display, the probability distribution is given as a table.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Edveation, Inc.All Rights Reserved Oranen\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mKey Concept\r\n",
      "\r\n",
      "il\r\n",
      "\r\n",
      "The focus of this section is the binomial probability\r\n",
      "distribution and methods for finding probabilities.\r\n",
      "\r\n",
      "Easy methods for finding the mean and standard\r\n",
      "deviation of a binomial distribution are also presented.\r\n",
      "\r\n",
      "As in other sections, we stress the importance of\r\n",
      "interpreting probability values to determine whether\r\n",
      "events are significantly low or significantly high.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Edueation, In. Al Rights Reserved Orr\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mRelative freq. Theoretical\r\n",
      "prob.\r\n",
      "\r\n",
      "0 3 att 056\r\n",
      "\r\n",
      "1 4 148 188\r\n",
      "\r\n",
      "2 9 333 282\r\n",
      "\r\n",
      "3 5 185 250\r\n",
      "\r\n",
      "4 3 itt 446\r\n",
      "\r\n",
      "5 3 oa 058\r\n",
      "\r\n",
      "6 0 (000 016\r\n",
      "\r\n",
      "7 0 000 003\r\n",
      "\r\n",
      "8 ° ‘000 (0004\r\n",
      "\r\n",
      "9 0 000 00003\r\n",
      "\r\n",
      "10 0 000 (000001\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Edueaion, In, Al Rights Reserved @Psrwn\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mPop quiz! =_\r\n",
      "\r\n",
      "+ Number your paper 1-10. There will be 10\r\n",
      "questions, each with four choices (A, B, C, or D).\r\n",
      "\r\n",
      "2018, 2018, 2012 Pearson Ecucation, Ine. Al Rights Reserved Oranen\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mcent class\r\n",
      "\r\n",
      "+ Here are the results for a recent class who did this experiment. The =\r\n",
      "number of students with each score is given, along with the relative\r\n",
      "\r\n",
      "f\r\n",
      "requency. “x= number right Frequency Relative freq.\r\n",
      "\r\n",
      "0 3 Tr\r\n",
      "148\r\n",
      "333\r\n",
      "185\r\n",
      "44\r\n",
      "41\r\n",
      "(000\r\n",
      ".000\r\n",
      "(000\r\n",
      "000\r\n",
      "(000\r\n",
      "\r\n",
      "4\r\n",
      "8\r\n",
      "5\r\n",
      "3\r\n",
      "3\r\n",
      "0\r\n",
      "0\r\n",
      "0\r\n",
      "°\r\n",
      "o\r\n",
      "\r\n",
      "0\r\n",
      "\r\n",
      "CCopyiat © 2048, 2014, 2012 Pearson Education,\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mle: Twitter\r\n",
      "\r\n",
      "Solution\r\n",
      "\r\n",
      "3. Each of the 5 trials has two categories of outcomes:\r\n",
      "The selected person knows what Twitter is or that\r\n",
      "person does not know what Twitter is.\r\n",
      "\r\n",
      "4. For each randomly selected adult, there is a 0.85\r\n",
      "probability that this person knows what Twitter is, and\r\n",
      "that probability remains the same for each of the five\r\n",
      "selected people.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Education, Inc.All RightsReserved Oranen\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1m| Probabi\r\n",
      "\r\n",
      "* Binomial Probability Distribution\r\n",
      "\r\n",
      "—Abinomial probability distribution results from a\r\n",
      "procedure that meets these four requirements:\r\n",
      "\r\n",
      "3. Each trial must have all outcomes classified into\r\n",
      "exactly two categories, commonly referred to as\r\n",
      "success and failure.\r\n",
      "\r\n",
      "4. The probability of a success remains the same in\r\n",
      "all trials.\r\n",
      "\r\n",
      "‘Copy © 2038, 2014, 2012 Pearson Education, Inc. Al Rights Reserved Orinn\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1m5% Guideline for Cumbersome Calculations\r\n",
      "\r\n",
      "When sampling without replacement and the sample\r\n",
      "size is no more than 5% of the size of the population,\r\n",
      "treat the selections as being independent (even though\r\n",
      "they are actually dependent).\r\n",
      "\r\n",
      "CCopyiht © 2088, 2014, 2012 Pearson Education, Ine. Al Rights Reserved\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mTwit\r\n",
      "\r\n",
      "Tter (1 of\r\n",
      "\r\n",
      "When an adult is randomly selected (with replacement), [ug\r\n",
      "there is a 0.85 probability that this person knows what\r\n",
      "‘Twitter is (based on results from a Pew Research\r\n",
      "\r\n",
      "Center survey). Suppose that we want to find the\r\n",
      "\r\n",
      "probability that exactly three of five randomly selected\r\n",
      "adults know what Twitter is.\r\n",
      "\r\n",
      "a. Does this procedure result in a binomial distribution?\r\n",
      "\r\n",
      "b. If this procedure does result in a binomial distribution,\r\n",
      "identify the values of n, x, p, and g.\r\n",
      "\r\n",
      "copyright © 2038, 2014, 2012 Pearson Education, I\r\n",
      "\r\n",
      "Al Rights Reserves rere\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mSolution ‘\r\n",
      "\r\n",
      "Using the notation for binomial probabilities, we have n = 460,\r\n",
      "p=0.5, q=0.5, and we want to find the sum of all\r\n",
      "probabilities for each value of x from 252 through 460. The\r\n",
      "formula is not practical here, because we would need to apply\r\n",
      "it 209 times—we don't want to go there. Table A-1 (Binomial\r\n",
      "Probabilities) doesn't apply because n = 460, which is way\r\n",
      "beyond the scope of that table. Instead, we wisely choose to\r\n",
      "use technology.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Eeuca\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1m.S77S7AOE] puting \"tue\" atthe end gives P25 or fewer wins)\r\n",
      "0,022428837Thsisthe probably ofthe complement, 252 or more\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Education, In, All Rights Reserved Oranen\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mFoo =\r\n",
      "We previously noted that between 1974 and 2011, there\r\n",
      "were 460 NFL football games decided in overtime, and\r\n",
      "252 of them were won by the team that won the\r\n",
      "overtime coin toss. Is the result of 252 wins in the 460\r\n",
      "games equivalent to random chance, or is 252 wins\r\n",
      "significantly high? We can answer that question by\r\n",
      "finding the probability of 252 wins or more in 460\r\n",
      "games, assuming that wins and losses are equally\r\n",
      "\r\n",
      "likely.\r\n",
      "\r\n",
      "* © 2018, 2018, 2012 Pearson Edueaton Ine.\r\n",
      "\r\n",
      "Al Rights Reserve Oranwn\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mpop\r\n",
      "oF\r\n",
      "\r\n",
      "+ How many did you get right on the pop quiz? Find the\r\n",
      "probability of getting that many right by chance, using the\r\n",
      "formula. If you got three right, we already did that\r\n",
      "problem, so find P(6) instead, the probability of getting 6\r\n",
      "right. We'll compare these theoretical probabilities to the\r\n",
      "results we observed in our class.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearton Eda,\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mThe Answers — how did you do?\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1m1 vs. theoretical\r\n",
      "\r\n",
      "Relative freq. Theoretical\r\n",
      "prob.\r\n",
      "\r\n",
      "0 3 it 056\r\n",
      "\r\n",
      "1 4 148 188\r\n",
      "\r\n",
      "2 9 333 282\r\n",
      "\r\n",
      "3 5 185 250\r\n",
      "\r\n",
      "4 3 itt 446\r\n",
      "\r\n",
      "5 3 oa) 058\r\n",
      "\r\n",
      "6 0 000 016\r\n",
      "\r\n",
      "7 ° 000 003\r\n",
      "\r\n",
      "8 ° ‘000 (0004\r\n",
      "\r\n",
      "9 0 000 00003\r\n",
      "\r\n",
      "10 0 (000 (000001\r\n",
      "\r\n",
      "CCopyiht © 2048, 2014, 2012 Pearson Education, Inc, Al Rights Reserved\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mPop quiz! =\r\n",
      "\r\n",
      "Number your paper 1-10. There will be 10\r\n",
      "questions, each with four choices (A, B, C, or D).\r\n",
      "\r\n",
      "I Righe Reserves Oran\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mExample: Twitter (ors =\r\n",
      "\r\n",
      "Solution\r\n",
      "Using the given values of n, x, p, and q in the binomial\r\n",
      "probability formula, we get\r\n",
      "\r\n",
      "!\r\n",
      "P(3) => 85°.0.15°°\r\n",
      "6-331\r\n",
      "\r\n",
      "= 2! .0.614128-0.0225\r\n",
      "2131\r\n",
      "\r\n",
      "= (10)(0.614125)(0.0225)\r\n",
      "= 0.138178\r\n",
      "= 0.138 (round to three significant digits)\r\n",
      "\r\n",
      "The probability of getting exactly three adults who know\r\n",
      "Twitter among five randomly selected adults is 0.138.\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.667\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1m* Binomial Probability Distribution\r\n",
      "—Abinomial probability distribution results from a\r\n",
      "procedure that meets these four requirements:\r\n",
      "\r\n",
      "The procedure has a fixed number of trials. (A\r\n",
      "trial is a single observation.)\r\n",
      "\r\n",
      "2. The trials must be independent, meaning that the\r\n",
      "outcome of any individual trial doesn't affect the\r\n",
      "probabilities in the other trials.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 PeartonEdeation,\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.668\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mThe word success as used here is arbitrary and does\r\n",
      "not necessarily represent something good. Either of the\r\n",
      "two possible categories may be called the success S as\r\n",
      "long as its probability is identified as p.\r\n",
      "\r\n",
      "CAUTION When using a binomial probability distribution,\r\n",
      "always be sure that x and p are consistent in the sense\r\n",
      "\r\n",
      "that they both refer to the same category being called a\r\n",
      "success.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Education, I\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.668\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1m5% Guideline for Cumbersome Calculations\r\n",
      "\r\n",
      "When sampling without replacement and the sample\r\n",
      "size is no more than 5% of the size of the population,\r\n",
      "treat the selections as being independent (even though\r\n",
      "they are actually dependent).\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Edueation, Inc.All Rights Reserved Oran\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.668\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mlal Pro\r\n",
      "\r\n",
      "* Binomial Probability Distribution\r\n",
      "\r\n",
      "— Abinomial probability distribution results from a\r\n",
      "procedure that meets these four requirements:\r\n",
      "3. Each trial must have all outcomes classified into\r\n",
      "exactly two categories, commonly referred to as.\r\n",
      "success and failure.\r\n",
      "\r\n",
      "4. The probability of a success remains the same in\r\n",
      "all trials.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearton Education, Oran\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.668\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mSolution\r\n",
      "\r\n",
      "a. This procedure does satisfy the requirements for a\r\n",
      "binomial distribution, as shown below.\r\n",
      "\r\n",
      "1, The number of trials (5) is fixed\r\n",
      "\r\n",
      "2. The 5 trials are independent because the probability of\r\n",
      "any adult knowing Twitter is not affected by results from\r\n",
      "other selected adults.\r\n",
      "\r\n",
      "Orearson\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.668\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mMethod 1: Binomial Probability Formula\r\n",
      "\r\n",
      "P(x) = C(m, x) p* qh ™\r\n",
      "forx=0,1,2,...,n\r\n",
      "where\r\n",
      "n= number of trials\r\n",
      "x = number of successes among n trials\r\n",
      "Pp = probability of success in any one trial\r\n",
      "q = probability of failure in any one trial (q = 1 - p)\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Education, In. Al Rights Reserved\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.673\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mKey Concept =\r\n",
      "\r\n",
      "The focus of this section is the binomial probability\r\n",
      "distribution and methods for finding probabilities.\r\n",
      "\r\n",
      "Easy methods for finding the mean and standard\r\n",
      "deviation of a binomial distribution are also presented.\r\n",
      "\r\n",
      "As in other sections, we stress the importance of\r\n",
      "interpreting probability values to determine whether\r\n",
      "events are significantly low or significantly high.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Edveation, Inc.All Rights Reserved rar\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.673\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1m+ How many did you get right on the pop quiz? Find the\r\n",
      "probability of getting that many right by chance, using the\r\n",
      "formula. If you got three right, we already did that\r\n",
      "problem, so find P(6) instead, the probability of getting 6\r\n",
      "right. We'll compare these theoretical probabilities to the\r\n",
      "results we observed in our class.\r\n",
      "\r\n",
      "CCopyiht © 2088, 2014, 2012 Pearson Education, Ine, Al Rights Reserved Oran\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.675\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mResults for a recent class\r\n",
      "\r\n",
      "+ Here are the results for a recent class who did this experiment. The\r\n",
      "number of students with each score is given, along with the relative\r\n",
      "\r\n",
      "frequen i\r\n",
      "eauency. “x= numberright Frequency Relative freq.\r\n",
      "\r\n",
      ") 3 Ta\r\n",
      "148\r\n",
      "333\r\n",
      "185\r\n",
      "44\r\n",
      "a1\r\n",
      "(000\r\n",
      ".000\r\n",
      "(000\r\n",
      ".000\r\n",
      "(000\r\n",
      "\r\n",
      "4\r\n",
      "8\r\n",
      "5\r\n",
      "3\r\n",
      "3\r\n",
      ")\r\n",
      "0\r\n",
      "0\r\n",
      "0\r\n",
      "O\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.676\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mSolution\r\n",
      "\r\n",
      "b. Having concluded that the given procedure does\r\n",
      "result in a binomial distribution, we now proceed to\r\n",
      "identify the values of n, x, p, and q\r\n",
      "\r\n",
      "1. With five randomly selected adults, we have n= 5.\r\n",
      "\r\n",
      "2. We want the probability of exactly three who know what\r\n",
      "Twitter is, so x = 3.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Education, Inc.All Rights Reserved Oran\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.677\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mWhen an adult is randomly selected (with replacement),\r\n",
      "there is a 0.85 probability that this person knows what\r\n",
      "Twitter is (based on results from a Pew Research\r\n",
      "Center survey). Suppose that we want to find the\r\n",
      "probability that exactly three of five randomly selected\r\n",
      "adults know what Twitter is.\r\n",
      "\r\n",
      "a. Does this procedure result in a binomial distribution?\r\n",
      "\r\n",
      "b. If this procedure does result in a binomial distribution,\r\n",
      "identify the values of n, x, p, and g.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Edueation, In, Al Rights Reserved Oranwn\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.677\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mX - a specific number of successes in n trials, so x can\r\n",
      "be any whole number between 0 and n, inclusive\r\n",
      "\r\n",
      "p- probability of success in one of the n trials\r\n",
      "q- probability of failure in one of the n trials\r\n",
      "\r\n",
      "P(x) - probability of getting exactly x successes among\r\n",
      "the n trials\r\n",
      "\r\n",
      "copyright © 2038, 2014, 2012 Pearson Education, In. Al\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.678\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mCopyright © 2038, 2014, 2012 Pearton Eda,\r\n",
      "\r\n",
      "On the pop quiz you took earrier, what is the probability of getting\r\n",
      "exactly 3 right?\r\n",
      "\r\n",
      "(One way to get three right is RRRWWWWWWW (R = right, W =\r\n",
      "wrong)\r\n",
      "\r\n",
      "The probability of this exact outcome is (*) (2) ~.00208,\r\n",
      "\r\n",
      "But this isn't the only way to get three right. There are C(10,3) =\r\n",
      "120 different ways to get 3 right (choose 3 spots for the R's)\r\n",
      "\r\n",
      "Al RightsReserved raven\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.680\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mExample: Twitter «\r\n",
      "\r\n",
      "Solution\r\n",
      "\r\n",
      "Again, it is very important to be sure that x and p both refer\r\n",
      "to the same concept of “success.” In this example, we use x\r\n",
      "to count the number of people who know what Twitter is, so\r\n",
      "p must be the probability that the selected person knows\r\n",
      "what Twitter is. Therefore, x and p do use the same concept\r\n",
      "of success: knowing what Twitter is.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Education, Inc.All Rights Reserved rare\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.680\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1m1a\r\n",
      "\r\n",
      "* Binomial Probability Distribution\r\n",
      "—Abinomial probability distribution results from a\r\n",
      "procedure that meets these four requirements:\r\n",
      "The procedure has a fixed number of trials. (A\r\n",
      "trial is a single observation.)\r\n",
      "\r\n",
      "2. The trials must be independent, meaning that the\r\n",
      "outcome of any individual trial doesn’t affect the\r\n",
      "probabilities in the other trials.\r\n",
      "\r\n",
      "CCopyiht © 2048, 2014, 2012 Pearson Education, Ine. Al Rights Reserved\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.681\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mMethod 2: Using Technology\r\n",
      "\r\n",
      "Technologies can be used to find binomial probabilities. The\r\n",
      "screen displays on the next slide list binomial probabilities for\r\n",
      "n=5 and p = 0.85, as in the previous example. Notice that in\r\n",
      "each display, the probability distribution is given as a table.\r\n",
      "\r\n",
      "‘Copy © 2088, 2014, 2012 Pearson Education,\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.682\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mMethod 2: Using Technology Ye\r\n",
      "\r\n",
      "7189/84 Plus CE Excel\r\n",
      "Pte)\r\n",
      "7386.05\r\n",
      "\r\n",
      "x Hi] =binom.dist(x, n, p, false)\r\n",
      "\r\n",
      "CCopyriht © 2038, 2014, 2012 Pearson Education, I\r\n",
      "\r\n",
      "Oversee\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.683\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mThe Answers — how did you do?\r\n",
      "\r\n",
      "‘\r\n",
      "8\r\n",
      "D\r\n",
      "8\r\n",
      "\r\n",
      "5.8\r\n",
      "\r\n",
      "6.0\r\n",
      "D\r\n",
      "c\r\n",
      "\r\n",
      "9.¢\r\n",
      "\r\n",
      "0.8\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.684\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1m+ How many did you get right on the pop quiz? Find the\r\n",
      "probability of getting that many right by chance, using the\r\n",
      "formula. If you got three right, we already did that\r\n",
      "problem, so find P(6) instead, the probability of getting 6\r\n",
      "right. We'll compare these theoretical probabilities to the\r\n",
      "results we observed in our class.\r\n",
      "\r\n",
      "copy © 2088, 2014, 2012 Pearson Education,\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.684\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mProba\r\n",
      "\r\n",
      "5-1 Probability Distributions\r\n",
      "5-2 Binomial Probability Distributions\r\n",
      "5-3 Poisson Probability Distributions\r\n",
      "\r\n",
      "2018, 2014, 2012 Pearzon Edveation, ne Al RightsReserved\r\n",
      "\r\n",
      "copyriht\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.685\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mnan\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.687\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mONS (1 of 3\r\n",
      "\r\n",
      "Sand F (success and failure) denote the two\r\n",
      "possible categories of all outcomes.\r\n",
      "\r\n",
      "P(S)=p (p = probability of a success)\r\n",
      "P(F)=1-p=q (q= probability of a failure)\r\n",
      "\r\n",
      "n the fixed number of trials\r\n",
      "\r\n",
      "CCopyrit © 2038, 2014, 2012 Pearson Edueation, In. Al Rights Reserved\r\n",
      "\r\n",
      "Orearson,\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.688\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1m5% Guideline for Cumbersome Calculations\r\n",
      "\r\n",
      "When sampling without replacement and the sample\r\n",
      "size is no more than 5% of the size of the population,\r\n",
      "treat the selections as being independent (even though\r\n",
      "they are actually dependent).\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.688\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mThe word success as used here is arbitrary and does\r\n",
      "not necessarily represent something good. Either of the\r\n",
      "two possible categories may be called the success S as\r\n",
      "long as its probability is identified as p.\r\n",
      "\r\n",
      "CAUTION When using a binomial probability distribution,\r\n",
      "always be sure that x and p are consistent in the sense\r\n",
      "\r\n",
      "that they both refer to the same category being called a\r\n",
      "success.\r\n",
      "\r\n",
      "copyiht\r\n",
      "\r\n",
      "2018, 2014, 2012 Parzen Edveaton, Ine. Al RightsReserved Oranen\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.689\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mMethod 1: Binomial Probability Formula\r\n",
      "\r\n",
      "P(x) = C(m, x) p* qh ™\r\n",
      "forx=0,1,2,...,n\r\n",
      "where\r\n",
      "n= number of trials\r\n",
      "x = number of successes among n trials\r\n",
      "Pp = probability of success in any one trial\r\n",
      "q = probability of failure in any one trial (q = 1 - p)\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Education, Ine, Al Rights Reserved\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.689\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mnomial Probab\r\n",
      "\r\n",
      "on for B\r\n",
      "\r\n",
      "IDUTIONS (2 of 3)\r\n",
      "\r\n",
      "X - a specific number of successes in n trials, so x can\r\n",
      "be any whole number between 0 and n, inclusive\r\n",
      "\r\n",
      "Pp - probability of success in one of the n trials\r\n",
      "\r\n",
      "q - probability of failure in one of the n trials\r\n",
      "\r\n",
      "P(x) - probability of getting exactly x successes among\r\n",
      "the n trials\r\n",
      "\r\n",
      "‘copyit © 2048, 2014, 2012 Pearson Education, Ine. Al Rights Reserved\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.691\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1miple\r\n",
      "\r\n",
      "Solution\r\n",
      "3. The probability of success (getting a person who knows\r\n",
      "what Twitter is) for one selection is 0.85, so p = 0.85.\r\n",
      "\r\n",
      "4. The probability of failure (not getting someone who\r\n",
      "knows what Twitter is) is 0.15, so q = 0.15.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Education, Inc, All Rights Reserved Oranwn\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.692\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mFootball «. z\r\n",
      "\r\n",
      "Solution\r\n",
      "\r\n",
      "The Excel display on the next page shows that the probability\r\n",
      "of 252 or more wins in 460 overtime games is 0.0224\r\n",
      "(rounded), which is low (such as less than 0.05). This shows\r\n",
      "that it is unlikely that we would get 252 or more wins by\r\n",
      "chance. If we effectively rule out chance, we are left with the\r\n",
      "more reasonable explanation that the team winning the\r\n",
      "overtime coin toss has a better chance of winning the game.\r\n",
      "\r\n",
      "CCopyiht © 2038, 2014, 2012 Pearson Education, Oran\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.692\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1m* Binomial Probability Distribution\r\n",
      "—Abinomial probability distribution results from a\r\n",
      "procedure that meets these four requirements:\r\n",
      "3. Each trial must have all outcomes classified into\r\n",
      "exactly two categories, commonly referred to as\r\n",
      "success and failure.\r\n",
      "\r\n",
      "4. The probability of a success remains the same in\r\n",
      "all trials.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Education, Ine. Al Rights Reserved\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.693\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mple:\r\n",
      "\r\n",
      "Solution\r\n",
      "\r\n",
      "a. This procedure does satisfy the requirements for a\r\n",
      "binomial distribution, as shown below.\r\n",
      "\r\n",
      "1. The number of trials (5) is fixed\r\n",
      "\r\n",
      "2. The 5 trials are independent because the probability of\r\n",
      "any adult knowing Twitter is not affected by results from\r\n",
      "other selected adults.\r\n",
      "\r\n",
      "‘Copy © 2048, 2014, 2012 Pearson Education,\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.694\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1m+ Binomial Probability Distribution\r\n",
      "—Abinomial probability distribution results from a\r\n",
      "procedure that meets these four requirements:\r\n",
      "\r\n",
      "The procedure has a fixed number of trials. (A\r\n",
      "trial is a single observation.)\r\n",
      "\r\n",
      "2. The trials must be independent, meaning that the\r\n",
      "‘outcome of any individual trial doesn't affect the\r\n",
      "probabilities in the other trials.\r\n",
      "\r\n",
      "‘Copyiht © 2038, 2014, 2012 Pearson Education, Inc. Al Rights Reserved Oranon\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.695\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1m5% Guideline for Cumbersome Calculations\r\n",
      "\r\n",
      "When sampling without replacement and the sample\r\n",
      "size is no more than 5% of the size of the population,\r\n",
      "treat the selections as being independent (even though\r\n",
      "they are actually dependent).\r\n",
      "\r\n",
      "Ccopyit © 2048, 2014, 2012 Pearson Education, Ine. Al Rights Reserved\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.696\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mPop quiz!\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.697\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mX=number Frequency Relative freq. Theoretical\r\n",
      "\r\n",
      "right prob.\r\n",
      "0 3 wi 056\r\n",
      "\r\n",
      "1 4 148 188\r\n",
      "\r\n",
      "2 9 333 282\r\n",
      "\r\n",
      "3 5 185 250\r\n",
      "\r\n",
      "4 3 it 146\r\n",
      "\r\n",
      "5 3 a 088\r\n",
      "\r\n",
      "6 0 000 016,\r\n",
      "\r\n",
      "7 ° 000 003\r\n",
      "\r\n",
      "8 ° 000 (0004\r\n",
      "8 ° 000 (00003\r\n",
      "10 0 ‘000 (000001\r\n",
      "\r\n",
      "CCopyriht © 2038, 2014, 2012 Pearson Edveation, Inc.All Rights Reserved\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.698\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mExample: Twitter ors\r\n",
      "\r\n",
      "Solution\r\n",
      "Using the given values of n, x, p, and q in the binomial\r\n",
      "probability formula, we get\r\n",
      "\r\n",
      "!\r\n",
      "P(3)=—> 85°.0.15°°\r\n",
      "6-331\r\n",
      "\r\n",
      "= ©! .0.614128-0.0225\r\n",
      "2131\r\n",
      "\r\n",
      "= (10)(0.614125)(0.0225)\r\n",
      "= 0.138178\r\n",
      "= 0.138 (round to three significant digits)\r\n",
      "\r\n",
      "The probability of getting exactly three adults who know\r\n",
      "Twitter among five randomly selected adults is 0.138.\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.699\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mResults for a re\r\n",
      "\r\n",
      "+ Here are the results for a recent class who did this experiment. The\r\n",
      "\r\n",
      "number of students with each score is given, along with the relative\r\n",
      "\r\n",
      "frequen\r\n",
      "requency. “x= number right Frequency Relative freq.\r\n",
      "\r\n",
      "0 3 Tal\r\n",
      "148\r\n",
      "333\r\n",
      "185\r\n",
      "44\r\n",
      "11\r\n",
      "(000\r\n",
      ".000\r\n",
      "000\r\n",
      ".000\r\n",
      "(000\r\n",
      "\r\n",
      "4\r\n",
      "8\r\n",
      "5\r\n",
      "3\r\n",
      "3\r\n",
      "0\r\n",
      "0\r\n",
      "0\r\n",
      "0\r\n",
      "0\r\n",
      "\r\n",
      "0\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Education, Inc. Al Rights Reserved\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.699\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mPop quiz! —\r\n",
      "\r\n",
      "* Number your paper 1-10. There will be 10 vs\r\n",
      "questions, each with four choices (A, B, C, or D).\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Edueation, Ine, Al Rights Reserved rear\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.699\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mRelative freq. Theoretical\r\n",
      "prob.\r\n",
      "\r\n",
      "o 3 ii 056\r\n",
      "\r\n",
      "1 4 148 188\r\n",
      "\r\n",
      "2 9 333 282\r\n",
      "\r\n",
      "3 5 185 250\r\n",
      "\r\n",
      "4 3 11 146\r\n",
      "\r\n",
      "5 3 a1 088\r\n",
      "\r\n",
      "6 0 000 016\r\n",
      "\r\n",
      "7 ° 000 003\r\n",
      "\r\n",
      "8 ° ‘000 (0004\r\n",
      "\r\n",
      "9 ° 000 (00003\r\n",
      "\r\n",
      "10 0 000 (000001\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Edueaion, In, Al Rights Reserved @rsrwn\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.699\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1m5% Guideline for Cumbersome Calculations\r\n",
      "\r\n",
      "When sampling without replacement and the sample\r\n",
      "size is no more than 5% of the size of the population,\r\n",
      "treat the selections as being independent (even though\r\n",
      "they are actually dependent).\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Edueation, Inc.All Rights Reserved Oran\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.699\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mThe word success as used here is arbitrary and does\r\n",
      "not necessarily represent something good. Either of the\r\n",
      "two possible categories may be called the success S as\r\n",
      "long as its probability is identified as p.\r\n",
      "\r\n",
      "CAUTION When using a binomial probability distribution,\r\n",
      "always be sure that x and p are consistent in the sense\r\n",
      "\r\n",
      "that they both refer to the same category being called a\r\n",
      "success.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Edueation, Ine,\r\n",
      "\r\n",
      "Al Rights Reserves Oranwn\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.699\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1m®\r\n",
      "\r\n",
      "ple:\r\n",
      "\r\n",
      "When an adult is randomly selected (with replacement),\r\n",
      "there is a 0.85 probability that this person knows what\r\n",
      "‘Twitter is (based on results from a Pew Research\r\n",
      "Center survey). Suppose that we want to find the\r\n",
      "probability that exactly three of five randomly selected\r\n",
      "adults know what Twitter is.\r\n",
      "\r\n",
      "a. Does this procedure result in a binomial distribution?\r\n",
      "\r\n",
      "b. If this procedure does result in a binomial distribution,\r\n",
      "identify the values of n, x, p, and g.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Edueation, Ine.\r\n",
      "\r\n",
      "A Rights Reserved Oran\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.699\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mSand F (success and failure) denote the two\r\n",
      "possible categories of all outcomes.\r\n",
      "\r\n",
      "P(S)=p (p = probability of a success)\r\n",
      "P(F)=1-p=q (q= probability of a failure)\r\n",
      "n the fixed number of trials\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Edveation, Inc.All Rights Reserved\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.699\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mX=number Frequency Relative freq. Theoretical “\r\n",
      "right prob.\r\n",
      "0 3 ra 056\r\n",
      "\r\n",
      "1 4 148 188\r\n",
      "\r\n",
      "2 9 333 282\r\n",
      "\r\n",
      "3 5 485 250\r\n",
      "\r\n",
      "4 3 11 146\r\n",
      "\r\n",
      "5 3 a1 088\r\n",
      "\r\n",
      "6 ° ‘000 016\r\n",
      "\r\n",
      "7 0 000 003\r\n",
      "\r\n",
      "8 ° ‘000 (0004\r\n",
      "9 ° 000 (00003\r\n",
      "40 0 000 000001\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.699\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mThe Answers — how did you do?\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.699\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1m2\r\n",
      "\r\n",
      "+ How many did you get right on the pop quiz? Find the\r\n",
      "probability of getting that many right by chance, using the\r\n",
      "formula. If you got three right, we already did that\r\n",
      "problem, so find P(6) instead, the probability of getting 6\r\n",
      "right. We'll compare these theoretical probabilities to the\r\n",
      "results we observed in our class.\r\n",
      "\r\n",
      "copyright © 2038, 2014, 2012 Pearson Education, In. Al Rights Reserved Oren\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.699\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mab\r\n",
      "\r\n",
      "* Binomial Probability Distribution\r\n",
      "—Abinomial probability distribution results from a\r\n",
      "procedure that meets these four requirements:\r\n",
      "The procedure has a fixed number of trials. (A\r\n",
      "trial is a single observation.)\r\n",
      "2. The trials must be independent, meaning that the\r\n",
      "\r\n",
      "‘outcome of any individual trial doesn't affect the\r\n",
      "probabilities in the other trials.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Education,\r\n",
      "\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.708\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mnan\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.709\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mPop quiz! i\r\n",
      "\r\n",
      "* Number your paper 1-10. There will be 10\r\n",
      "questions, each with four choices (A, B, C, or D).\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 PeartanEdueation, In. Al Rights Reserved ran\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.710\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mSolution\r\n",
      "\r\n",
      "The Excel display on the next page shows that the probability\r\n",
      "of 252 or more wins in 460 overtime games is 0.0224\r\n",
      "(rounded), which is low (such as less than 0.05). This shows\r\n",
      "that it is unlikely that we would get 252 or more wins by\r\n",
      "chance. If we effectively rule out chance, we are left with the\r\n",
      "more reasonable explanation that the team winning the\r\n",
      "overtime coin toss has a better chance of winning the game.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Education, Ine, Al Rights Reserved Orne\r\n",
      "\u001B[0m\n",
      "\u001B[32m2024-07-13 13:08:53.711\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mWe previously noted that between 1974 and 2011, there\r\n",
      "were 460 NFL football games decided in overtime, and\r\n",
      "252 of them were won by the team that won the\r\n",
      "overtime coin toss. Is:the result of 252 wins in the 460\r\n",
      "games equivalent to random chance, or is 252 wins\r\n",
      "significantly high? We can answer that question by\r\n",
      "finding the probability of 252 wins or more in 460\r\n",
      "games, assuming that wins and losses are equally\r\n",
      "\r\n",
      "likely.\r\n",
      "\r\n",
      "Copyright © 2038, 2014, 2012 Pearson Edueation, Ine.\r\n",
      "\r\n",
      "All Rights Reserved Orearso0,\r\n",
      "\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T11:08:53.979223Z",
     "start_time": "2024-07-13T11:08:53.716748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get ocr_lava \n",
    "lava_only = df_data_extensive.iloc[4].to_dict().values()\n",
    "\n",
    "lava_only = list(lava_only)\n",
    "\n",
    "lava_only = lava_only[1:]\n",
    "\n",
    "concat_result_ocr_lava = []\n",
    "\n",
    "# list to a list of strings\n",
    "ocr_only = [str(i) for i in ocr_only]\n",
    "\n",
    "lava_only = [str(i) for i in lava_only]\n",
    "\n",
    "for i in range(len(ocr_only)):\n",
    "    concat_result_ocr_lava.append(ocr_only[i] + lava_only[i])"
   ],
   "id": "370a8f17965b5465",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T11:08:54.623321Z",
     "start_time": "2024-07-13T11:08:53.981374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get ocr_transcriptions\n",
    "transcriptions = df_data_extensive.iloc[2].to_dict().values()\n",
    "\n",
    "transcriptions = list(transcriptions)\n",
    "transcriptions = transcriptions[1:]\n",
    "\n",
    "concat_result_ocr_transcriptions = []\n",
    "\n",
    "# concatenate the result \n",
    "ocr = ocr_only\n",
    "\n",
    "transcriptions = [str(i) for i in transcriptions]\n",
    "ocr_only = [str(i) for i in ocr_only]\n",
    "\n",
    "# for i in transcriptions:\n",
    "#     if transcriptions[i] == 'nan' or transcriptions[i] == None:\n",
    "#         transcriptions[i] = ''\n",
    "\n",
    "for i in range(len(ocr_only)):\n",
    "    concat_result_ocr_transcriptions.append(ocr_only[i] + transcriptions[i])\n",
    "\n",
    "logger.info(concat_result_ocr_transcriptions)"
   ],
   "id": "1f0ebf7df19a8809",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-07-13 13:08:54.549\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m22\u001B[0m - \u001B[1m['Method 2: Using Technology\\r\\n\\r\\nTechnologies can be used to find binomial probabilities. The\\r\\nscreen displays on the next slide list binomial probabilities for\\r\\nn=5 and p = 0.85, as in the previous example. Notice that in\\r\\neach display, the probability distribution is given as a table.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearton Education,\\r\\n\\r\\n Another way to find binomial probabilities is using technology.', 'be any whole number between 0 and n, inclusive\\r\\nPp - probability of success in one of the n trials\\r\\n\\r\\nq- probability of failure in one of the n trials\\r\\n\\r\\nP(x) - probability of getting exactly x successes among\\r\\n\\r\\nthe n trials\\r\\n\\r\\nCCopyiht © 2048, 2014, 2012 Pearson Education, Ine. Al Rights Reserved\\r\\n Notice that X can be any whole number between zero.', \"The word success as used here is arbitrary and does\\r\\nnot necessarily represent something good. Either of the\\r\\ntwo possible categories may be called the success S as\\r\\nlong as its probability is identified as p.\\r\\n\\r\\nCAUTION When using a binomial probability distribution,\\r\\nalways be sure that x and p are consistent in the sense\\r\\n\\r\\nthat they both refer to the same category being called a\\r\\nsuccess.\\r\\n\\r\\nCCopyrit © 2038, 2014, 2012 Pearson Edueation, Ine, Al Rights Reserved\\r\\n\\r\\n I guess they'd set with RIP\", 'Solution\\r\\n\\r\\nb. Having concluded that the given procedure does\\r\\nresult in a binomial distribution, we now proceed to\\r\\nidentify the values of n, x, p, and q\\r\\n\\r\\n1. With five randomly selected adults, we have n= 5.\\r\\n\\r\\n2. We want the probability of exactly three who know what\\r\\nTwitter is, so x = 3.\\r\\n\\r\\n‘Copy © 2048, 2014, 2012 Pearson Education, Ine. Al Rights Reserved Oran\\r\\n equals 5, x equals 3.', \"* Binomial Probability Distribution BS\\r\\n—Abinomial probability distribution results from a\\r\\nprocedure that meets these four requirements:\\r\\nThe procedure has a fixed number of trials. (A\\r\\ntrial is a single observation.)\\r\\n\\r\\n2. The trials must be independent, meaning that the\\r\\n‘outcome of any individual trial doesn't affect the\\r\\nprobabilities in the other trials.\\r\\n\\r\\n‘Copy © 2048, 2014, 2012 Pearson Education, Inc. Al Rights Reserved\\r\\n So here that is again, again the example we're talking about right now is I'm going to\", 'ple:\\r\\n\\r\\nSolution\\r\\n\\r\\nAgain, it is very important to be sure that x and p both refer\\r\\nto the same concept of “success.” In this example, we use x\\r\\nto count the number of people who know what Twitter is, so\\r\\np must be the probability that the selected person knows\\r\\nwhat Twitter is. Therefore, x and p do use the same concept\\r\\nof success: knowing what Twitter is.\\r\\n\\r\\nCcopyiht © 2088, 2014, 2012 Pearson Education,\\r\\n that X and P both refer to the same concept of success.  So X is the number of people who have heard of Twitter.  P is the probability that a specific person has heard of Twitter.', \"Let’s develop the fo\\r\\n\\r\\ni\\r\\n\\r\\n+ On the pop quiz you took earlier, what is the probability of getting et\\r\\nexactly 3 right?\\r\\n\\r\\n+ One way to get three right is RRRWWWWWWW (R = right, W =\\r\\nwrong)\\r\\n\\r\\n+ The probability of this exact outcome is (2) (2) ~ 00208\\r\\n\\r\\n* But this isn't the only way to get three right. There are (10,3)\\r\\n120 different ways to get 3 right (choose 3 spots for the R's)\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Education, In. All Rights Reserved Orin\\r\\n Right, I would be very surprised if anybody in this room,  or you watching at home.  If you got three right, even if you got three right,  I'd be surprised if you got this exact outcome.  Because there are a whole bunch of other ways  to get three right.  You don't have to get the first three,  could have gotten the last three,  could have gotten one, five, and ten,  one, three, and five, two, seven, and four, right?  So the total number of ways to get exactly three right  is actually 10 choose three.  And the reason it's 10 choose three  is because I have 10 questions,  and I'm choosing three of them  that were the ones that were correct.  And so the reason that's a combination  and not a permutation is that ordered doesn't matter.  Getting number two, four, and seven right,  is the same thing as getting number seven,  or two, and number four right.  So I don't care about order.  All right, so 10 choose three works out to be 120.  So there are that many different outcomes  that have three right.  Each of those specific outcomes  has this probability right here.  So I'm gonna multiply that probability by 120.  And it turns out that the probability  of getting exactly three right is about one, four,  about one, fourth, not exactly.  I think it's like 0.2503 or something,  if I remember correctly.\", 'Key Concept\\r\\n\\r\\nThe focus of this section is the binomial probability\\r\\ndistribution and methods for finding probabilities.\\r\\n\\r\\nEasy methods for finding the mean and standard\\r\\ndeviation of a binomial distribution are also presented.\\r\\n\\r\\nAs in other sections, we stress the importance of\\r\\ninterpreting probability values to determine whether\\r\\nevents are significantly low or significantly high.\\r\\n\\r\\n Okay, so the binomial distribution, binomial probability distribution is a specific discrete  probability distribution.  This whole chapter is about discrete probability distributions.', \"Example: Twitter (7 or\\r\\n\\r\\nGiven that there is a 0.85 probability that a randomly\\r\\nselected adult knows what Twitter is, use the binomial\\r\\nprobability formula to find the probability that when five\\r\\nadults are randomly selected, exactly three of them know\\r\\nwhat Twitter is. That is, apply the previous formula to find\\r\\nP(3) given that n = 5, x = 3, p = 0.85, and q=0.15.\\r\\n\\r\\n2018, 2014, 2012 Pearson Edueation, Ine. All\\r\\n\\r\\n Okay, so back to the Twitter example, and then we're going to go back to the pop quiz for a minute, do a little activity.  Given that there is a 0.85 probability that a randomly selected adult knows what Twitter is, use the binomial probability formula to find the probability that when five adults are randomly selected exactly three of them know what Twitter is.  So use the formula that we just looked at to find pf3 given that n is 5 x is 3 p is 0.85, p is 0.15.\", \"Pop quiz!\\r\\n\\r\\n» Number your paper 1-10. There will be 10\\r\\nquestions, each with four choices (A, B, C, or D).\\r\\n\\r\\n* Oops! | forgot to bring the questions. But we\\r\\nhave to have the quiz today, so you'll just have to\\r\\nguess, Aaaaand GO!\\r\\n\\r\\n question has four choices. Unfortunately, I forgot to bring the questions with me so you just  have to guess. What I'm going to have you do is pause the video, just make your guesses for each  question. Don't put too much thought into it and then unpause the video and we'll have you  grade your paper. Okay. So here we go. Here are the answers to the pop.\", '4\\r\\nX=number Frequency Relative req. Theoretical -\\r\\ntaht prob,\\r\\n\\r\\n0 a a 056\\r\\n\\r\\n1 4 148 128\\r\\n\\r\\n2 9 333 282\\r\\n\\r\\n3 5 195 250\\r\\n\\r\\n4 3 i\" 146\\r\\n\\r\\n5 a 1 058\\r\\n\\r\\n6 Q 000 a6\\r\\n\\r\\n7 o 00 as\\r\\n\\r\\n8 9 60 004\\r\\n\\r\\n9 0 000 00003\\r\\n\\r\\n10 0 000 00004\\r\\n\\r\\nCopyright © 2018, 2014, 2012 Pearson Edveation, In, Al Rights Reserved\\r\\n\\r\\n Alright!', 'The word success as used here is arbitrary and does\\r\\nnot necessarily represent something good. Either of the\\r\\ntwo possible categories may be called the success S as\\r\\nlong as its probability is identified as p.\\r\\n\\r\\nCAUTION When using a binomial probability distribution,\\r\\nalways be sure that x and p are consistent in the sense\\r\\n\\r\\nthat they both refer to the same category being called a\\r\\nsuccess.\\r\\n\\r\\n© 2018, 2018, 2012 Pearson Education, Inc. Al Rights Reserves\\r\\n\\r\\n Okay', \"'s develop t mula\\r\\n\\r\\n+ On the pop quiz you took earlier, what is the probability of getting\\r\\nexactly 3 right?\\r\\n\\r\\n+ One way to get three right is RRRWWWWWWW (R = right, W =\\r\\nwrong)\\r\\n\\r\\n+ The probability of this exact outcome is (2) (2) ~ .00208\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Education, Inc.All Rights Reserved Orann\\r\\n Okay, so now we're going to develop the formula that we need to actually find that probability and other things like it.  So I'm going to do this in terms of the pop quiz.  All right, and we're going to talk about what's the probability of getting exactly three right.  So there were a few people in this room who got three right when we did this the other day.  Maybe you watching at home got three right.  Okay, so here is one way to get three right. This is just one way.  Okay, you get the first three right and then you get all the rest of them wrong.  Okay, that's one way.  The probability of that particular outcome would be one fourth is the probability of getting number one right.  One fourth is the probability getting number two right. One fourth is the probability of getting number three right.  So the probability of getting the first three right is one fourth times one fourth times one fourth.  Okay, but then you also have to get all the rest of them wrong.  Remember we want this specific outcome to be exactly three right.  So the probability getting number four wrong is three fours probably getting number five wrong is three fours probably number six wrong has three fours, et cetera, et cetera.  So the probability of getting the last seven wrong is three fours to the seventh.  So this would be an example of the well independent events right getting number one right is independent of getting number two right.  And that's independent of getting number three right.  So the probability of this specific outcome is one fourth to the power three times three fours to the power seven, which comes out to be about two and a thousand.\", \"Proba\\r\\n\\r\\n* Binomial Probability Distribution\\r\\n—Abinomial probability distribution results from a\\r\\n\\r\\ncopyiht\\r\\n\\r\\nprocedure that meets these four requirements:\\r\\n\\r\\n3. Each trial must have all outcomes classified into\\r\\nexactly two categories, commonly referred to as\\r\\nsuccess and failure.\\r\\n\\r\\n4. The probability of a success remains the same in\\r\\nall trials.\\r\\n\\r\\n So if I pick five random people, all right, and this person over here has heard of Twitter, does that have any effect on whether this person over here has heard of Twitter?  No, it does not, okay, so those trials are independent.  Each trial must have all outcomes classified into two categories, success and failure.  Either you've heard of Twitter or you haven't, right?  Okay, and then the probability of success remains the same in all trials.  All right, so here is kind of important that it's set with replacement.  They didn't say exactly how big this population is.  I have a feeling it probably doesn't matter all that much.  But if I'm going to pull a person aside, ask them, have you ever heard of Twitter?  The answer yes or no, and then I'll put that person back in the population.  That means the probability of picking somebody who's heard of Twitter is always 25.  Now, if you're talking about a really huge population, it really wouldn't matter whether it was with or without replacement.  You may remember, I want to say that was somewhere in chapter four, maybe in four, four.  If your sample is like less than 5% the size of the population, then it really doesn't matter if it's with or without replacement.\", 'Solution\\r\\n\\r\\nAgain, it is very important to be sure that x and p both refer\\r\\nto the same concept of “success.” In this example, we use x\\r\\nto count the number of people who know what Twitter is, so\\r\\np must be the probability that the selected person knows\\r\\nwhat Twitter is. Therefore, x and p do use the same concept\\r\\nof success: knowing what Twitter is\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Education, Inc, All Rights Reserved Orne\\r\\n So just a note on that last.', 'X-a specific number of successes in n trials, so x can\\r\\nbe any whole number between 0 and n, inclusive\\r\\n\\r\\np- probability of success in one of the n trials\\r\\nq- probability of failure in one of the n trials\\r\\n\\r\\nP(x) - probability of getting exactly x successes among\\r\\nthe n trials\\r\\n\\r\\nCCopyiht © 2088, 2014, 2012 Pearson Education, Inc. Al Rights Reserved @ arson\\r\\n Alright, so here is I think all the note A.', 'Method 1: Binomial Probability Formula\\r\\n\\r\\nP(x) = Cm, x) p* qh ™\\r\\nforx=0,1,2,...,n\\r\\nwhere\\r\\nn= number of trials\\r\\nx = number of successes among m trials\\r\\nPp = probability of success in any one trial\\r\\nq = probability of failure in any one trial (q = 1 - p)\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Education, In. Al Rights Reserved Oranwn\\r\\n successes, the probability of having any particular...', \"+ How many did you get right on the pop quiz? Find the\\r\\nprobability of getting that many right by chance, using the\\r\\nformula. If you got three right, we already did that\\r\\nproblem, so find P(6) instead, the probability of getting 6\\r\\nright. We'll compare these theoretical probabilities to the\\r\\nresults we observed in our class.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Edueation, Inc.All Rights Reserved pearson\\r\\n there was nobody in this class that got six right so we can\", \"Pop quiz! Ee\\r\\n\\r\\n» Number your paper 1-10. There will be 10 4\\r\\nquestions, each with four choices (A, B, C, or D).\\r\\n\\r\\n* Oops! | forgot to bring the questions. But we\\r\\nhave to have the quiz today, so you'll just have to\\r\\nguess, Aaaaand GO!\\r\\n\\r\\n+ Alldone? | feel bad about that “forgot the\\r\\nquestions’ thing, so I'll let you grade your own\\r\\npaper. (Be honest!) Here are the answers..\\r\\n\\r\\nCCopyrit © 2038, 2014, 2012 Pearson Eaueation, Inc.All Rights Reserved rare\\r\\n just a second.\", \"nan You're also going to see this worked out on the PowerPoint here in just a second.  5, and then remember to get NCR.  You go into math and then go over to P or B.  If you're using a scientific calculator, there's a PRB button,  at least on the one I have, and then go down to NCR.\", \"Metr\\r\\n\\r\\nrob\\r\\n\\r\\nMethod 2: Using Technology\\r\\n\\r\\nTechnologies can be used to find binomial probabilities. The\\r\\nscreen displays on the next slide list binomial probabilities for\\r\\nn=5 and p = 0.85, as in the previous example. Notice that in\\r\\neach display, the probability distribution is given as a table.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 PeartonEdueation, Oran\\r\\n\\r\\n There is one slide that has different.  We'll show you different things, different ways to find it using technology.  My favorite is Excel.  I love Excel.  So this is the Twitter example.  Take five adults to ask them if they've ever heard of Twitter.\", \"Solution\\r\\n\\r\\nUsing the given values of n, x, p, and q in the binomial\\r\\nprobability formula, we get\\r\\n\\r\\n5!\\r\\nP(3)=\\r\\n= Gaya\\r\\n\\r\\n85°.0.15°*\\r\\n\\r\\n= 2! .0.614128-0.0225\\r\\n2131\\r\\n\\r\\n= (10)(0.614125)(0.0225)\\r\\n= 0.138178\\r\\n= 0.138 (round to three significant digits)\\r\\nThe probability of getting exactly three adults who know\\r\\n\\r\\nTwitter among five randomly selected adults is 0.138.\\r\\n\\r\\nAll RightsReserved parse,\\r\\n\\r\\n it, they actually did not use the built-in and CR formula and the calculator. They just  use the actual formula for NCR. It works out to the same thing. So you crunch all those numbers  comes out to about .138, so if we're rounding to three significant digits,  .138. So the probability of picking exactly when you pick five adults, that exactly  three of them have heard of Twitter, is about .138.\", 'omial\\r\\n\\r\\nMethod 2: Using Technology\\r\\n\\r\\nTechnologies can be used to find binomial probabilities. The\\r\\nscreen displays on the next slide list binomial probabilities for\\r\\nn=5 and p = 0.85, as in the previous example. Notice that in\\r\\neach display, the probability distribution is given as a table.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Edveation, Inc.All Rights Reserved Oranen\\r\\n Alright so', \"Key Concept\\r\\n\\r\\nil\\r\\n\\r\\nThe focus of this section is the binomial probability\\r\\ndistribution and methods for finding probabilities.\\r\\n\\r\\nEasy methods for finding the mean and standard\\r\\ndeviation of a binomial distribution are also presented.\\r\\n\\r\\nAs in other sections, we stress the importance of\\r\\ninterpreting probability values to determine whether\\r\\nevents are significantly low or significantly high.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Edueation, In. Al Rights Reserved Orr\\r\\n distribution is binomial and I think we've done this a couple times before we're  going to talk about how do you know if you have a significantly lower  significantly high number of outcomes.\", 'Relative freq. Theoretical\\r\\nprob.\\r\\n\\r\\n0 3 att 056\\r\\n\\r\\n1 4 148 188\\r\\n\\r\\n2 9 333 282\\r\\n\\r\\n3 5 185 250\\r\\n\\r\\n4 3 itt 446\\r\\n\\r\\n5 3 oa 058\\r\\n\\r\\n6 0 (000 016\\r\\n\\r\\n7 0 000 003\\r\\n\\r\\n8 ° ‘000 (0004\\r\\n\\r\\n9 0 000 00003\\r\\n\\r\\n10 0 000 (000001\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Edueaion, In, Al Rights Reserved @Psrwn\\r\\n for at least.', \"Pop quiz! =_\\r\\n\\r\\n+ Number your paper 1-10. There will be 10\\r\\nquestions, each with four choices (A, B, C, or D).\\r\\n\\r\\n2018, 2018, 2012 Pearson Ecucation, Ine. Al Rights Reserved Oranen\\r\\n\\r\\n All right, you're going to number your paper one through ten, please.\", \"cent class\\r\\n\\r\\n+ Here are the results for a recent class who did this experiment. The =\\r\\nnumber of students with each score is given, along with the relative\\r\\n\\r\\nf\\r\\nrequency. “x= number right Frequency Relative freq.\\r\\n\\r\\n0 3 Tr\\r\\n148\\r\\n333\\r\\n185\\r\\n44\\r\\n41\\r\\n(000\\r\\n.000\\r\\n(000\\r\\n000\\r\\n(000\\r\\n\\r\\n4\\r\\n8\\r\\n5\\r\\n3\\r\\n3\\r\\n0\\r\\n0\\r\\n0\\r\\n°\\r\\no\\r\\n\\r\\n0\\r\\n\\r\\nCCopyiat © 2048, 2014, 2012 Pearson Education,\\r\\n And actually we've already done that.\", 'le: Twitter\\r\\n\\r\\nSolution\\r\\n\\r\\n3. Each of the 5 trials has two categories of outcomes:\\r\\nThe selected person knows what Twitter is or that\\r\\nperson does not know what Twitter is.\\r\\n\\r\\n4. For each randomly selected adult, there is a 0.85\\r\\nprobability that this person knows what Twitter is, and\\r\\nthat probability remains the same for each of the five\\r\\nselected people.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Education, Inc.All RightsReserved Oranen\\r\\n success or failure and that probability stays the same.', '| Probabi\\r\\n\\r\\n* Binomial Probability Distribution\\r\\n\\r\\n—Abinomial probability distribution results from a\\r\\nprocedure that meets these four requirements:\\r\\n\\r\\n3. Each trial must have all outcomes classified into\\r\\nexactly two categories, commonly referred to as\\r\\nsuccess and failure.\\r\\n\\r\\n4. The probability of a success remains the same in\\r\\nall trials.\\r\\n\\r\\n‘Copy © 2038, 2014, 2012 Pearson Education, Inc. Al Rights Reserved Orinn\\r\\nnan', '5% Guideline for Cumbersome Calculations\\r\\n\\r\\nWhen sampling without replacement and the sample\\r\\nsize is no more than 5% of the size of the population,\\r\\ntreat the selections as being independent (even though\\r\\nthey are actually dependent).\\r\\n\\r\\nCCopyiht © 2088, 2014, 2012 Pearson Education, Ine. Al Rights Reserved\\r\\n\\r\\n minute ago when sampling without replacement and the sample size is no more.', \"Twit\\r\\n\\r\\nTter (1 of\\r\\n\\r\\nWhen an adult is randomly selected (with replacement), [ug\\r\\nthere is a 0.85 probability that this person knows what\\r\\n‘Twitter is (based on results from a Pew Research\\r\\n\\r\\nCenter survey). Suppose that we want to find the\\r\\n\\r\\nprobability that exactly three of five randomly selected\\r\\nadults know what Twitter is.\\r\\n\\r\\na. Does this procedure result in a binomial distribution?\\r\\n\\r\\nb. If this procedure does result in a binomial distribution,\\r\\nidentify the values of n, x, p, and g.\\r\\n\\r\\ncopyright © 2038, 2014, 2012 Pearson Education, I\\r\\n\\r\\nAl Rights Reserves rere\\r\\n All right, so here's an example that has nothing to do with the pop quiz.  So all we're going to do in this example right now is figure out what is n, what is x, what is p, what is q.  And then later on we're going to come back to this example and actually find this probability.  So when an adult is randomly selected with replacement, there is a 0.85 probability that this person  knows what Twitter is.  Suppose we want to find the probability that exactly 3 of 5 randomly selected adults,  know what Twitter is.  So the first question does this procedure result in a binomial distribution?  So think back to those four requirements for what makes a binomial distribution.  Actually, might be a good idea to go back and take a look at those.\", \"Solution ‘\\r\\n\\r\\nUsing the notation for binomial probabilities, we have n = 460,\\r\\np=0.5, q=0.5, and we want to find the sum of all\\r\\nprobabilities for each value of x from 252 through 460. The\\r\\nformula is not practical here, because we would need to apply\\r\\nit 209 times—we don't want to go there. Table A-1 (Binomial\\r\\nProbabilities) doesn't apply because n = 460, which is way\\r\\nbeyond the scope of that table. Instead, we wisely choose to\\r\\nuse technology.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Eeuca\\r\\n\\r\\n What I'm going to tell you about next time is this table A1.  I'll show that to you in part 2 of this video.  We wouldn't be able to use it in this problem anyway.  I'll show you how to use it in a different problem.  We want to find the sum of all probabilities for each value of x from 250 to 460.  That would be a nightmare using the formula.  You would have to use the formula 200 times.  And add them all together.  So what I'm going to do is...\", '.S77S7AOE] puting \"tue\" atthe end gives P25 or fewer wins)\\r\\n0,022428837Thsisthe probably ofthe complement, 252 or more\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Education, In, All Rights Reserved Oranen\\r\\n it back. All right, so here\\'s a screenshot of my Excel when I did this. So this time I am using  the cumulative version of the formula. Okay, so the way the cumulative version works, remember we\\'re  trying to find the probability of 252 or more successes. That\\'s not the way the formula works,  the formula will give you a specific number or less. So I\\'m going to have to use the complement rule.  All right, so I\\'m asking Excel what\\'s the probability of 251 or fewer wins? So the way that you do that  is bynom.dist 251 successes at a 460 trials probability success is 25 and then I\\'m putting  true here to make it cumulative. So the probability of 251 or fewer wins is about 0.976,  which means that the probability of the complementary event 252 or more wins is 1 minus that.  1 minus 0.976 is about 0.0224. So what that means?', 'Foo =\\r\\nWe previously noted that between 1974 and 2011, there\\r\\nwere 460 NFL football games decided in overtime, and\\r\\n252 of them were won by the team that won the\\r\\novertime coin toss. Is the result of 252 wins in the 460\\r\\ngames equivalent to random chance, or is 252 wins\\r\\nsignificantly high? We can answer that question by\\r\\nfinding the probability of 252 wins or more in 460\\r\\ngames, assuming that wins and losses are equally\\r\\n\\r\\nlikely.\\r\\n\\r\\n* © 2018, 2018, 2012 Pearson Edueaton Ine.\\r\\n\\r\\nAl Rights Reserve Oranwn\\r\\n All right.', \"pop\\r\\noF\\r\\n\\r\\n+ How many did you get right on the pop quiz? Find the\\r\\nprobability of getting that many right by chance, using the\\r\\nformula. If you got three right, we already did that\\r\\nproblem, so find P(6) instead, the probability of getting 6\\r\\nright. We'll compare these theoretical probabilities to the\\r\\nresults we observed in our class.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearton Eda,\\r\\n\\r\\n Alright, back to the pop quiz.  So think back to how many questions did you...\", 'The Answers — how did you do?\\r\\n\\r\\n Number one is C, number two is B.  So just mark each of your-', \"1 vs. theoretical\\r\\n\\r\\nRelative freq. Theoretical\\r\\nprob.\\r\\n\\r\\n0 3 it 056\\r\\n\\r\\n1 4 148 188\\r\\n\\r\\n2 9 333 282\\r\\n\\r\\n3 5 185 250\\r\\n\\r\\n4 3 itt 446\\r\\n\\r\\n5 3 oa) 058\\r\\n\\r\\n6 0 000 016\\r\\n\\r\\n7 ° 000 003\\r\\n\\r\\n8 ° ‘000 (0004\\r\\n\\r\\n9 0 000 00003\\r\\n\\r\\n10 0 (000 (000001\\r\\n\\r\\nCCopyiht © 2048, 2014, 2012 Pearson Education, Inc, Al Rights Reserved\\r\\n\\r\\n Okay.  0.282.  Here's the one.\", 'Pop quiz! =\\r\\n\\r\\nNumber your paper 1-10. There will be 10\\r\\nquestions, each with four choices (A, B, C, or D).\\r\\n\\r\\nI Righe Reserves Oran\\r\\n So now take a pop quiz.', 'Example: Twitter (ors =\\r\\n\\r\\nSolution\\r\\nUsing the given values of n, x, p, and q in the binomial\\r\\nprobability formula, we get\\r\\n\\r\\n!\\r\\nP(3) => 85°.0.15°°\\r\\n6-331\\r\\n\\r\\n= 2! .0.614128-0.0225\\r\\n2131\\r\\n\\r\\n= (10)(0.614125)(0.0225)\\r\\n= 0.138178\\r\\n= 0.138 (round to three significant digits)\\r\\n\\r\\nThe probability of getting exactly three adults who know\\r\\nTwitter among five randomly selected adults is 0.138.\\r\\n\\r\\n Alright, so here...', \"* Binomial Probability Distribution\\r\\n—Abinomial probability distribution results from a\\r\\nprocedure that meets these four requirements:\\r\\n\\r\\nThe procedure has a fixed number of trials. (A\\r\\ntrial is a single observation.)\\r\\n\\r\\n2. The trials must be independent, meaning that the\\r\\noutcome of any individual trial doesn't affect the\\r\\nprobabilities in the other trials.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 PeartonEdeation,\\r\\n\\r\\n Alright, so here are the properties of a binomial distribution.\", \"The word success as used here is arbitrary and does\\r\\nnot necessarily represent something good. Either of the\\r\\ntwo possible categories may be called the success S as\\r\\nlong as its probability is identified as p.\\r\\n\\r\\nCAUTION When using a binomial probability distribution,\\r\\nalways be sure that x and p are consistent in the sense\\r\\n\\r\\nthat they both refer to the same category being called a\\r\\nsuccess.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Education, I\\r\\n\\r\\n that this is rarely represented something good.  And the pop quiz example it does.  Okay.  Either of the two possible categories  may be called the success,  as long as its probability is identified as P.  All right.  So let's say that you're the person who's in charge  of studying the roads in Merced,  and you've gotten some complaints that they're...\", '5% Guideline for Cumbersome Calculations\\r\\n\\r\\nWhen sampling without replacement and the sample\\r\\nsize is no more than 5% of the size of the population,\\r\\ntreat the selections as being independent (even though\\r\\nthey are actually dependent).\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Edueation, Inc.All Rights Reserved Oran\\r\\n you can treat the selections as being independent.', \"lal Pro\\r\\n\\r\\n* Binomial Probability Distribution\\r\\n\\r\\n— Abinomial probability distribution results from a\\r\\nprocedure that meets these four requirements:\\r\\n3. Each trial must have all outcomes classified into\\r\\nexactly two categories, commonly referred to as.\\r\\nsuccess and failure.\\r\\n\\r\\n4. The probability of a success remains the same in\\r\\nall trials.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearton Education, Oran\\r\\n\\r\\n by a binomial probability distribution  is that each trial must have all outcomes  classified into two categories,  which are called success and failure.  So in our example, there were actually four outcomes,  ABC or D, but only one of those is correct,  so we'll call that a success,  and the other three are wrong, we'll call that a failure.  And number four, the probability of success  remains the same in all trials.  So for my pop quiz, I had to have every single question  have four choices.  On some of your exams, there are some questions  that have only two choices, I think there was one that had five choices.  But if I want this to be binomial,  they all have to have the same number of choices.  It doesn't have to be four, but they all have to be the same.\", \"Solution\\r\\n\\r\\na. This procedure does satisfy the requirements for a\\r\\nbinomial distribution, as shown below.\\r\\n\\r\\n1, The number of trials (5) is fixed\\r\\n\\r\\n2. The 5 trials are independent because the probability of\\r\\nany adult knowing Twitter is not affected by results from\\r\\nother selected adults.\\r\\n\\r\\nOrearson\\r\\n 8.5.  All right, so here's\", \"Method 1: Binomial Probability Formula\\r\\n\\r\\nP(x) = C(m, x) p* qh ™\\r\\nforx=0,1,2,...,n\\r\\nwhere\\r\\nn= number of trials\\r\\nx = number of successes among n trials\\r\\nPp = probability of success in any one trial\\r\\nq = probability of failure in any one trial (q = 1 - p)\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Education, In. Al Rights Reserved\\r\\n particular x successes is p to the x, and then all the rest of the outcomes have to be  failures.  So the probability of getting that number of failures is q to the power and minus x.  So this formula works for any value of x from zero all the way up to n.  What typically happens is that within a specific problem n stays the same and p stays  the same and a p stays the same q has to stay the same.  What may change throughout the problem from like part A to part B to part C is the value  of x.  Part A might ask you what's the probability of three successes and then part B asks you what's  the probability of five successes.  So x may change throughout the problem but the other things won't.  So again, n is the number of trials, x is the number of successes, p is the probability  of success in any one trial, q is the probability of failure in any one trial.  Remember q is always one minus p.\", 'Key Concept =\\r\\n\\r\\nThe focus of this section is the binomial probability\\r\\ndistribution and methods for finding probabilities.\\r\\n\\r\\nEasy methods for finding the mean and standard\\r\\ndeviation of a binomial distribution are also presented.\\r\\n\\r\\nAs in other sections, we stress the importance of\\r\\ninterpreting probability values to determine whether\\r\\nevents are significantly low or significantly high.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Edveation, Inc.All Rights Reserved rar\\r\\n very simple formulas for finding the mean and standard deviation.', \"+ How many did you get right on the pop quiz? Find the\\r\\nprobability of getting that many right by chance, using the\\r\\nformula. If you got three right, we already did that\\r\\nproblem, so find P(6) instead, the probability of getting 6\\r\\nright. We'll compare these theoretical probabilities to the\\r\\nresults we observed in our class.\\r\\n\\r\\nCCopyiht © 2088, 2014, 2012 Pearson Education, Ine, Al Rights Reserved Oran\\r\\n do that one. And then once you've done that, we'll come back. We'll compare notes. We'll ask  everybody what did they get for that. And we'll compare it to what we actually observed in our class.  So go ahead and pause the video, try that, and then we'll come back and compare notes.\", \"Results for a recent class\\r\\n\\r\\n+ Here are the results for a recent class who did this experiment. The\\r\\nnumber of students with each score is given, along with the relative\\r\\n\\r\\nfrequen i\\r\\neauency. “x= numberright Frequency Relative freq.\\r\\n\\r\\n) 3 Ta\\r\\n148\\r\\n333\\r\\n185\\r\\n44\\r\\na1\\r\\n(000\\r\\n.000\\r\\n(000\\r\\n.000\\r\\n(000\\r\\n\\r\\n4\\r\\n8\\r\\n5\\r\\n3\\r\\n3\\r\\n)\\r\\n0\\r\\n0\\r\\n0\\r\\nO\\r\\n\\r\\n Where's...\", 'Solution\\r\\n\\r\\nb. Having concluded that the given procedure does\\r\\nresult in a binomial distribution, we now proceed to\\r\\nidentify the values of n, x, p, and q\\r\\n\\r\\n1. With five randomly selected adults, we have n= 5.\\r\\n\\r\\n2. We want the probability of exactly three who know what\\r\\nTwitter is, so x = 3.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Education, Inc.All Rights Reserved Oran\\r\\n Okay, so any', \"When an adult is randomly selected (with replacement),\\r\\nthere is a 0.85 probability that this person knows what\\r\\nTwitter is (based on results from a Pew Research\\r\\nCenter survey). Suppose that we want to find the\\r\\nprobability that exactly three of five randomly selected\\r\\nadults know what Twitter is.\\r\\n\\r\\na. Does this procedure result in a binomial distribution?\\r\\n\\r\\nb. If this procedure does result in a binomial distribution,\\r\\nidentify the values of n, x, p, and g.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Edueation, In, Al Rights Reserved Oranwn\\r\\n placement so that we didn't have to worry about it.  All right, so this person...\", \"X - a specific number of successes in n trials, so x can\\r\\nbe any whole number between 0 and n, inclusive\\r\\n\\r\\np- probability of success in one of the n trials\\r\\nq- probability of failure in one of the n trials\\r\\n\\r\\nP(x) - probability of getting exactly x successes among\\r\\nthe n trials\\r\\n\\r\\ncopyright © 2038, 2014, 2012 Pearson Education, In. Al\\r\\n\\r\\n end so that automatically makes it discrete. There's only a finite number of possible outcomes.  And they happen to be whole numbers. Again, P is the probability of success in anyone  trial. Q is the probability of failure in anyone trial. And then we'll use our usual probability  notation P of x is the probability of getting exactly x successes in n trial. So the example we're  going to be doing here pretty soon, what's the probability of getting exactly three questions right  out of the 10 questions?\", \"Copyright © 2038, 2014, 2012 Pearton Eda,\\r\\n\\r\\nOn the pop quiz you took earrier, what is the probability of getting\\r\\nexactly 3 right?\\r\\n\\r\\n(One way to get three right is RRRWWWWWWW (R = right, W =\\r\\nwrong)\\r\\n\\r\\nThe probability of this exact outcome is (*) (2) ~.00208,\\r\\n\\r\\nBut this isn't the only way to get three right. There are C(10,3) =\\r\\n120 different ways to get 3 right (choose 3 spots for the R's)\\r\\n\\r\\nAl RightsReserved raven\\r\\n Alright, but of course that's not the only way to get three.\", 'Example: Twitter «\\r\\n\\r\\nSolution\\r\\n\\r\\nAgain, it is very important to be sure that x and p both refer\\r\\nto the same concept of “success.” In this example, we use x\\r\\nto count the number of people who know what Twitter is, so\\r\\np must be the probability that the selected person knows\\r\\nwhat Twitter is. Therefore, x and p do use the same concept\\r\\nof success: knowing what Twitter is.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Education, Inc.All Rights Reserved rare\\r\\n example.', \"1a\\r\\n\\r\\n* Binomial Probability Distribution\\r\\n—Abinomial probability distribution results from a\\r\\nprocedure that meets these four requirements:\\r\\nThe procedure has a fixed number of trials. (A\\r\\ntrial is a single observation.)\\r\\n\\r\\n2. The trials must be independent, meaning that the\\r\\noutcome of any individual trial doesn’t affect the\\r\\nprobabilities in the other trials.\\r\\n\\r\\nCCopyiht © 2048, 2014, 2012 Pearson Education, Ine. Al Rights Reserved\\r\\n\\r\\n to ask five adults, have you ever heard of Twitter? Okay. So number one, the procedure has a fixed  number of trials. Is that true? Yes, I think that's true. The fixed number of trials in this  problem would be the five adults. I'm going to ask five adults have you heard of Twitter?  Okay. Number two, the trials must be independent.\", \"Method 2: Using Technology\\r\\n\\r\\nTechnologies can be used to find binomial probabilities. The\\r\\nscreen displays on the next slide list binomial probabilities for\\r\\nn=5 and p = 0.85, as in the previous example. Notice that in\\r\\neach display, the probability distribution is given as a table.\\r\\n\\r\\n‘Copy © 2088, 2014, 2012 Pearson Education,\\r\\n\\r\\n Okay? Now depending on what statistics class you're taking, most of the time the only  technology of access to, say during an exam is just a calculator. It could be a  scientific calculator, it could be a graph and calculator. But if you're doing homework,  you have access to other kinds of technology. Okay? So what I'm going to show you here,\", \"Method 2: Using Technology Ye\\r\\n\\r\\n7189/84 Plus CE Excel\\r\\nPte)\\r\\n7386.05\\r\\n\\r\\nx Hi] =binom.dist(x, n, p, false)\\r\\n\\r\\nCCopyriht © 2038, 2014, 2012 Pearson Education, I\\r\\n\\r\\nOversee\\r\\n So here are a few different technologies that will help you find that probability.  So one of them is a program called Stat disk.  Another one is a program called Mini tab.  Here is a graph and calculator. It looks to me like what they did was they put the number zero through five into a list.  And then they programmed the binomial formula, probably into the YE calls space.  I want to focus on this one right here.  So what I've done right here is given you the formula in Excel for finding a binomial probability.  So let me explain as to you.  Formulas in Excel always start with an equal sign.  And then the name of the function is binomial period DIST for binomial distribution.  And the inputs for that formula are X, the number of successes, and the number of trials.  P the probability of success.  And then the reason I'm putting this word false here, I'm telling Excel not to make this cumulative.  If you put a true there, what it will tell you is the probability of X successes or less.  X or less, right, up to X, up to an including X.  So if you want them separated out probability of zero successes, one success, two successes, you put balls there.  And I'm going to show you another example using Excel that I did.\", 'The Answers — how did you do?\\r\\n\\r\\n‘\\r\\n8\\r\\nD\\r\\n8\\r\\n\\r\\n5.8\\r\\n\\r\\n6.0\\r\\nD\\r\\nc\\r\\n\\r\\n9.¢\\r\\n\\r\\n0.8\\r\\n\\r\\n All right, the answers to the pop.', \"+ How many did you get right on the pop quiz? Find the\\r\\nprobability of getting that many right by chance, using the\\r\\nformula. If you got three right, we already did that\\r\\nproblem, so find P(6) instead, the probability of getting 6\\r\\nright. We'll compare these theoretical probabilities to the\\r\\nresults we observed in our class.\\r\\n\\r\\ncopy © 2088, 2014, 2012 Pearson Education,\\r\\n\\r\\n get right on the pop quiz so I hope you played. And what you're going to do now is find  the probability of getting that number right by chance using the formula that we just talked  about. Now if you happen to get three right I kind of stole that example. So if you got three  right what I will ask you to do instead is find the probability of getting sick.\", \"Proba\\r\\n\\r\\n5-1 Probability Distributions\\r\\n5-2 Binomial Probability Distributions\\r\\n5-3 Poisson Probability Distributions\\r\\n\\r\\n2018, 2014, 2012 Pearzon Edveation, ne Al RightsReserved\\r\\n\\r\\ncopyriht\\r\\n Hi everybody, it's Professor Mitchell continuing with Chapter 5.  We're now looking at Section 5-2 by Nomile Probability Distribution.\", \"nan Alright, so I've got my calculator up.  First thing I need to put in is five choose three.\", 'ONS (1 of 3\\r\\n\\r\\nSand F (success and failure) denote the two\\r\\npossible categories of all outcomes.\\r\\n\\r\\nP(S)=p (p = probability of a success)\\r\\nP(F)=1-p=q (q= probability of a failure)\\r\\n\\r\\nn the fixed number of trials\\r\\n\\r\\nCCopyrit © 2038, 2014, 2012 Pearson Edueation, In. Al Rights Reserved\\r\\n\\r\\nOrearson,\\r\\nnan', \"5% Guideline for Cumbersome Calculations\\r\\n\\r\\nWhen sampling without replacement and the sample\\r\\nsize is no more than 5% of the size of the population,\\r\\ntreat the selections as being independent (even though\\r\\nthey are actually dependent).\\r\\n\\r\\n and even though technically they're not.  Okay?  Because if your sample is less than 5% of the population,  then picking out a person,  and then not putting them back,  is not really gonna change the probability  that when you pick another person,  that person has also heard of Twitter.  It'll change it just a little bit,  but not really enough to matter all that much.\", 'The word success as used here is arbitrary and does\\r\\nnot necessarily represent something good. Either of the\\r\\ntwo possible categories may be called the success S as\\r\\nlong as its probability is identified as p.\\r\\n\\r\\nCAUTION When using a binomial probability distribution,\\r\\nalways be sure that x and p are consistent in the sense\\r\\n\\r\\nthat they both refer to the same category being called a\\r\\nsuccess.\\r\\n\\r\\ncopyiht\\r\\n\\r\\n2018, 2014, 2012 Parzen Edveaton, Ine. Al RightsReserved Oranen\\r\\n the word success as used here is arbitrary and does not', 'Method 1: Binomial Probability Formula\\r\\n\\r\\nP(x) = C(m, x) p* qh ™\\r\\nforx=0,1,2,...,n\\r\\nwhere\\r\\nn= number of trials\\r\\nx = number of successes among n trials\\r\\nPp = probability of success in any one trial\\r\\nq = probability of failure in any one trial (q = 1 - p)\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Education, Ine, Al Rights Reserved\\r\\n Okay, so here is the formula for finding a binomial probability.  The probability of exactly x successes, you do n-choose x, multiply by p to the power x,  and then multiply by q to the power n-ax.  And again, the reason for that is there are n-choose x ways or different outcomes  that have exactly x.', \"nomial Probab\\r\\n\\r\\non for B\\r\\n\\r\\nIDUTIONS (2 of 3)\\r\\n\\r\\nX - a specific number of successes in n trials, so x can\\r\\nbe any whole number between 0 and n, inclusive\\r\\n\\r\\nPp - probability of success in one of the n trials\\r\\n\\r\\nq - probability of failure in one of the n trials\\r\\n\\r\\nP(x) - probability of getting exactly x successes among\\r\\nthe n trials\\r\\n\\r\\n‘copyit © 2048, 2014, 2012 Pearson Education, Ine. Al Rights Reserved\\r\\n we're going to be using. So we're going to use X to stand for a specific number of successes  in N trials. So one of the examples we're going to do with the pop quiz is what is the probability  of getting exactly three questions right? And we had, I think, about five people, get three  questions right? So in that example, X would be three.\", 'iple\\r\\n\\r\\nSolution\\r\\n3. The probability of success (getting a person who knows\\r\\nwhat Twitter is) for one selection is 0.85, so p = 0.85.\\r\\n\\r\\n4. The probability of failure (not getting someone who\\r\\nknows what Twitter is) is 0.15, so q = 0.15.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Education, Inc, All Rights Reserved Oranwn\\r\\n P is 0.85 and Q is 0.15.', \"Football «. z\\r\\n\\r\\nSolution\\r\\n\\r\\nThe Excel display on the next page shows that the probability\\r\\nof 252 or more wins in 460 overtime games is 0.0224\\r\\n(rounded), which is low (such as less than 0.05). This shows\\r\\nthat it is unlikely that we would get 252 or more wins by\\r\\nchance. If we effectively rule out chance, we are left with the\\r\\nmore reasonable explanation that the team winning the\\r\\novertime coin toss has a better chance of winning the game.\\r\\n\\r\\nCCopyiht © 2038, 2014, 2012 Pearson Education, Oran\\r\\n\\r\\n Instead is used Excel.  Okay?  So the Excel page display on the next page  shows that the probability of 252 or more wins  in 460 games is 0.0224.  So let's have a look.\", '* Binomial Probability Distribution\\r\\n—Abinomial probability distribution results from a\\r\\nprocedure that meets these four requirements:\\r\\n3. Each trial must have all outcomes classified into\\r\\nexactly two categories, commonly referred to as\\r\\nsuccess and failure.\\r\\n\\r\\n4. The probability of a success remains the same in\\r\\nall trials.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Education, Ine. Al Rights Reserved\\r\\n Third requirement for a probability.', 'ple:\\r\\n\\r\\nSolution\\r\\n\\r\\na. This procedure does satisfy the requirements for a\\r\\nbinomial distribution, as shown below.\\r\\n\\r\\n1. The number of trials (5) is fixed\\r\\n\\r\\n2. The 5 trials are independent because the probability of\\r\\nany adult knowing Twitter is not affected by results from\\r\\nother selected adults.\\r\\n\\r\\n‘Copy © 2048, 2014, 2012 Pearson Education,\\r\\n All the stuff we talked about, five extra aisle, trials are in the pen day.', \"+ Binomial Probability Distribution\\r\\n—Abinomial probability distribution results from a\\r\\nprocedure that meets these four requirements:\\r\\n\\r\\nThe procedure has a fixed number of trials. (A\\r\\ntrial is a single observation.)\\r\\n\\r\\n2. The trials must be independent, meaning that the\\r\\n‘outcome of any individual trial doesn't affect the\\r\\nprobabilities in the other trials.\\r\\n\\r\\n‘Copyiht © 2038, 2014, 2012 Pearson Education, Inc. Al Rights Reserved Oranon\\r\\n All right.\", \"5% Guideline for Cumbersome Calculations\\r\\n\\r\\nWhen sampling without replacement and the sample\\r\\nsize is no more than 5% of the size of the population,\\r\\ntreat the selections as being independent (even though\\r\\nthey are actually dependent).\\r\\n\\r\\nCcopyit © 2048, 2014, 2012 Pearson Education, Ine. Al Rights Reserved\\r\\n\\r\\n All right.  Here's that guideline that I was referring to.\", \"Pop quiz!\\r\\n\\r\\n Alright, so we're going...\", 'X=number Frequency Relative freq. Theoretical\\r\\n\\r\\nright prob.\\r\\n0 3 wi 056\\r\\n\\r\\n1 4 148 188\\r\\n\\r\\n2 9 333 282\\r\\n\\r\\n3 5 185 250\\r\\n\\r\\n4 3 it 146\\r\\n\\r\\n5 3 a 088\\r\\n\\r\\n6 0 000 016,\\r\\n\\r\\n7 ° 000 003\\r\\n\\r\\n8 ° 000 (0004\\r\\n8 ° 000 (00003\\r\\n10 0 ‘000 (000001\\r\\n\\r\\nCCopyriht © 2038, 2014, 2012 Pearson Edveation, Inc.All Rights Reserved\\r\\n\\r\\n We did earlier, 0.250, 0.146, 0.058, 0.016, and then these ones are really, really low.', 'Example: Twitter ors\\r\\n\\r\\nSolution\\r\\nUsing the given values of n, x, p, and q in the binomial\\r\\nprobability formula, we get\\r\\n\\r\\n!\\r\\nP(3)=—> 85°.0.15°°\\r\\n6-331\\r\\n\\r\\n= ©! .0.614128-0.0225\\r\\n2131\\r\\n\\r\\n= (10)(0.614125)(0.0225)\\r\\n= 0.138178\\r\\n= 0.138 (round to three significant digits)\\r\\n\\r\\nThe probability of getting exactly three adults who know\\r\\nTwitter among five randomly selected adults is 0.138.\\r\\n\\r\\n how they did.', \"Results for a re\\r\\n\\r\\n+ Here are the results for a recent class who did this experiment. The\\r\\n\\r\\nnumber of students with each score is given, along with the relative\\r\\n\\r\\nfrequen\\r\\nrequency. “x= number right Frequency Relative freq.\\r\\n\\r\\n0 3 Tal\\r\\n148\\r\\n333\\r\\n185\\r\\n44\\r\\n11\\r\\n(000\\r\\n.000\\r\\n000\\r\\n.000\\r\\n(000\\r\\n\\r\\n4\\r\\n8\\r\\n5\\r\\n3\\r\\n3\\r\\n0\\r\\n0\\r\\n0\\r\\n0\\r\\n0\\r\\n\\r\\n0\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Education, Inc. Al Rights Reserved\\r\\n We did that the other day. So these were our results in this class that I'm standing in right now. We had three people who got zero right  We had four people who got one right nine people got two right  Five people got three right three people got four right three people got five right nobody got six or more right  All right, so if you're watching the video just see which of those categories do you fall in  Okay, and then what we're gonna do here in a little while is we're gonna compare this to  What kinds of results would I have expected because it turns out that this experiment  Taking a pop quiz and just guessing at every answer is an example of a binomial  distribution\", \"Pop quiz! —\\r\\n\\r\\n* Number your paper 1-10. There will be 10 vs\\r\\nquestions, each with four choices (A, B, C, or D).\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Edueation, Ine, Al Rights Reserved rear\\r\\n play along at home. And there's going to be 10 questions each\", 'Relative freq. Theoretical\\r\\nprob.\\r\\n\\r\\no 3 ii 056\\r\\n\\r\\n1 4 148 188\\r\\n\\r\\n2 9 333 282\\r\\n\\r\\n3 5 185 250\\r\\n\\r\\n4 3 11 146\\r\\n\\r\\n5 3 a1 088\\r\\n\\r\\n6 0 000 016\\r\\n\\r\\n7 ° 000 003\\r\\n\\r\\n8 ° ‘000 (0004\\r\\n\\r\\n9 ° 000 (00003\\r\\n\\r\\n10 0 000 (000001\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Edueaion, In, Al Rights Reserved @rsrwn\\r\\n So hopefully you were able to find the probability.', \"5% Guideline for Cumbersome Calculations\\r\\n\\r\\nWhen sampling without replacement and the sample\\r\\nsize is no more than 5% of the size of the population,\\r\\ntreat the selections as being independent (even though\\r\\nthey are actually dependent).\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Edueation, Inc.All Rights Reserved Oran\\r\\n more than 5% of the size of the pop you'll...\", \"The word success as used here is arbitrary and does\\r\\nnot necessarily represent something good. Either of the\\r\\ntwo possible categories may be called the success S as\\r\\nlong as its probability is identified as p.\\r\\n\\r\\nCAUTION When using a binomial probability distribution,\\r\\nalways be sure that x and p are consistent in the sense\\r\\n\\r\\nthat they both refer to the same category being called a\\r\\nsuccess.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Edueation, Ine,\\r\\n\\r\\nAl Rights Reserves Oranwn\\r\\n is a particularly dangerous intersection somewhere in Merced.  So you study to see how many accidents happen in a year at that intersection.  You might call the event, you know, having an accident at that intersection,  that might be called a success.  As weird as that sounds.  It really just means like the outcome of interest,  not necessarily something good.  So when using a binomial probability distribution,  be sure that X and P are consistent throughout the problem.  Okay.  So X is the number of successes.  P is the probability of success.  So once you decide which category of outcomes,  you're going to call a success.  You need to stick with that throughout the problem.  Okay.\", \"®\\r\\n\\r\\nple:\\r\\n\\r\\nWhen an adult is randomly selected (with replacement),\\r\\nthere is a 0.85 probability that this person knows what\\r\\n‘Twitter is (based on results from a Pew Research\\r\\nCenter survey). Suppose that we want to find the\\r\\nprobability that exactly three of five randomly selected\\r\\nadults know what Twitter is.\\r\\n\\r\\na. Does this procedure result in a binomial distribution?\\r\\n\\r\\nb. If this procedure does result in a binomial distribution,\\r\\nidentify the values of n, x, p, and g.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Edueation, Ine.\\r\\n\\r\\nA Rights Reserved Oran\\r\\n C major is a binomial distribution.  So let's see, what is N and is the number of trials  that would be five, right?  Five trials and we wanna know  what's the probability that exactly three?  No what Twitter is, so that would make X3.  Success is the person has heard of Twitter.  So the probability of success would be 0.85,  which means the probability of failure  would be 0.15, right?  One minus point.\", \"Sand F (success and failure) denote the two\\r\\npossible categories of all outcomes.\\r\\n\\r\\nP(S)=p (p = probability of a success)\\r\\nP(F)=1-p=q (q= probability of a failure)\\r\\nn the fixed number of trials\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Edveation, Inc.All Rights Reserved\\r\\n\\r\\n Okay. Notation. So, P little P is what we always use for the probability of success.  And then Q is what we use for the probability of failure. Now, since the only possibilities are success or failure,  P and Q have to add up to 1. Okay. So, if I tell you P, you automatically know Q, because it's just 1 minus P.  All right. So, again, in the pop quiz example, P, which is the probability of getting any specific question right, that would be 1, 4th.  Because there's one correct answer out of 4. And that means Q would be 3, 4th.  Okay. 1 minus 1, 4th.\", 'X=number Frequency Relative freq. Theoretical “\\r\\nright prob.\\r\\n0 3 ra 056\\r\\n\\r\\n1 4 148 188\\r\\n\\r\\n2 9 333 282\\r\\n\\r\\n3 5 485 250\\r\\n\\r\\n4 3 11 146\\r\\n\\r\\n5 3 a1 088\\r\\n\\r\\n6 ° ‘000 016\\r\\n\\r\\n7 0 000 003\\r\\n\\r\\n8 ° ‘000 (0004\\r\\n9 ° 000 (00003\\r\\n40 0 000 000001\\r\\n\\r\\n used your specific number or whatever you got.  And here they are.  So it turns out that the probability of getting  non-right is actually about .056 in the class that  sitting here in front of me.  It was higher than that.  It was about .111.  Probability getting one right is about .188.  Kind of close to what we saw in the class sitting here.', \"The Answers — how did you do?\\r\\n\\r\\n answers right or wrong. Number three is D. Number four is B. Five is B. Six is D. Seven is D. Eight is C. Nine is C. And ten is B. So what I'm going to do right now is I'm going to ask the class that sitting here in the room with me how they did and we're going to count how many people got zero right how many people got one right how many people got to right.  It's center, it's center, it's center, it's center.\", \"2\\r\\n\\r\\n+ How many did you get right on the pop quiz? Find the\\r\\nprobability of getting that many right by chance, using the\\r\\nformula. If you got three right, we already did that\\r\\nproblem, so find P(6) instead, the probability of getting 6\\r\\nright. We'll compare these theoretical probabilities to the\\r\\nresults we observed in our class.\\r\\n\\r\\ncopyright © 2038, 2014, 2012 Pearson Education, In. Al Rights Reserved Oren\\r\\nnan\", \"ab\\r\\n\\r\\n* Binomial Probability Distribution\\r\\n—Abinomial probability distribution results from a\\r\\nprocedure that meets these four requirements:\\r\\nThe procedure has a fixed number of trials. (A\\r\\ntrial is a single observation.)\\r\\n2. The trials must be independent, meaning that the\\r\\n\\r\\n‘outcome of any individual trial doesn't affect the\\r\\nprobabilities in the other trials.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Education,\\r\\n\\r\\n It has four requirements.  Number one, the procedure has a fixed number of trials.  So in this pop quiz example, the trials are the questions.  Each time you get to a new question, you pick an answer.  The trials have to be independent,  meaning that the outcome of any individual trial  doesn't affect the probabilities and the other trials.  So if you get number one right, that does not affect how likely you are to get number two right.  If you get number two right, that doesn't affect how likely you are to get number three right.  Et cetera, et cetera, et cetera.\", \"nan Okay, now I'm just going to go ahead and hit times.  And then I'm going to say 0.85 to the power 3.  And then I'm going to say times 0.15 to the power 2, right? 5 minus 3 is 2.  All right, so if I did this correctly, the probability that when you ask 5 adults,  have you ever heard of Twitter that exactly 3 of them say yes is 0.138.\", 'Pop quiz! i\\r\\n\\r\\n* Number your paper 1-10. There will be 10\\r\\nquestions, each with four choices (A, B, C, or D).\\r\\n\\r\\nCopyright © 2038, 2014, 2012 PeartanEdueation, In. Al Rights Reserved ran\\r\\nnan', \"Solution\\r\\n\\r\\nThe Excel display on the next page shows that the probability\\r\\nof 252 or more wins in 460 overtime games is 0.0224\\r\\n(rounded), which is low (such as less than 0.05). This shows\\r\\nthat it is unlikely that we would get 252 or more wins by\\r\\nchance. If we effectively rule out chance, we are left with the\\r\\nmore reasonable explanation that the team winning the\\r\\novertime coin toss has a better chance of winning the game.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Education, Ine, Al Rights Reserved Orne\\r\\n Our sort of working definition of what is an unusual event is anything that has probability  0.05 or less.  Since this probability is less than 0.05, we're going to say that that's an unusual event.  252 is unusually high.  So what that tells me is that maybe my assumption that wins and losses are equally likely  was wrong.  And maybe it's true that the team that wins the overtime coin toss has an advantage in  actually winning the game.\", \"We previously noted that between 1974 and 2011, there\\r\\nwere 460 NFL football games decided in overtime, and\\r\\n252 of them were won by the team that won the\\r\\novertime coin toss. Is:the result of 252 wins in the 460\\r\\ngames equivalent to random chance, or is 252 wins\\r\\nsignificantly high? We can answer that question by\\r\\nfinding the probability of 252 wins or more in 460\\r\\ngames, assuming that wins and losses are equally\\r\\n\\r\\nlikely.\\r\\n\\r\\nCopyright © 2038, 2014, 2012 Pearson Edueation, Ine.\\r\\n\\r\\nAll Rights Reserved Orearso0,\\r\\n Okay, so here's a good example for technology.  We previously noted, I don't remember doing that, but apparently at some point we did.  That between 1974 and 2011, that we're 460 NFL games decided it over time.  252 of them were won by the team at one over time coin toss.  So the question is, is the result of 252 wins in 460 games?  Could that happen by chance? Is that likely to happen by chance?  Or is that number of wins significantly high?  And we're going to assume at first that winning the overtime coin toss does not put you at an advantage for winning the game.  So winning and losing, we're going to assume that those are equally likely.  So I'm going to do this problem using Excel.\"]\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T11:08:55.093104Z",
     "start_time": "2024-07-13T11:08:54.624330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get img_path\n",
    "img_path = df_data_extensive.iloc[0].to_dict().values()\n",
    "\n",
    "# convert to list\n",
    "img_path = list(img_path)\n",
    "img_path = img_path[1:]"
   ],
   "id": "7d88398a78cded6b",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T11:09:03.477489Z",
     "start_time": "2024-07-13T11:08:55.094113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Embedd with LLM long summary\n",
    "logger.info(f\"Embedd with LLM long summary\")\n",
    "\n",
    "result = []\n",
    "\n",
    "embedding_model = EmbeddingsModel()\n",
    "\n",
    "embedding_model.text_embeddings = None\n",
    "\n",
    "embedding_model.img_paths = None\n",
    "\n",
    "embedding_model.img_paths = img_path\n",
    "\n",
    "embeddings = embedding_model.generate_dataset_embeddings_standard_tokenizer(llm_long_summary)\n",
    "\n",
    "embedding_model.text_embeddings = embeddings\n",
    "\n",
    "logger.info(f\"Embedding Model.text_embeddings: {embedding_model.text_embeddings}\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "rows = get_results(df)\n",
    "\n",
    "df_extensive_summary = pd.DataFrame(rows, columns=['Prompt', 'GT_Keyframe', 'Top_1', 'Top_2', 'Top_3'])\n",
    "\n",
    "# Save dataframe to CSV\n",
    "df_extensive_summary.to_csv('df_standard_llm_long_summary_math.csv', index=False)\n"
   ],
   "id": "9c8f865ed02fb866",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-07-13 13:08:55.362\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m2\u001B[0m - \u001B[1mEmbedd with LLM long summary\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:02.844\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m18\u001B[0m - \u001B[1mEmbedding Model.text_embeddings: tensor([[-0.1807,  0.0187, -0.0795,  ..., -0.0288, -0.0470,  0.1070],\n",
      "        [-0.0751, -0.1122, -0.1110,  ...,  0.1050,  0.0080, -0.0782],\n",
      "        [ 0.1494, -0.0069, -0.1828,  ...,  0.1257, -0.1049,  0.2026],\n",
      "        ...,\n",
      "        [ 0.0975,  0.2250,  0.0211,  ...,  0.3876, -0.1169,  0.2771],\n",
      "        [ 0.1336, -0.2133, -0.2561,  ...,  0.2625, -0.0250, -0.1052],\n",
      "        [ 0.0451, -0.1206, -0.2157,  ...,  0.3979, -0.0515,  0.0212]])\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:02.859\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mwhat is a binomial probability distribution?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:02.890\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8725, 0.7878, 0.7841]),\n",
      "indices=tensor([ 7,  4, 69])) - GT is keyframe number 18\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:02.890\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:02.906\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:02.906\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 7 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-002-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:02.906\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:02.906\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 4 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-034-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:02.906\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:02.906\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 69 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-033-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:02.916\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mx is a specific number of successes in n trials\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:02.954\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.6408, 0.6305, 0.6106]),\n",
      "indices=tensor([15,  1, 44])) - GT is keyframe number 25\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:02.954\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:02.954\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:02.954\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 15 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-024-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:02.954\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:02.954\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 1 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-026-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:02.954\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:02.954\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 44 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-060-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:02.969\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mP(F) = 1 -p \u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.001\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.4671, 0.4343, 0.4326]),\n",
      "indices=tensor([50, 64,  1])) - GT is keyframe number 23\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.001\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.001\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.016\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 50 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-027-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.016\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.016\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 64 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-025-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.016\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.016\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 1 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-026-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.016\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mwhat procedures does the binomial probability distribution results from?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.063\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8385, 0.8266, 0.8251]),\n",
      "indices=tensor([84,  4, 69])) - GT is keyframe number 29\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.063\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.063\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.063\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 84 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-019-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.063\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.063\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 4 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-034-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.063\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.063\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 69 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-033-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.063\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the binomial probability formula?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.110\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7823, 0.7717, 0.7590]),\n",
      "indices=tensor([31, 44, 16])) - GT is keyframe number 58\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.110\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.110\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.110\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 31 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-086-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.125\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.128\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 44 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-060-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.128\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.128\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 16 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-059-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.128\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the method 2 for finding the binomial probabilities?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.172\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7988, 0.7964, 0.7839]),\n",
      "indices=tensor([16, 54, 63])) - GT is keyframe number 80\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.172\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.172\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.172\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 16 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-059-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.172\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.172\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.172\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.172\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 63 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-058-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.172\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mHow many NFL Football games betweem 1974 and 2011 there is?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.219\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7546, 0.7020, 0.4718]),\n",
      "indices=tensor([33, 88, 66])) - GT is keyframe number 85\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.228\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.228\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.228\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 33 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-084-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.228\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.228\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 88 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-085-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.228\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.235\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 66 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-087-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.235\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat are the key concepts of the lecture\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.282\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7331, 0.7164, 0.6883]),\n",
      "indices=tensor([82, 18, 25])) - GT is keyframe number 3\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.282\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.282\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.282\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 82 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-015-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.282\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.282\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 18 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-012-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.282\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.282\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 25 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-008-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.298\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the probability of failure in the twitter example?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.334\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8605, 0.7708, 0.7092]),\n",
      "indices=tensor([65, 30,  8])) - GT is keyframe number 46\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.334\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.334\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.334\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 65 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-046-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.334\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.334\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 30 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-032-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.334\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.349\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 8 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-061-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.349\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mUsing the given values of n x and q\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.396\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.4622, 0.4537, 0.4492]),\n",
      "indices=tensor([44, 63, 48])) - GT is keyframe number 65\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.396\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.396\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.396\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 44 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-060-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.396\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.396\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 63 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-058-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.396\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.396\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 48 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-044-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.396\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mprobability of success remains the same in all trials\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.443\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.6307, 0.6236, 0.6207]),\n",
      "indices=tensor([42, 67, 13])) - GT is keyframe number 22\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.443\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.452\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.453\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 42 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-022-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.456\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.457\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 67 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-021-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.458\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:03.459\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 13 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-036-01.jpg\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T11:09:12.313677Z",
     "start_time": "2024-07-13T11:09:03.477489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Embedd with OCR ONLY \n",
    "logger.info(f\"Embedd with OCR ONLY \")\n",
    "\n",
    "result = []\n",
    "\n",
    "embedding_model = EmbeddingsModel()\n",
    "\n",
    "embedding_model.text_embeddings = None\n",
    "\n",
    "embedding_model.img_paths = None\n",
    "\n",
    "embedding_model.img_paths = img_path\n",
    "\n",
    "# need to be embedded\n",
    "\n",
    "embeddings = embedding_model.generate_dataset_embeddings_standard_tokenizer(ocr_only)\n",
    "\n",
    "embedding_model.text_embeddings = embeddings\n",
    "\n",
    "# already embedded \n",
    "#\n",
    "# if isinstance(embedding_model.text_embeddings, list):\n",
    "#     for i, text_embedding in enumerate(embedding_model.text_embeddings):\n",
    "#         logger.info(text_embedding)\n",
    "#         # Regular expression pattern to find numeric values\n",
    "#         numeric_pattern = r\"[-+]?\\d*\\.\\d+(?:[eE][-+]?\\d+)?\"\n",
    "#         \n",
    "#         # Extract numeric values from the tensor string\n",
    "#         tensor_values_str = re.findall(numeric_pattern, text_embedding)\n",
    "#         \n",
    "#         # Convert the extracted string values to float\n",
    "#         tensor_values = [float(value) for value in tensor_values_str]\n",
    "#         \n",
    "#         # Create a PyTorch tensor from the list of floats\n",
    "#         embedding_model.text_embeddings[i] = torch.tensor(tensor_values)\n",
    "#         \n",
    "# \n",
    "# # create one single torch for sim search \n",
    "# embedding_model.text_embeddings = torch.stack(embedding_model.text_embeddings, dim=0)\n",
    "# \n",
    "# logger.info(f\"Embedding Model.text_embeddings: {embedding_model.text_embeddings}\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "rows = get_results(df)\n",
    "\n",
    "df_ocr_only = pd.DataFrame(rows, columns=['Prompt', 'GT_Keyframe', 'Top_1', 'Top_2', 'Top_3'])\n",
    "\n",
    "# Save dataframe to CSV\n",
    "df_ocr_only.to_csv('df_standard_ocr_only_math.csv', index=False)\n",
    "logger.info('Saved old_df_standard_ocr_only_math.csv')"
   ],
   "id": "fe5c14edaf32d616",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-07-13 13:09:03.817\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m2\u001B[0m - \u001B[1mEmbedd with OCR ONLY \u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.194\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mwhat is a binomial probability distribution?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.352\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7391, 0.7355, 0.7067]),\n",
      "indices=tensor([54,  0, 31])) - GT is keyframe number 18\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.357\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.357\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.357\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.361\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.362\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 0 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-080-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.362\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.362\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 31 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-086-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.362\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mx is a specific number of successes in n trials\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.443\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8626, 0.8490, 0.7650]),\n",
      "indices=tensor([50, 15, 64])) - GT is keyframe number 25\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.447\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.447\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.447\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 50 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-027-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.451\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.452\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 15 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-024-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.452\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.452\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 64 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-025-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.457\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mP(F) = 1 -p \u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.519\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.4772, 0.4752, 0.4730]),\n",
      "indices=tensor([44, 16, 63])) - GT is keyframe number 23\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.519\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.522\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.524\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 44 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-060-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.532\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.535\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 16 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-059-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.535\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.535\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 63 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-058-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.535\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mwhat procedures does the binomial probability distribution results from?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.627\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7642, 0.7612, 0.7514]),\n",
      "indices=tensor([54,  0,  4])) - GT is keyframe number 29\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.627\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.630\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.630\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.632\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.632\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 0 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-080-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.635\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.635\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 4 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-034-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.638\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the binomial probability formula?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.712\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7726, 0.7385, 0.7307]),\n",
      "indices=tensor([31, 54,  0])) - GT is keyframe number 58\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.712\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.717\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.719\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 31 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-086-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.719\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.719\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.723\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.723\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 0 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-080-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.723\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the method 2 for finding the binomial probabilities?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.793\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8205, 0.8190, 0.7780]),\n",
      "indices=tensor([54,  0, 20])) - GT is keyframe number 80\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.797\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.802\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.802\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.802\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.807\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 0 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-080-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.807\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.810\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 20 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-082-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.812\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mHow many NFL Football games betweem 1974 and 2011 there is?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.913\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7581, 0.7421, 0.4597]),\n",
      "indices=tensor([88, 33, 66])) - GT is keyframe number 85\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.914\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.916\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.916\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 88 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-085-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.919\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.919\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 33 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-084-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.922\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.923\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 66 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-087-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.926\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat are the key concepts of the lecture\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.992\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.3661, 0.3357, 0.3162]),\n",
      "indices=tensor([ 7, 45, 23])) - GT is keyframe number 3\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.997\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.997\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:11.997\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 7 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-002-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.000\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.003\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 45 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-003-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.005\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.005\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 23 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-004-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.008\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the probability of failure in the twitter example?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.082\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8505, 0.7551, 0.7091]),\n",
      "indices=tensor([65, 27, 38])) - GT is keyframe number 46\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.086\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.086\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.090\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 65 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-046-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.092\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.093\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 27 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-043-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.094\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.096\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 38 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-065-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.098\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mUsing the given values of n x and q\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.197\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.5318, 0.5165, 0.5152]),\n",
      "indices=tensor([50, 15, 31])) - GT is keyframe number 65\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.200\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.203\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.203\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 50 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-027-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.203\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.203\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 15 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-024-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.207\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.207\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 31 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-086-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.210\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mprobability of success remains the same in all trials\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.282\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.6824, 0.6684, 0.6588]),\n",
      "indices=tensor([ 1, 15, 50])) - GT is keyframe number 22\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.283\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.286\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.288\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 1 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-026-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.288\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.288\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 15 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-024-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.288\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.292\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 50 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-027-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:12.300\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m51\u001B[0m - \u001B[1mSaved old_df_standard_ocr_only_math.csv\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T11:09:24.438765Z",
     "start_time": "2024-07-13T11:09:12.315726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Embedd with OCR TRANSCRIPTIONS\n",
    "# TODO: Doesn't work since transcriptions are nans\n",
    "logger.info(f\"Embedd with TRANSCRIPTIONS\")\n",
    "\n",
    "result = []\n",
    "\n",
    "embedding_model = EmbeddingsModel()\n",
    "\n",
    "embedding_model.text_embeddings = None\n",
    "\n",
    "embedding_model.img_paths = None\n",
    "\n",
    "embedding_model.img_paths = img_path\n",
    "\n",
    "embeddings = embedding_model.generate_dataset_embeddings_standard_tokenizer(concat_result_ocr_transcriptions)\n",
    "\n",
    "embedding_model.text_embeddings = embeddings\n",
    "\n",
    "logger.info(f\"Embedding Model.text_embeddings: {embedding_model.text_embeddings}\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "rows = get_results(df)\n",
    "\n",
    "df_ocr_transcriptions = pd.DataFrame(rows, columns=['Prompt', 'GT_Keyframe', 'Top_1', 'Top_2', 'Top_3'])\n",
    "\n",
    "# Save dataframe to CSV\n",
    "df_ocr_transcriptions.to_csv('df_standard_df_ocr_transcriptions_math.csv', index=False)"
   ],
   "id": "547f01970c56eff2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-07-13 13:09:13.042\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m3\u001B[0m - \u001B[1mEmbedd with TRANSCRIPTIONS\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.252\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m19\u001B[0m - \u001B[1mEmbedding Model.text_embeddings: tensor([[-0.1558, -0.0281, -0.0629,  ..., -0.0501, -0.1999,  0.0217],\n",
      "        [-0.0288, -0.0639, -0.1174,  ...,  0.2123,  0.0999, -0.0971],\n",
      "        [ 0.0047, -0.1774, -0.1902,  ...,  0.1141,  0.0542,  0.1336],\n",
      "        ...,\n",
      "        [-0.1746,  0.2062,  0.1619,  ...,  0.2807, -0.0483,  0.2825],\n",
      "        [ 0.1472, -0.0332, -0.2890,  ...,  0.1943,  0.0194, -0.0999],\n",
      "        [ 0.0034, -0.1747, -0.1204,  ...,  0.2931,  0.0011, -0.0896]])\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.252\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mwhat is a binomial probability distribution?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.348\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7256, 0.7189, 0.7067]),\n",
      "indices=tensor([ 0, 54, 31])) - GT is keyframe number 18\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.348\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.356\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.356\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 0 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-080-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.356\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.356\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.362\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.362\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 31 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-086-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.364\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mx is a specific number of successes in n trials\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.435\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8476, 0.8266, 0.7559]),\n",
      "indices=tensor([15, 50, 64])) - GT is keyframe number 25\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.435\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.435\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.435\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 15 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-024-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.435\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.435\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 50 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-027-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.435\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.451\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 64 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-025-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.453\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mP(F) = 1 -p \u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.559\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.4860, 0.4736, 0.4711]),\n",
      "indices=tensor([ 1, 64, 24])) - GT is keyframe number 23\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.562\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.562\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.562\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 1 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-026-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.562\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.569\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 64 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-025-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.570\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.570\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 24 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-075-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.570\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mwhat procedures does the binomial probability distribution results from?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.657\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7491, 0.7481, 0.7468]),\n",
      "indices=tensor([ 0, 28, 39])) - GT is keyframe number 29\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.657\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.657\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.657\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 0 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-080-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.657\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.657\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 28 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-020-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.673\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.675\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 39 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-018-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.675\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the binomial probability formula?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.745\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7726, 0.7272, 0.7214]),\n",
      "indices=tensor([31,  0, 54])) - GT is keyframe number 58\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.753\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.753\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.753\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 31 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-086-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.753\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.753\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 0 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-080-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.753\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.753\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.753\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the method 2 for finding the binomial probabilities?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.879\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8306, 0.7804, 0.7728]),\n",
      "indices=tensor([ 0, 54, 22])) - GT is keyframe number 80\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.879\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.879\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.879\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 0 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-080-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.887\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.887\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.887\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.887\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 22 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-079-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.887\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mHow many NFL Football games betweem 1974 and 2011 there is?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.975\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7581, 0.7421, 0.4554]),\n",
      "indices=tensor([88, 33, 66])) - GT is keyframe number 85\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.975\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.975\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.983\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 88 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-085-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.985\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.985\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 33 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-084-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.987\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.987\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 66 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-087-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:23.987\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat are the key concepts of the lecture\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.072\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.3465, 0.3417, 0.3376]),\n",
      "indices=tensor([82, 45,  7])) - GT is keyframe number 3\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.072\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.080\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.080\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 82 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-015-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.080\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.080\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 45 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-003-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.080\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.080\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 7 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-002-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.091\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the probability of failure in the twitter example?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.184\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8425, 0.7883, 0.7065]),\n",
      "indices=tensor([65, 27,  8])) - GT is keyframe number 46\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.185\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.185\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.185\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 65 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-046-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.185\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.185\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 27 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-043-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.185\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.185\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 8 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-061-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.185\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mUsing the given values of n x and q\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.299\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.5152, 0.5062, 0.4966]),\n",
      "indices=tensor([31, 64, 15])) - GT is keyframe number 65\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.299\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.299\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.310\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 31 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-086-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.310\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.314\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 64 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-025-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.314\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.318\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 15 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-024-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.320\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mprobability of success remains the same in all trials\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.405\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.6748, 0.6686, 0.6488]),\n",
      "indices=tensor([15, 50,  1])) - GT is keyframe number 22\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.405\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.405\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.405\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 15 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-024-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.405\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.414\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 50 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-027-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.414\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:24.414\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 1 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-026-01.jpg\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T11:09:37.460085Z",
     "start_time": "2024-07-13T11:09:24.438765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Embedd with OCR LAVA\n",
    "logger.info(f\"Embedd with OCR LAVA\")\n",
    "\n",
    "result = []\n",
    "\n",
    "embedding_model = EmbeddingsModel()\n",
    "\n",
    "embedding_model.text_embeddings = None\n",
    "\n",
    "embedding_model.img_paths = None\n",
    "\n",
    "embedding_model.img_paths = img_path\n",
    "\n",
    "embeddings = embedding_model.generate_dataset_embeddings_standard_tokenizer(concat_result_ocr_lava)\n",
    "\n",
    "embedding_model.text_embeddings = embeddings\n",
    "\n",
    "rows = []\n",
    "\n",
    "rows = get_results(df)\n",
    "\n",
    "df_ocr_lava = pd.DataFrame(rows, columns=['Prompt', 'GT_Keyframe', 'Top_1', 'Top_2', 'Top_3'])\n",
    "\n",
    "# Save dataframe to CSV\n",
    "df_ocr_lava.to_csv('df_standard_ocr_lava_math.csv', index=False)"
   ],
   "id": "1ffe907012ae084f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-07-13 13:09:25.415\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m2\u001B[0m - \u001B[1mEmbedd with OCR LAVA\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.505\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mwhat is a binomial probability distribution?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.584\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7246, 0.7208, 0.7160]),\n",
      "indices=tensor([28, 42, 54])) - GT is keyframe number 18\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.584\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.584\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.584\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 28 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-020-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.584\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.584\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 42 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-022-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.600\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.600\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.600\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mx is a specific number of successes in n trials\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.663\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8463, 0.8440, 0.7461]),\n",
      "indices=tensor([50, 15, 64])) - GT is keyframe number 25\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.663\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.663\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.663\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 50 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-027-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.663\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.678\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 15 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-024-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.679\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.679\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 64 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-025-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.682\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mP(F) = 1 -p \u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.776\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.4704, 0.4644, 0.4641]),\n",
      "indices=tensor([16,  1, 63])) - GT is keyframe number 23\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.776\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.776\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.776\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 16 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-059-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.776\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.776\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 1 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-026-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.776\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.776\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 63 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-058-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.792\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mwhat procedures does the binomial probability distribution results from?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.855\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7686, 0.7662, 0.7572]),\n",
      "indices=tensor([28, 67, 42])) - GT is keyframe number 29\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.855\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.855\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.855\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 28 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-020-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.855\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.855\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 67 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-021-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.855\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.855\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 42 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-022-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.870\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the binomial probability formula?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.917\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7726, 0.7284, 0.7167]),\n",
      "indices=tensor([31, 44, 54])) - GT is keyframe number 58\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.933\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.933\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.933\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 31 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-086-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.933\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.933\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 44 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-060-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.933\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.933\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:36.933\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the method 2 for finding the binomial probabilities?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.027\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8077, 0.7951, 0.7772]),\n",
      "indices=tensor([54,  0, 22])) - GT is keyframe number 80\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.027\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.034\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.034\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.034\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.034\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 0 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-080-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.034\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.034\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 22 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-079-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.043\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mHow many NFL Football games betweem 1974 and 2011 there is?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.090\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7581, 0.7421, 0.4534]),\n",
      "indices=tensor([88, 33, 66])) - GT is keyframe number 85\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.106\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.106\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.106\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 88 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-085-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.106\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.106\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 33 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-084-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.106\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.106\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 66 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-087-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.106\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat are the key concepts of the lecture\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.169\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.4638, 0.4502, 0.4436]),\n",
      "indices=tensor([19, 59, 85])) - GT is keyframe number 3\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.169\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.169\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.169\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 19 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-063-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.169\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.184\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 59 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-062-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.184\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.184\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 85 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-064-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.184\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the probability of failure in the twitter example?\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.276\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8801, 0.7663, 0.7081]),\n",
      "indices=tensor([65, 27,  8])) - GT is keyframe number 46\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.276\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.276\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.276\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 65 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-046-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.291\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.291\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 27 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-043-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.291\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.291\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 8 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-061-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.291\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mUsing the given values of n x and q\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.354\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.5152, 0.5104, 0.4797]),\n",
      "indices=tensor([31, 50, 16])) - GT is keyframe number 65\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.354\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.354\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.354\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 31 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-086-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.354\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.354\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 50 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-027-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.354\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.354\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 16 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-059-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.370\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mprobability of success remains the same in all trials\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.417\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m157\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.6666, 0.6628, 0.6527]),\n",
      "indices=tensor([15, 50,  1])) - GT is keyframe number 22\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.432\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m159\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.434\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.434\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 15 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-024-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.434\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.434\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 50 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-027-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.434\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m167\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-13 13:09:37.434\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m168\u001B[0m - \u001B[1mMax similarity for index 1 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-026-01.jpg\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
