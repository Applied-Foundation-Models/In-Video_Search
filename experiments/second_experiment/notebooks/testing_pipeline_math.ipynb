{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-11T09:33:07.911622Z",
     "start_time": "2024-07-11T09:32:41.608706Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from src.text_embedder.embedder import text_to_embedding_transformer\n",
    "\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "\n",
    "from src.text_embedder.embedder import EmbeddingsModel\n",
    "\n",
    "from pathlib import Path\n",
    "import os"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baatout\\PycharmProjects\\afm-vlm\\.venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ed097945bf783f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Data",
   "id": "18eb4cd1dfbcf75c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T13:13:55.909966Z",
     "start_time": "2024-07-11T13:13:55.344237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "notebook_path = Path().resolve().parent\n",
    "print(notebook_path)\n",
    "\n",
    "# Construct the filename relative to the new path\n",
    "filename = notebook_path / \"test_frames_math1.csv\"\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(filename)\n",
    "print(df)"
   ],
   "id": "2f559ca01dfb8b08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baatout\\PycharmProjects\\afm-vlm\\experiments\\second_experiment\n",
      "    ID                                             Prompt Length  GT_Keyframe\n",
      "0    1       what is a binomial probability distribution?   long           18\n",
      "1    2    x is a specific number of successes in n trials   long           25\n",
      "2    3                                       P(F) = 1 -p   short           23\n",
      "3    4  what procedures does the binomial probability ...   long           29\n",
      "4    5          What is the binomial probability formula?   long           58\n",
      "5    6  What is the method 2 for finding the binomial ...   long           80\n",
      "6    7  How many NFL Football games betweem 1974 and 2...   long           85\n",
      "7    8           What are the key concepts of the lecture   long            3\n",
      "8    9  What is the probability of failure in the twit...   long           46\n",
      "9   10                Using the given values of n x and q   long           65\n",
      "10  11  probability of success remains the same in all...   long           22\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T13:13:56.462353Z",
     "start_time": "2024-07-11T13:13:56.240913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create dataframe to save results of the experiments\n",
    "columns = ['Prompt', 'GT_Keyframe', 'Top_1', 'Top_2', 'Top_3']\n",
    "\n",
    "df_test = pd.DataFrame(columns=columns)\n",
    "\n",
    "df_ocr_only = df_test\n",
    "df_ocr_lava = df_test\n",
    "df_ocr_transcriptions = df_test\n",
    "\n",
    "df_short_llm_summary = df_test\n",
    "df_extensive_summary = df_test"
   ],
   "id": "3482c90c7ba15df8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T13:13:57.326588Z",
     "start_time": "2024-07-11T13:13:57.110192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_to_df(prompt, gt_keyframe, result):\n",
    "    # Create a new row with the provided data\n",
    "    return {\n",
    "        'Prompt': prompt,\n",
    "        'GT_Keyframe': gt_keyframe,\n",
    "        'Top_1': extract_keyframe_number(result[0]) if len(result) > 0 else None,\n",
    "        'Top_2': extract_keyframe_number(result[1]) if len(result) > 1 else None,\n",
    "        'Top_3': extract_keyframe_number(result[2]) if len(result) > 2 else None\n",
    "    }\n",
    "\n",
    "\n",
    "# ietrate over the dataframe and get the results\n",
    "def get_results(df):\n",
    "    for _, row in df.iterrows():\n",
    "        logger.info(row['Prompt'])\n",
    "        prompt = row['Prompt']\n",
    "        gt_keyframe = row['GT_Keyframe']\n",
    "\n",
    "        # Search for similar images\n",
    "        output = embedding_model.search_similar_images_top_k(prompt, gt_keyframe, 3)\n",
    "        res_row = add_to_df(prompt, gt_keyframe, output)\n",
    "        rows.append(res_row)\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "def extract_keyframe_number(path):\n",
    "    \"\"\"\n",
    "    Extracts the scene number from the given file path.\n",
    "\n",
    "    Parameters:\n",
    "    path (str): The full path of the file.\n",
    "\n",
    "    Returns:\n",
    "    str: The extracted scene number.\n",
    "    \"\"\"\n",
    "    # Get filename without extension\n",
    "    filename = os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "    # Extract '032' from filename\n",
    "    scene_number = filename.split('-Scene-')[-1].split('-')[0]\n",
    "\n",
    "    return scene_number"
   ],
   "id": "b9b4e99d4b8ea54",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T13:13:58.166270Z",
     "start_time": "2024-07-11T13:13:57.941706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#top_3 = []\n",
    "#embedding_model.check_proximity_keyframes(90, top_3)"
   ],
   "id": "c471d13af2b4719f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "bd96b30ced9483bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LOAD MODEL ",
   "id": "b9f59e530248b7eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T13:14:03.363188Z",
     "start_time": "2024-07-11T13:13:59.137354Z"
    }
   },
   "cell_type": "code",
   "source": "embedding_model = EmbeddingsModel()",
   "id": "415087029f4c5533",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T13:14:03.748574Z",
     "start_time": "2024-07-11T13:14:03.363188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "csv = notebook_path / \"math_1.csv\"\n",
    "df_data_extensive = pd.read_csv(csv)\n",
    "df_data_extensive"
   ],
   "id": "f68a639265049b08",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                           Unnamed: 0  \\\n",
       "0                            img_path   \n",
       "1                          timestamps   \n",
       "2                       transcription   \n",
       "3                  ocr_extracted_text   \n",
       "4                        llava_result   \n",
       "5                           clip_text   \n",
       "6                    llm_long_summary   \n",
       "7                 clip_text_embedding   \n",
       "8                clip_image_embedding   \n",
       "9             standard_text_embedding   \n",
       "10           extensive_text_embedding   \n",
       "11                 ocr_text_embedding   \n",
       "12       transcription_text_embedding   \n",
       "13               llava_text_embedding   \n",
       "14        ocr_transcription_embedding   \n",
       "15  ocr_transcription_llava_embedding   \n",
       "\n",
       "                                                   80  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                   [1454.08, 1459.2]   \n",
       "2    Another way to find binomial probabilities is...   \n",
       "3   Method 2: Using Technology\\n\\nTechnologies can...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Binomial probabilities, technology, spreadshee...   \n",
       "6   Method 2: Using Technology - The lecture discu...   \n",
       "7   tensor([[ 5.1960e-03,  5.5442e-02, -2.9637e-02...   \n",
       "8   tensor([[-1.6722e-02,  1.2606e-01, -3.9023e-02...   \n",
       "9   tensor([-8.5635e-02, -8.2966e-02, -2.1982e-01,...   \n",
       "10  tensor([-1.8073e-01,  1.8656e-02, -7.9516e-02,...   \n",
       "11  tensor([-1.7012e-01, -2.3376e-02, -6.5044e-02,...   \n",
       "12  tensor([-1.1286e-01, -3.6851e-02, -7.1103e-02,...   \n",
       "13  tensor([-5.5286e-02, -5.7482e-02,  2.3002e-02,...   \n",
       "14  tensor([-0.1558, -0.0281, -0.0629, -0.2853,  0...   \n",
       "15  tensor([-1.5069e-01, -4.7678e-02, -5.0572e-02,...   \n",
       "\n",
       "                                                   26  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                    [399.44, 404.48]   \n",
       "2    Notice that X can be any whole number between...   \n",
       "3   be any whole number between 0 and n, inclusive...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Bionomial probability distributions, notation,...   \n",
       "6   The slide explains notation for binomial proba...   \n",
       "7   tensor([[-2.2565e-02,  2.9402e-02, -6.4396e-02...   \n",
       "8   tensor([[-1.1037e-02,  4.2648e-02, -1.3678e-02...   \n",
       "9   tensor([ 3.5344e-02,  3.0355e-02,  7.1971e-03,...   \n",
       "10  tensor([-0.0751, -0.1122, -0.1110, -0.2555, -0...   \n",
       "11  tensor([-3.3976e-02, -5.2518e-02, -8.7697e-02,...   \n",
       "12  tensor([-0.2527,  0.0917, -0.0312, -0.0377, -0...   \n",
       "13  tensor([-0.0832,  0.0405,  0.0582, -0.1096,  0...   \n",
       "14  tensor([-2.8846e-02, -6.3873e-02, -1.1736e-01,...   \n",
       "15  tensor([-4.1617e-03, -4.7293e-02, -7.4943e-02,...   \n",
       "\n",
       "                                                   38  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                     [715.6, 716.92]   \n",
       "2                         I guess they'd set with RIP   \n",
       "3   The word success as used here is arbitrary and...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   success probability p, binomial distribution, ...   \n",
       "6   The concept of success as used here is arbitra...   \n",
       "7   tensor([[ 1.6784e-02,  8.1404e-03, -2.5032e-02...   \n",
       "8   tensor([[ 1.1816e-02,  7.1861e-02, -3.5468e-05...   \n",
       "9   tensor([ 2.2932e-01, -1.0410e-01, -1.6513e-01,...   \n",
       "10  tensor([ 1.4936e-01, -6.9109e-03, -1.8281e-01,...   \n",
       "11  tensor([ 4.7415e-02, -1.6109e-01, -2.1035e-01,...   \n",
       "12  tensor([-2.1935e-01, -1.0559e-01,  2.2703e-01,...   \n",
       "13  tensor([ 2.2215e-02, -1.0916e-01,  6.8139e-02,...   \n",
       "14  tensor([ 0.0047, -0.1774, -0.1902, -0.1306, -0...   \n",
       "15  tensor([ 5.7992e-03, -2.2144e-01, -1.7809e-01,...   \n",
       "\n",
       "                                                   45  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                     [783.36, 785.6]   \n",
       "2                               equals 5, x equals 3.   \n",
       "3   Solution\\n\\nb. Having concluded that the given...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Binomial distribution, Twitter data collection...   \n",
       "6   The lecture discussed a binomial distribution ...   \n",
       "7   tensor([[ 1.0491e-02,  1.8044e-02, -1.6795e-02...   \n",
       "8   tensor([[-3.8834e-02,  3.5723e-02, -2.2615e-02...   \n",
       "9   tensor([ 2.5956e-02, -1.6343e-01, -1.7768e-01,...   \n",
       "10  tensor([ 0.0142,  0.0795, -0.0884, -0.3639,  0...   \n",
       "11  tensor([-3.4410e-02,  1.3466e-02, -4.2267e-02,...   \n",
       "12  tensor([ 0.2134, -0.0186, -0.0360, -0.0049, -0...   \n",
       "13  tensor([-1.5370e-01,  1.8803e-01,  4.5884e-02,...   \n",
       "14  tensor([-0.0262, -0.0007, -0.0523, -0.2620, -0...   \n",
       "15  tensor([ 1.6927e-02, -3.4209e-02, -5.8822e-02,...   \n",
       "\n",
       "                                                   34  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                    [593.92, 599.04]   \n",
       "2    So here that is again, again the example we'r...   \n",
       "3   * Binomial Probability Distribution BS\\n—Abino...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Binomial probability distribution, independent...   \n",
       "6   A binomial probability distribution results fr...   \n",
       "7   tensor([[-1.7205e-02,  3.4386e-02, -3.2124e-02...   \n",
       "8   tensor([[-1.7681e-02,  3.2758e-02, -1.0590e-02...   \n",
       "9   tensor([ 0.0245,  0.1300, -0.0587, -0.2838, -0...   \n",
       "10  tensor([ 6.5100e-02,  5.6179e-02, -9.4640e-02,...   \n",
       "11  tensor([ 2.0410e-02,  1.5192e-01, -1.8803e-01,...   \n",
       "12  tensor([ 0.0664, -0.1439,  0.0947,  0.1197,  0...   \n",
       "13  tensor([-0.1649, -0.1063, -0.0328, -0.2106,  0...   \n",
       "14  tensor([ 2.6093e-02,  1.2894e-01, -1.7960e-01,...   \n",
       "15  tensor([ 0.0422,  0.1119, -0.1470, -0.1917,  0...   \n",
       "\n",
       "                                                   49  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                    [798.72, 813.96]   \n",
       "2    that X and P both refer to the same concept o...   \n",
       "3   ple:\\n\\nSolution\\n\\nAgain, it is very importan...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Twitter educational tool, share ideas/resource...   \n",
       "6   The lecture discussed the importance of using ...   \n",
       "7   tensor([[-1.0936e-02,  1.3913e-02, -9.5265e-03...   \n",
       "8   tensor([[-3.4967e-02,  1.1532e-02,  5.8089e-03...   \n",
       "9   tensor([-5.0663e-02, -1.9418e-01, -9.7258e-02,...   \n",
       "10  tensor([-0.0523, -0.0989, -0.0447, -0.1362, -0...   \n",
       "11  tensor([-3.4922e-02, -1.5838e-01,  1.7810e-02,...   \n",
       "12  tensor([-0.0280, -0.4231, -0.0143, -0.2034, -0...   \n",
       "13  tensor([-0.1994, -0.0615,  0.1766, -0.0913,  0...   \n",
       "14  tensor([-4.6075e-02, -1.8089e-01,  4.9301e-03,...   \n",
       "15  tensor([-4.6075e-02, -1.8089e-01,  4.9301e-03,...   \n",
       "\n",
       "                                                   57  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                   [977.92, 1083.88]   \n",
       "2    Right, I would be very surprised if anybody i...   \n",
       "3   Let’s develop the fo\\n\\ni\\n\\n+ On the pop quiz...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Probability calculation, probability of gettin...   \n",
       "6   The probability of getting exactly 3 right ans...   \n",
       "7   tensor([[ 8.6700e-03,  2.2865e-02, -1.4433e-02...   \n",
       "8   tensor([[-3.4798e-02,  4.2907e-02, -1.9039e-02...   \n",
       "9   tensor([ 1.6039e-01, -1.6502e-01, -1.2744e-02,...   \n",
       "10  tensor([ 0.4545, -0.3252, -0.0938, -0.2329, -0...   \n",
       "11  tensor([ 9.2679e-02, -2.2400e-01, -7.5917e-02,...   \n",
       "12  tensor([ 1.2617e-01, -2.9918e-01,  8.4224e-02,...   \n",
       "13  tensor([-1.0690e-01, -2.1193e-01, -5.2433e-02,...   \n",
       "14  tensor([ 0.0899, -0.2315, -0.0652, -0.2966, -0...   \n",
       "15  tensor([ 0.0899, -0.2315, -0.0652, -0.2966, -0...   \n",
       "\n",
       "                                                    2  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                      [10.12, 30.72]   \n",
       "2    Okay, so the binomial distribution, binomial ...   \n",
       "3   Key Concept\\n\\nThe focus of this section is th...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Binomial probability distribution, discrete pr...   \n",
       "6   The binomial distribution, binomial probabilit...   \n",
       "7   tensor([[-4.5463e-03,  1.6110e-02, -2.0650e-02...   \n",
       "8   tensor([[-1.1023e-03,  4.4724e-02, -2.0930e-02...   \n",
       "9   tensor([ 1.0485e-01, -5.6872e-02,  1.0654e-01,...   \n",
       "10  tensor([-1.3679e-01,  1.0031e-02, -3.8077e-02,...   \n",
       "11  tensor([-9.7531e-02,  1.1729e-02, -4.8321e-02,...   \n",
       "12  tensor([-0.0970, -0.1151,  0.1323, -0.1864,  0...   \n",
       "13  tensor([-9.6267e-02, -1.4498e-01, -4.5661e-02,...   \n",
       "14  tensor([-1.3256e-01, -9.8598e-03,  4.0017e-03,...   \n",
       "15  tensor([-1.2094e-01, -2.1370e-02, -2.5478e-04,...   \n",
       "\n",
       "                                                   61  ...  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...  ...   \n",
       "1                                  [1190.28, 1231.16]  ...   \n",
       "2    Okay, so back to the Twitter example, and the...  ...   \n",
       "3   Example: Twitter (7 or\\n\\nGiven that there is ...  ...   \n",
       "4    The image you've provided appears to be a scr...  ...   \n",
       "5   Twitter probability binomial formula adults kn...  ...   \n",
       "6   Given that there is a 0.85 probability that a ...  ...   \n",
       "7   tensor([[-1.4731e-03,  1.6395e-02, -2.2071e-02...  ...   \n",
       "8   tensor([[-2.4954e-02,  2.8499e-02, -1.2477e-02...  ...   \n",
       "9   tensor([ 0.1081, -0.0920, -0.0017, -0.3471,  0...  ...   \n",
       "10  tensor([-2.8476e-02, -7.4902e-02,  7.4877e-02,...  ...   \n",
       "11  tensor([-8.1552e-02, -1.2928e-01,  5.2166e-02,...  ...   \n",
       "12  tensor([-0.0134, -0.2096,  0.1396, -0.3475,  0...  ...   \n",
       "13  tensor([ 4.6093e-03, -1.5259e-01,  1.8080e-02,...  ...   \n",
       "14  tensor([-8.1063e-02, -1.5291e-01,  6.1723e-02,...  ...   \n",
       "15  tensor([-8.1063e-02, -1.5291e-01,  6.1723e-02,...  ...   \n",
       "\n",
       "                                                   40  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                    [721.92, 763.32]   \n",
       "2    C major is a binomial distribution.  So let's...   \n",
       "3   ®\\n\\nple:\\n\\nWhen an adult is randomly selecte...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Binomial distribution, probability of success ...   \n",
       "6   The lecture discusses a binomial distribution ...   \n",
       "7   tensor([[-8.6146e-03,  8.3915e-03, -3.9367e-02...   \n",
       "8   tensor([[-1.1230e-02,  5.8981e-02,  2.2850e-02...   \n",
       "9   tensor([ 8.9046e-02,  1.7294e-02, -1.7561e-01,...   \n",
       "10  tensor([ 1.2892e-02,  7.9248e-02, -9.0279e-02,...   \n",
       "11  tensor([-4.0876e-02, -3.4146e-02, -1.3483e-03,...   \n",
       "12  tensor([ 0.1395, -0.0910,  0.0794, -0.3907, -0...   \n",
       "13  tensor([-0.0205, -0.0816,  0.0323, -0.0862,  0...   \n",
       "14  tensor([-4.0876e-02, -3.4146e-02, -1.3483e-03,...   \n",
       "15  tensor([-4.0876e-02, -3.4146e-02, -1.3483e-03,...   \n",
       "\n",
       "                                                   23  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                    [313.64, 369.36]   \n",
       "2    Okay. Notation. So, P little P is what we alw...   \n",
       "3   Sand F (success and failure) denote the two\\np...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Binomial probability, notation P and Q, add up...   \n",
       "6   The lecture discussed binomial probability dis...   \n",
       "7   tensor([[ 5.3796e-03,  7.5618e-03, -2.3130e-02...   \n",
       "8   tensor([[ 5.0079e-03,  5.3988e-02, -3.3951e-02...   \n",
       "9   tensor([ 1.0437e-01, -7.3343e-03, -7.2010e-02,...   \n",
       "10  tensor([-0.1565,  0.1090, -0.1335, -0.2257, -0...   \n",
       "11  tensor([-0.2049, -0.2461,  0.1274, -0.0621, -0...   \n",
       "12  tensor([-4.8438e-03, -2.3021e-01,  3.5162e-02,...   \n",
       "13  tensor([-1.5808e-01, -1.1350e-01,  4.9287e-02,...   \n",
       "14  tensor([-1.8131e-01, -2.6552e-01,  1.4785e-01,...   \n",
       "15  tensor([-1.8131e-01, -2.6552e-01,  1.4785e-01,...   \n",
       "\n",
       "                                                   76  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                    [1408.0, 1433.6]   \n",
       "2    used your specific number or whatever you got...   \n",
       "3   X=number Frequency Relative freq. Theoretical ...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Probability theory observed vs theoretical fre...   \n",
       "6   The slide presents a quiz on observed vs theor...   \n",
       "7   tensor([[-3.4614e-02,  2.4161e-02, -4.2352e-02...   \n",
       "8   tensor([[ 5.8095e-03,  3.5173e-02, -1.5557e-02...   \n",
       "9   tensor([ 8.8447e-02, -1.1505e-02,  1.4052e-01,...   \n",
       "10  tensor([ 0.0728, -0.0427, -0.1030, -0.0830,  0...   \n",
       "11  tensor([-1.0861e-01,  8.0917e-02,  2.1251e-02,...   \n",
       "12  tensor([ 0.2031, -0.2477, -0.3101, -0.1122,  0...   \n",
       "13  tensor([-8.8247e-02, -4.4753e-02, -1.5758e-04,...   \n",
       "14  tensor([ 0.0035, -0.0956, -0.0396, -0.1699,  0...   \n",
       "15  tensor([ 0.0035, -0.0956, -0.0396, -0.1699,  0...   \n",
       "\n",
       "                                                   15  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                    [117.76, 150.28]   \n",
       "2    answers right or wrong. Number three is D. Nu...   \n",
       "3                   The Answers — how did you do?\\n\\n   \n",
       "4    The slide appears to be from an academic lect...   \n",
       "5   Answers right or wrong, multiple-choice questi...   \n",
       "6   The lecture appears to be an assessment of und...   \n",
       "7   tensor([[ 1.7163e-03,  8.9570e-03,  2.8305e-03...   \n",
       "8   tensor([[-4.0929e-02,  4.3851e-02, -4.2689e-02...   \n",
       "9   tensor([ 4.4614e-01, -2.1112e-01,  3.4753e-02,...   \n",
       "10  tensor([ 1.4151e-01,  9.5755e-02, -8.1816e-02,...   \n",
       "11  tensor([ 5.0100e-01,  4.2088e-02,  2.4783e-01,...   \n",
       "12  tensor([ 0.2544, -0.2140, -0.1404, -0.0309, -0...   \n",
       "13  tensor([ 1.1979e-01, -1.1710e-01,  1.6335e-01,...   \n",
       "14  tensor([ 2.7631e-01, -1.1319e-01, -6.0725e-02,...   \n",
       "15  tensor([ 2.7631e-01, -1.1319e-01, -6.0725e-02,...   \n",
       "\n",
       "                                                   68  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                  [1345.12, 1346.56]   \n",
       "2                                                 NaN   \n",
       "3   2\\n\\n+ How many did you get right on the pop q...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Pop quiz probability, theoretical vs. observed...   \n",
       "6   The lecture discussed how many students got ri...   \n",
       "7   tensor([[-1.5380e-02, -2.8845e-03, -7.9334e-03...   \n",
       "8   tensor([[-1.9318e-02,  5.5134e-02, -6.3328e-02...   \n",
       "9   tensor([ 1.3634e-01, -3.0984e-02, -1.2701e-01,...   \n",
       "10  tensor([ 0.0550,  0.0839, -0.1225, -0.1555, -0...   \n",
       "11  tensor([ 9.9797e-02, -1.2169e-01, -1.7010e-02,...   \n",
       "12  tensor([ 2.2692e-01,  8.1784e-02,  2.3543e-02,...   \n",
       "13  tensor([ 4.5333e-02, -1.0781e-01,  9.9918e-02,...   \n",
       "14  tensor([ 9.9797e-02, -1.2169e-01, -1.7010e-02,...   \n",
       "15  tensor([ 0.0938, -0.2037, -0.0279, -0.1850, -0...   \n",
       "\n",
       "                                                   19  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                    [209.92, 252.48]   \n",
       "2    It has four requirements.  Number one, the pr...   \n",
       "3   ab\\n\\n* Binomial Probability Distribution\\n—Ab...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Binomial probability distribution, fixed numbe...   \n",
       "6   The binomial probability distribution results ...   \n",
       "7   tensor([[-7.7309e-03,  1.8499e-02, -3.7852e-02...   \n",
       "8   tensor([[-0.0119,  0.0322, -0.0126,  0.0180, -...   \n",
       "9   tensor([ 1.7352e-02,  5.3766e-02, -7.4951e-03,...   \n",
       "10  tensor([ 0.0754,  0.1210, -0.0456, -0.2778, -0...   \n",
       "11  tensor([ 0.0068,  0.1454, -0.1894, -0.1955, -0...   \n",
       "12  tensor([ 1.4470e-01,  8.1109e-02, -7.0167e-02,...   \n",
       "13  tensor([-1.6687e-01, -6.3698e-02,  5.2310e-02,...   \n",
       "14  tensor([ 5.6154e-02,  1.4585e-01, -1.6363e-01,...   \n",
       "15  tensor([ 5.6154e-02,  1.4585e-01, -1.6363e-01,...   \n",
       "\n",
       "                                                   64  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                   [1264.64, 1306.4]   \n",
       "2    Okay, now I'm just going to go ahead and hit ...   \n",
       "3                                                 NaN   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Probability calculator math Twitter adults hea...   \n",
       "6   The lecture discussed calculators and mathemat...   \n",
       "7   tensor([[-1.2640e-03,  1.7357e-02, -1.5980e-02...   \n",
       "8   tensor([[ 2.1822e-02,  3.0071e-02,  9.9883e-03...   \n",
       "9   tensor([ 0.1213, -0.3609, -0.1789, -0.1939, -0...   \n",
       "10  tensor([ 3.3183e-02, -6.4988e-02, -2.0071e-01,...   \n",
       "11  tensor([ 2.2692e-01,  8.1784e-02,  2.3543e-02,...   \n",
       "12  tensor([ 1.3068e-02, -2.1405e-01,  3.1282e-02,...   \n",
       "13  tensor([-0.0403, -0.2010,  0.0270, -0.0218,  0...   \n",
       "14  tensor([ 1.3068e-02, -2.1405e-01,  3.1282e-02,...   \n",
       "15  tensor([ 1.0324e-03, -1.5084e-01,  6.6102e-02,...   \n",
       "\n",
       "                                                    7  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                      [61.44, 63.04]   \n",
       "2                                                 NaN   \n",
       "3   Pop quiz! i\\n\\n* Number your paper 1-10. There...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Pop quiz! 10 questions, each with 4 choices (A...   \n",
       "6   Pop quiz! The lecture appears to be an academi...   \n",
       "7   tensor([[ 8.0131e-03,  3.1325e-02,  7.0254e-03...   \n",
       "8   tensor([[ 8.8992e-04,  2.4442e-02, -6.5559e-02...   \n",
       "9   tensor([ 0.0854,  0.0739,  0.3152, -0.0486, -0...   \n",
       "10  tensor([ 0.0975,  0.2250,  0.0211, -0.1165, -0...   \n",
       "11  tensor([-1.4790e-01,  1.9107e-01,  1.5564e-01,...   \n",
       "12  tensor([ 2.2692e-01,  8.1784e-02,  2.3543e-02,...   \n",
       "13  tensor([ 1.2520e-02, -3.7925e-02,  1.5745e-01,...   \n",
       "14  tensor([-1.4790e-01,  1.9107e-01,  1.5564e-01,...   \n",
       "15  tensor([-0.1330,  0.0448,  0.2359, -0.1617,  0...   \n",
       "\n",
       "                                                   89  \\\n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...   \n",
       "1                                   [1820.88, 1861.8]   \n",
       "2    Our sort of working definition of what is an ...   \n",
       "3   Solution\\n\\nThe Excel display on the next page...   \n",
       "4    The image you've provided appears to be a scr...   \n",
       "5   Unusual event probability <0.05, overtime coin...   \n",
       "6   The probability of 252 or more wins in 460 ove...   \n",
       "7   tensor([[-1.4216e-03, -2.0283e-02, -1.2192e-02...   \n",
       "8   tensor([[-1.1211e-02,  7.0335e-02, -4.6952e-02...   \n",
       "9   tensor([ 1.2005e-01, -2.1817e-01, -1.7670e-01,...   \n",
       "10  tensor([ 1.3362e-01, -2.1329e-01, -2.5612e-01,...   \n",
       "11  tensor([ 1.4016e-01, -2.5006e-02, -2.8691e-01,...   \n",
       "12  tensor([-4.4180e-02, -3.0056e-01, -1.0255e-01,...   \n",
       "13  tensor([ 2.0953e-02, -5.0737e-02, -1.3741e-01,...   \n",
       "14  tensor([ 1.4720e-01, -3.3228e-02, -2.8897e-01,...   \n",
       "15  tensor([ 1.4720e-01, -3.3228e-02, -2.8897e-01,...   \n",
       "\n",
       "                                                   85  \n",
       "0   /Users/magic-rabbit/Documents/AFM/afm-vlm/data...  \n",
       "1                                  [1617.92, 1679.88]  \n",
       "2    Okay, so here's a good example for technology...  \n",
       "3   We previously noted that between 1974 and 2011...  \n",
       "4    The image you've provided appears to be a scr...  \n",
       "5   NFL games overtime coin toss wins probability ...  \n",
       "6   The lecture discussed NFL football games decid...  \n",
       "7   tensor([[ 2.6404e-03,  5.7825e-03, -4.9042e-03...  \n",
       "8   tensor([[-1.7590e-02,  2.9331e-02, -3.1065e-02...  \n",
       "9   tensor([-8.3826e-02, -1.5241e-01, -4.6781e-02,...  \n",
       "10  tensor([ 0.0451, -0.1206, -0.2157, -0.2854, -0...  \n",
       "11  tensor([ 3.3652e-03, -1.7468e-01, -1.2044e-01,...  \n",
       "12  tensor([ 3.9551e-02, -1.2612e-01, -4.5963e-02,...  \n",
       "13  tensor([-0.0257, -0.0809,  0.0372, -0.0814,  0...  \n",
       "14  tensor([ 3.3652e-03, -1.7468e-01, -1.2044e-01,...  \n",
       "15  tensor([ 3.3652e-03, -1.7468e-01, -1.2044e-01,...  \n",
       "\n",
       "[16 rows x 90 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>80</th>\n",
       "      <th>26</th>\n",
       "      <th>38</th>\n",
       "      <th>45</th>\n",
       "      <th>34</th>\n",
       "      <th>49</th>\n",
       "      <th>57</th>\n",
       "      <th>2</th>\n",
       "      <th>61</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>23</th>\n",
       "      <th>76</th>\n",
       "      <th>15</th>\n",
       "      <th>68</th>\n",
       "      <th>19</th>\n",
       "      <th>64</th>\n",
       "      <th>7</th>\n",
       "      <th>89</th>\n",
       "      <th>85</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_path</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "      <td>/Users/magic-rabbit/Documents/AFM/afm-vlm/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>timestamps</td>\n",
       "      <td>[1454.08, 1459.2]</td>\n",
       "      <td>[399.44, 404.48]</td>\n",
       "      <td>[715.6, 716.92]</td>\n",
       "      <td>[783.36, 785.6]</td>\n",
       "      <td>[593.92, 599.04]</td>\n",
       "      <td>[798.72, 813.96]</td>\n",
       "      <td>[977.92, 1083.88]</td>\n",
       "      <td>[10.12, 30.72]</td>\n",
       "      <td>[1190.28, 1231.16]</td>\n",
       "      <td>...</td>\n",
       "      <td>[721.92, 763.32]</td>\n",
       "      <td>[313.64, 369.36]</td>\n",
       "      <td>[1408.0, 1433.6]</td>\n",
       "      <td>[117.76, 150.28]</td>\n",
       "      <td>[1345.12, 1346.56]</td>\n",
       "      <td>[209.92, 252.48]</td>\n",
       "      <td>[1264.64, 1306.4]</td>\n",
       "      <td>[61.44, 63.04]</td>\n",
       "      <td>[1820.88, 1861.8]</td>\n",
       "      <td>[1617.92, 1679.88]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transcription</td>\n",
       "      <td>Another way to find binomial probabilities is...</td>\n",
       "      <td>Notice that X can be any whole number between...</td>\n",
       "      <td>I guess they'd set with RIP</td>\n",
       "      <td>equals 5, x equals 3.</td>\n",
       "      <td>So here that is again, again the example we'r...</td>\n",
       "      <td>that X and P both refer to the same concept o...</td>\n",
       "      <td>Right, I would be very surprised if anybody i...</td>\n",
       "      <td>Okay, so the binomial distribution, binomial ...</td>\n",
       "      <td>Okay, so back to the Twitter example, and the...</td>\n",
       "      <td>...</td>\n",
       "      <td>C major is a binomial distribution.  So let's...</td>\n",
       "      <td>Okay. Notation. So, P little P is what we alw...</td>\n",
       "      <td>used your specific number or whatever you got...</td>\n",
       "      <td>answers right or wrong. Number three is D. Nu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It has four requirements.  Number one, the pr...</td>\n",
       "      <td>Okay, now I'm just going to go ahead and hit ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our sort of working definition of what is an ...</td>\n",
       "      <td>Okay, so here's a good example for technology...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ocr_extracted_text</td>\n",
       "      <td>Method 2: Using Technology\\n\\nTechnologies can...</td>\n",
       "      <td>be any whole number between 0 and n, inclusive...</td>\n",
       "      <td>The word success as used here is arbitrary and...</td>\n",
       "      <td>Solution\\n\\nb. Having concluded that the given...</td>\n",
       "      <td>* Binomial Probability Distribution BS\\n—Abino...</td>\n",
       "      <td>ple:\\n\\nSolution\\n\\nAgain, it is very importan...</td>\n",
       "      <td>Let’s develop the fo\\n\\ni\\n\\n+ On the pop quiz...</td>\n",
       "      <td>Key Concept\\n\\nThe focus of this section is th...</td>\n",
       "      <td>Example: Twitter (7 or\\n\\nGiven that there is ...</td>\n",
       "      <td>...</td>\n",
       "      <td>®\\n\\nple:\\n\\nWhen an adult is randomly selecte...</td>\n",
       "      <td>Sand F (success and failure) denote the two\\np...</td>\n",
       "      <td>X=number Frequency Relative freq. Theoretical ...</td>\n",
       "      <td>The Answers — how did you do?\\n\\n</td>\n",
       "      <td>2\\n\\n+ How many did you get right on the pop q...</td>\n",
       "      <td>ab\\n\\n* Binomial Probability Distribution\\n—Ab...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pop quiz! i\\n\\n* Number your paper 1-10. There...</td>\n",
       "      <td>Solution\\n\\nThe Excel display on the next page...</td>\n",
       "      <td>We previously noted that between 1974 and 2011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llava_result</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The slide appears to be from an academic lect...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "      <td>The image you've provided appears to be a scr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clip_text</td>\n",
       "      <td>Binomial probabilities, technology, spreadshee...</td>\n",
       "      <td>Bionomial probability distributions, notation,...</td>\n",
       "      <td>success probability p, binomial distribution, ...</td>\n",
       "      <td>Binomial distribution, Twitter data collection...</td>\n",
       "      <td>Binomial probability distribution, independent...</td>\n",
       "      <td>Twitter educational tool, share ideas/resource...</td>\n",
       "      <td>Probability calculation, probability of gettin...</td>\n",
       "      <td>Binomial probability distribution, discrete pr...</td>\n",
       "      <td>Twitter probability binomial formula adults kn...</td>\n",
       "      <td>...</td>\n",
       "      <td>Binomial distribution, probability of success ...</td>\n",
       "      <td>Binomial probability, notation P and Q, add up...</td>\n",
       "      <td>Probability theory observed vs theoretical fre...</td>\n",
       "      <td>Answers right or wrong, multiple-choice questi...</td>\n",
       "      <td>Pop quiz probability, theoretical vs. observed...</td>\n",
       "      <td>Binomial probability distribution, fixed numbe...</td>\n",
       "      <td>Probability calculator math Twitter adults hea...</td>\n",
       "      <td>Pop quiz! 10 questions, each with 4 choices (A...</td>\n",
       "      <td>Unusual event probability &lt;0.05, overtime coin...</td>\n",
       "      <td>NFL games overtime coin toss wins probability ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llm_long_summary</td>\n",
       "      <td>Method 2: Using Technology - The lecture discu...</td>\n",
       "      <td>The slide explains notation for binomial proba...</td>\n",
       "      <td>The concept of success as used here is arbitra...</td>\n",
       "      <td>The lecture discussed a binomial distribution ...</td>\n",
       "      <td>A binomial probability distribution results fr...</td>\n",
       "      <td>The lecture discussed the importance of using ...</td>\n",
       "      <td>The probability of getting exactly 3 right ans...</td>\n",
       "      <td>The binomial distribution, binomial probabilit...</td>\n",
       "      <td>Given that there is a 0.85 probability that a ...</td>\n",
       "      <td>...</td>\n",
       "      <td>The lecture discusses a binomial distribution ...</td>\n",
       "      <td>The lecture discussed binomial probability dis...</td>\n",
       "      <td>The slide presents a quiz on observed vs theor...</td>\n",
       "      <td>The lecture appears to be an assessment of und...</td>\n",
       "      <td>The lecture discussed how many students got ri...</td>\n",
       "      <td>The binomial probability distribution results ...</td>\n",
       "      <td>The lecture discussed calculators and mathemat...</td>\n",
       "      <td>Pop quiz! The lecture appears to be an academi...</td>\n",
       "      <td>The probability of 252 or more wins in 460 ove...</td>\n",
       "      <td>The lecture discussed NFL football games decid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>clip_text_embedding</td>\n",
       "      <td>tensor([[ 5.1960e-03,  5.5442e-02, -2.9637e-02...</td>\n",
       "      <td>tensor([[-2.2565e-02,  2.9402e-02, -6.4396e-02...</td>\n",
       "      <td>tensor([[ 1.6784e-02,  8.1404e-03, -2.5032e-02...</td>\n",
       "      <td>tensor([[ 1.0491e-02,  1.8044e-02, -1.6795e-02...</td>\n",
       "      <td>tensor([[-1.7205e-02,  3.4386e-02, -3.2124e-02...</td>\n",
       "      <td>tensor([[-1.0936e-02,  1.3913e-02, -9.5265e-03...</td>\n",
       "      <td>tensor([[ 8.6700e-03,  2.2865e-02, -1.4433e-02...</td>\n",
       "      <td>tensor([[-4.5463e-03,  1.6110e-02, -2.0650e-02...</td>\n",
       "      <td>tensor([[-1.4731e-03,  1.6395e-02, -2.2071e-02...</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor([[-8.6146e-03,  8.3915e-03, -3.9367e-02...</td>\n",
       "      <td>tensor([[ 5.3796e-03,  7.5618e-03, -2.3130e-02...</td>\n",
       "      <td>tensor([[-3.4614e-02,  2.4161e-02, -4.2352e-02...</td>\n",
       "      <td>tensor([[ 1.7163e-03,  8.9570e-03,  2.8305e-03...</td>\n",
       "      <td>tensor([[-1.5380e-02, -2.8845e-03, -7.9334e-03...</td>\n",
       "      <td>tensor([[-7.7309e-03,  1.8499e-02, -3.7852e-02...</td>\n",
       "      <td>tensor([[-1.2640e-03,  1.7357e-02, -1.5980e-02...</td>\n",
       "      <td>tensor([[ 8.0131e-03,  3.1325e-02,  7.0254e-03...</td>\n",
       "      <td>tensor([[-1.4216e-03, -2.0283e-02, -1.2192e-02...</td>\n",
       "      <td>tensor([[ 2.6404e-03,  5.7825e-03, -4.9042e-03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>clip_image_embedding</td>\n",
       "      <td>tensor([[-1.6722e-02,  1.2606e-01, -3.9023e-02...</td>\n",
       "      <td>tensor([[-1.1037e-02,  4.2648e-02, -1.3678e-02...</td>\n",
       "      <td>tensor([[ 1.1816e-02,  7.1861e-02, -3.5468e-05...</td>\n",
       "      <td>tensor([[-3.8834e-02,  3.5723e-02, -2.2615e-02...</td>\n",
       "      <td>tensor([[-1.7681e-02,  3.2758e-02, -1.0590e-02...</td>\n",
       "      <td>tensor([[-3.4967e-02,  1.1532e-02,  5.8089e-03...</td>\n",
       "      <td>tensor([[-3.4798e-02,  4.2907e-02, -1.9039e-02...</td>\n",
       "      <td>tensor([[-1.1023e-03,  4.4724e-02, -2.0930e-02...</td>\n",
       "      <td>tensor([[-2.4954e-02,  2.8499e-02, -1.2477e-02...</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor([[-1.1230e-02,  5.8981e-02,  2.2850e-02...</td>\n",
       "      <td>tensor([[ 5.0079e-03,  5.3988e-02, -3.3951e-02...</td>\n",
       "      <td>tensor([[ 5.8095e-03,  3.5173e-02, -1.5557e-02...</td>\n",
       "      <td>tensor([[-4.0929e-02,  4.3851e-02, -4.2689e-02...</td>\n",
       "      <td>tensor([[-1.9318e-02,  5.5134e-02, -6.3328e-02...</td>\n",
       "      <td>tensor([[-0.0119,  0.0322, -0.0126,  0.0180, -...</td>\n",
       "      <td>tensor([[ 2.1822e-02,  3.0071e-02,  9.9883e-03...</td>\n",
       "      <td>tensor([[ 8.8992e-04,  2.4442e-02, -6.5559e-02...</td>\n",
       "      <td>tensor([[-1.1211e-02,  7.0335e-02, -4.6952e-02...</td>\n",
       "      <td>tensor([[-1.7590e-02,  2.9331e-02, -3.1065e-02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>standard_text_embedding</td>\n",
       "      <td>tensor([-8.5635e-02, -8.2966e-02, -2.1982e-01,...</td>\n",
       "      <td>tensor([ 3.5344e-02,  3.0355e-02,  7.1971e-03,...</td>\n",
       "      <td>tensor([ 2.2932e-01, -1.0410e-01, -1.6513e-01,...</td>\n",
       "      <td>tensor([ 2.5956e-02, -1.6343e-01, -1.7768e-01,...</td>\n",
       "      <td>tensor([ 0.0245,  0.1300, -0.0587, -0.2838, -0...</td>\n",
       "      <td>tensor([-5.0663e-02, -1.9418e-01, -9.7258e-02,...</td>\n",
       "      <td>tensor([ 1.6039e-01, -1.6502e-01, -1.2744e-02,...</td>\n",
       "      <td>tensor([ 1.0485e-01, -5.6872e-02,  1.0654e-01,...</td>\n",
       "      <td>tensor([ 0.1081, -0.0920, -0.0017, -0.3471,  0...</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor([ 8.9046e-02,  1.7294e-02, -1.7561e-01,...</td>\n",
       "      <td>tensor([ 1.0437e-01, -7.3343e-03, -7.2010e-02,...</td>\n",
       "      <td>tensor([ 8.8447e-02, -1.1505e-02,  1.4052e-01,...</td>\n",
       "      <td>tensor([ 4.4614e-01, -2.1112e-01,  3.4753e-02,...</td>\n",
       "      <td>tensor([ 1.3634e-01, -3.0984e-02, -1.2701e-01,...</td>\n",
       "      <td>tensor([ 1.7352e-02,  5.3766e-02, -7.4951e-03,...</td>\n",
       "      <td>tensor([ 0.1213, -0.3609, -0.1789, -0.1939, -0...</td>\n",
       "      <td>tensor([ 0.0854,  0.0739,  0.3152, -0.0486, -0...</td>\n",
       "      <td>tensor([ 1.2005e-01, -2.1817e-01, -1.7670e-01,...</td>\n",
       "      <td>tensor([-8.3826e-02, -1.5241e-01, -4.6781e-02,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>extensive_text_embedding</td>\n",
       "      <td>tensor([-1.8073e-01,  1.8656e-02, -7.9516e-02,...</td>\n",
       "      <td>tensor([-0.0751, -0.1122, -0.1110, -0.2555, -0...</td>\n",
       "      <td>tensor([ 1.4936e-01, -6.9109e-03, -1.8281e-01,...</td>\n",
       "      <td>tensor([ 0.0142,  0.0795, -0.0884, -0.3639,  0...</td>\n",
       "      <td>tensor([ 6.5100e-02,  5.6179e-02, -9.4640e-02,...</td>\n",
       "      <td>tensor([-0.0523, -0.0989, -0.0447, -0.1362, -0...</td>\n",
       "      <td>tensor([ 0.4545, -0.3252, -0.0938, -0.2329, -0...</td>\n",
       "      <td>tensor([-1.3679e-01,  1.0031e-02, -3.8077e-02,...</td>\n",
       "      <td>tensor([-2.8476e-02, -7.4902e-02,  7.4877e-02,...</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor([ 1.2892e-02,  7.9248e-02, -9.0279e-02,...</td>\n",
       "      <td>tensor([-0.1565,  0.1090, -0.1335, -0.2257, -0...</td>\n",
       "      <td>tensor([ 0.0728, -0.0427, -0.1030, -0.0830,  0...</td>\n",
       "      <td>tensor([ 1.4151e-01,  9.5755e-02, -8.1816e-02,...</td>\n",
       "      <td>tensor([ 0.0550,  0.0839, -0.1225, -0.1555, -0...</td>\n",
       "      <td>tensor([ 0.0754,  0.1210, -0.0456, -0.2778, -0...</td>\n",
       "      <td>tensor([ 3.3183e-02, -6.4988e-02, -2.0071e-01,...</td>\n",
       "      <td>tensor([ 0.0975,  0.2250,  0.0211, -0.1165, -0...</td>\n",
       "      <td>tensor([ 1.3362e-01, -2.1329e-01, -2.5612e-01,...</td>\n",
       "      <td>tensor([ 0.0451, -0.1206, -0.2157, -0.2854, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ocr_text_embedding</td>\n",
       "      <td>tensor([-1.7012e-01, -2.3376e-02, -6.5044e-02,...</td>\n",
       "      <td>tensor([-3.3976e-02, -5.2518e-02, -8.7697e-02,...</td>\n",
       "      <td>tensor([ 4.7415e-02, -1.6109e-01, -2.1035e-01,...</td>\n",
       "      <td>tensor([-3.4410e-02,  1.3466e-02, -4.2267e-02,...</td>\n",
       "      <td>tensor([ 2.0410e-02,  1.5192e-01, -1.8803e-01,...</td>\n",
       "      <td>tensor([-3.4922e-02, -1.5838e-01,  1.7810e-02,...</td>\n",
       "      <td>tensor([ 9.2679e-02, -2.2400e-01, -7.5917e-02,...</td>\n",
       "      <td>tensor([-9.7531e-02,  1.1729e-02, -4.8321e-02,...</td>\n",
       "      <td>tensor([-8.1552e-02, -1.2928e-01,  5.2166e-02,...</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor([-4.0876e-02, -3.4146e-02, -1.3483e-03,...</td>\n",
       "      <td>tensor([-0.2049, -0.2461,  0.1274, -0.0621, -0...</td>\n",
       "      <td>tensor([-1.0861e-01,  8.0917e-02,  2.1251e-02,...</td>\n",
       "      <td>tensor([ 5.0100e-01,  4.2088e-02,  2.4783e-01,...</td>\n",
       "      <td>tensor([ 9.9797e-02, -1.2169e-01, -1.7010e-02,...</td>\n",
       "      <td>tensor([ 0.0068,  0.1454, -0.1894, -0.1955, -0...</td>\n",
       "      <td>tensor([ 2.2692e-01,  8.1784e-02,  2.3543e-02,...</td>\n",
       "      <td>tensor([-1.4790e-01,  1.9107e-01,  1.5564e-01,...</td>\n",
       "      <td>tensor([ 1.4016e-01, -2.5006e-02, -2.8691e-01,...</td>\n",
       "      <td>tensor([ 3.3652e-03, -1.7468e-01, -1.2044e-01,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>transcription_text_embedding</td>\n",
       "      <td>tensor([-1.1286e-01, -3.6851e-02, -7.1103e-02,...</td>\n",
       "      <td>tensor([-0.2527,  0.0917, -0.0312, -0.0377, -0...</td>\n",
       "      <td>tensor([-2.1935e-01, -1.0559e-01,  2.2703e-01,...</td>\n",
       "      <td>tensor([ 0.2134, -0.0186, -0.0360, -0.0049, -0...</td>\n",
       "      <td>tensor([ 0.0664, -0.1439,  0.0947,  0.1197,  0...</td>\n",
       "      <td>tensor([-0.0280, -0.4231, -0.0143, -0.2034, -0...</td>\n",
       "      <td>tensor([ 1.2617e-01, -2.9918e-01,  8.4224e-02,...</td>\n",
       "      <td>tensor([-0.0970, -0.1151,  0.1323, -0.1864,  0...</td>\n",
       "      <td>tensor([-0.0134, -0.2096,  0.1396, -0.3475,  0...</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor([ 0.1395, -0.0910,  0.0794, -0.3907, -0...</td>\n",
       "      <td>tensor([-4.8438e-03, -2.3021e-01,  3.5162e-02,...</td>\n",
       "      <td>tensor([ 0.2031, -0.2477, -0.3101, -0.1122,  0...</td>\n",
       "      <td>tensor([ 0.2544, -0.2140, -0.1404, -0.0309, -0...</td>\n",
       "      <td>tensor([ 2.2692e-01,  8.1784e-02,  2.3543e-02,...</td>\n",
       "      <td>tensor([ 1.4470e-01,  8.1109e-02, -7.0167e-02,...</td>\n",
       "      <td>tensor([ 1.3068e-02, -2.1405e-01,  3.1282e-02,...</td>\n",
       "      <td>tensor([ 2.2692e-01,  8.1784e-02,  2.3543e-02,...</td>\n",
       "      <td>tensor([-4.4180e-02, -3.0056e-01, -1.0255e-01,...</td>\n",
       "      <td>tensor([ 3.9551e-02, -1.2612e-01, -4.5963e-02,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>llava_text_embedding</td>\n",
       "      <td>tensor([-5.5286e-02, -5.7482e-02,  2.3002e-02,...</td>\n",
       "      <td>tensor([-0.0832,  0.0405,  0.0582, -0.1096,  0...</td>\n",
       "      <td>tensor([ 2.2215e-02, -1.0916e-01,  6.8139e-02,...</td>\n",
       "      <td>tensor([-1.5370e-01,  1.8803e-01,  4.5884e-02,...</td>\n",
       "      <td>tensor([-0.1649, -0.1063, -0.0328, -0.2106,  0...</td>\n",
       "      <td>tensor([-0.1994, -0.0615,  0.1766, -0.0913,  0...</td>\n",
       "      <td>tensor([-1.0690e-01, -2.1193e-01, -5.2433e-02,...</td>\n",
       "      <td>tensor([-9.6267e-02, -1.4498e-01, -4.5661e-02,...</td>\n",
       "      <td>tensor([ 4.6093e-03, -1.5259e-01,  1.8080e-02,...</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor([-0.0205, -0.0816,  0.0323, -0.0862,  0...</td>\n",
       "      <td>tensor([-1.5808e-01, -1.1350e-01,  4.9287e-02,...</td>\n",
       "      <td>tensor([-8.8247e-02, -4.4753e-02, -1.5758e-04,...</td>\n",
       "      <td>tensor([ 1.1979e-01, -1.1710e-01,  1.6335e-01,...</td>\n",
       "      <td>tensor([ 4.5333e-02, -1.0781e-01,  9.9918e-02,...</td>\n",
       "      <td>tensor([-1.6687e-01, -6.3698e-02,  5.2310e-02,...</td>\n",
       "      <td>tensor([-0.0403, -0.2010,  0.0270, -0.0218,  0...</td>\n",
       "      <td>tensor([ 1.2520e-02, -3.7925e-02,  1.5745e-01,...</td>\n",
       "      <td>tensor([ 2.0953e-02, -5.0737e-02, -1.3741e-01,...</td>\n",
       "      <td>tensor([-0.0257, -0.0809,  0.0372, -0.0814,  0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ocr_transcription_embedding</td>\n",
       "      <td>tensor([-0.1558, -0.0281, -0.0629, -0.2853,  0...</td>\n",
       "      <td>tensor([-2.8846e-02, -6.3873e-02, -1.1736e-01,...</td>\n",
       "      <td>tensor([ 0.0047, -0.1774, -0.1902, -0.1306, -0...</td>\n",
       "      <td>tensor([-0.0262, -0.0007, -0.0523, -0.2620, -0...</td>\n",
       "      <td>tensor([ 2.6093e-02,  1.2894e-01, -1.7960e-01,...</td>\n",
       "      <td>tensor([-4.6075e-02, -1.8089e-01,  4.9301e-03,...</td>\n",
       "      <td>tensor([ 0.0899, -0.2315, -0.0652, -0.2966, -0...</td>\n",
       "      <td>tensor([-1.3256e-01, -9.8598e-03,  4.0017e-03,...</td>\n",
       "      <td>tensor([-8.1063e-02, -1.5291e-01,  6.1723e-02,...</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor([-4.0876e-02, -3.4146e-02, -1.3483e-03,...</td>\n",
       "      <td>tensor([-1.8131e-01, -2.6552e-01,  1.4785e-01,...</td>\n",
       "      <td>tensor([ 0.0035, -0.0956, -0.0396, -0.1699,  0...</td>\n",
       "      <td>tensor([ 2.7631e-01, -1.1319e-01, -6.0725e-02,...</td>\n",
       "      <td>tensor([ 9.9797e-02, -1.2169e-01, -1.7010e-02,...</td>\n",
       "      <td>tensor([ 5.6154e-02,  1.4585e-01, -1.6363e-01,...</td>\n",
       "      <td>tensor([ 1.3068e-02, -2.1405e-01,  3.1282e-02,...</td>\n",
       "      <td>tensor([-1.4790e-01,  1.9107e-01,  1.5564e-01,...</td>\n",
       "      <td>tensor([ 1.4720e-01, -3.3228e-02, -2.8897e-01,...</td>\n",
       "      <td>tensor([ 3.3652e-03, -1.7468e-01, -1.2044e-01,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ocr_transcription_llava_embedding</td>\n",
       "      <td>tensor([-1.5069e-01, -4.7678e-02, -5.0572e-02,...</td>\n",
       "      <td>tensor([-4.1617e-03, -4.7293e-02, -7.4943e-02,...</td>\n",
       "      <td>tensor([ 5.7992e-03, -2.2144e-01, -1.7809e-01,...</td>\n",
       "      <td>tensor([ 1.6927e-02, -3.4209e-02, -5.8822e-02,...</td>\n",
       "      <td>tensor([ 0.0422,  0.1119, -0.1470, -0.1917,  0...</td>\n",
       "      <td>tensor([-4.6075e-02, -1.8089e-01,  4.9301e-03,...</td>\n",
       "      <td>tensor([ 0.0899, -0.2315, -0.0652, -0.2966, -0...</td>\n",
       "      <td>tensor([-1.2094e-01, -2.1370e-02, -2.5478e-04,...</td>\n",
       "      <td>tensor([-8.1063e-02, -1.5291e-01,  6.1723e-02,...</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor([-4.0876e-02, -3.4146e-02, -1.3483e-03,...</td>\n",
       "      <td>tensor([-1.8131e-01, -2.6552e-01,  1.4785e-01,...</td>\n",
       "      <td>tensor([ 0.0035, -0.0956, -0.0396, -0.1699,  0...</td>\n",
       "      <td>tensor([ 2.7631e-01, -1.1319e-01, -6.0725e-02,...</td>\n",
       "      <td>tensor([ 0.0938, -0.2037, -0.0279, -0.1850, -0...</td>\n",
       "      <td>tensor([ 5.6154e-02,  1.4585e-01, -1.6363e-01,...</td>\n",
       "      <td>tensor([ 1.0324e-03, -1.5084e-01,  6.6102e-02,...</td>\n",
       "      <td>tensor([-0.1330,  0.0448,  0.2359, -0.1617,  0...</td>\n",
       "      <td>tensor([ 1.4720e-01, -3.3228e-02, -2.8897e-01,...</td>\n",
       "      <td>tensor([ 3.3652e-03, -1.7468e-01, -1.2044e-01,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 90 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T13:14:03.959575Z",
     "start_time": "2024-07-11T13:14:03.748574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get img_path\n",
    "img_path = df_data_extensive.iloc[0].to_dict().values()\n",
    "\n",
    "# convert to list\n",
    "img_path = list(img_path)\n",
    "img_path = img_path[1:]\n",
    "logger.info(img_path)"
   ],
   "id": "4dc309313f9be6ab",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-07-11 15:14:03.942\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m7\u001B[0m - \u001B[1m['/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-080-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-026-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-038-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-045-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-034-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-049-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-057-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-002-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-061-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-010-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-073-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-028-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-055-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-036-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-047-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-024-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-059-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-071-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-012-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-063-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-082-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-067-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-079-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-004-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-075-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-008-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-016-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-043-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-020-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-051-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-032-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-086-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-088-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-084-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-069-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-014-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-077-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-006-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-065-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-018-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-030-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-053-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-022-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-041-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-060-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-003-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-072-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-011-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-044-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-039-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-027-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-056-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-048-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-035-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-083-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-013-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-070-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-001-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-062-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-037-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-054-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-029-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-058-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-025-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-046-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-087-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-021-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-042-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-033-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-050-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-005-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-078-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-066-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-017-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-009-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-074-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-052-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-031-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-040-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-023-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-076-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-015-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-068-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-019-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-064-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-007-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-089-01.jpg', '/Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-085-01.jpg']\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T13:14:20.374769Z",
     "start_time": "2024-07-11T13:14:20.068293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get llm_long_summary \n",
    "llm_long_summary = df_data_extensive.iloc[6].to_dict().values()\n",
    "\n",
    "# convert to list\n",
    "llm_long_summary = list(llm_long_summary)\n",
    "llm_long_summary = llm_long_summary[1:]\n",
    "logger.info(llm_long_summary)"
   ],
   "id": "36b7d851b10032d2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-07-11 15:14:20.370\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m7\u001B[0m - \u001B[1m['Method 2: Using Technology - The lecture discussed how technology can be used to find binomial probabilities. It mentioned that technologies such as spreadsheets and calculators can help in this process. The slide provided an example of a binomial probability, where there are two possible outcomes (success or failure) and the probability of each outcome is known. The slide also included a visual aid, which seems to be a screenshot of a spreadsheet with a formula for calculating the probability of a binomial event.', 'The slide explains notation for binomial probability distributions, which model the number of successes in a series of independent trials. The notation includes P(x) - probability of getting exactly x successes among n trials, where 0 ≤ x ≤ n. The probability of success (P) and failure (q) are also defined. The bionomial formula is given as P(x; n) = (n choose x) * p^x * (1 - p)^(n - x), where p is the probability of success on any single trial.', 'The concept of success as used here is arbitrary and does not necessarily represent something good. The probability of a binomial distribution should be consistent with the category being called a success. The lecture focused on the importance of understanding the context and main points discussed on the slides, highlighting the most important ideas and concepts.', 'The lecture discussed a binomial distribution example related to Twitter data collection or sentiment analysis. The procedure involves identifying values of n, x, p, and q. With five randomly selected adults, we have n=5, and we want the probability of exactly three who know what Twitter is, so x = 3.', \"A binomial probability distribution results from a procedure that meets four requirements: a fixed number of trials, independent trials, a constant probability of success on each trial, and the outcome of any individual trial does not affect the probabilities in other trials. The distribution is characterized by two parameters: n (the number of trials) and p (the probability of success on each trial). It's commonly used in fields like finance, marketing, and quality control.\", \"The lecture discussed the importance of using Twitter effectively in an educational context. It emphasized that x and p both refer to the same concept of success, with x being the number of people who have heard of Twitter and p being the probability that a specific person has heard of Twitter. The slide highlighted the benefits of using Twitter as a professional tool for educators, including sharing resources, connecting with peers, and learning from others' successes.\", 'The probability of getting exactly 3 right answers out of 10 questions is about 1/4 or approximately 0.2503, not exactly. There are many different ways to get 3 right answers, and each outcome has a specific probability. The total number of ways to get exactly 3 right answers is 120, which is calculated using the combination formula (10 choose 3).', 'The binomial distribution, binomial probability distribution is a specific discrete probability distribution. This chapter focuses on discrete probability distributions. The concept of probability is defined as the distribution and methods for finding probabilities. The probability of an event occurring can be determined by considering the number of favorable outcomes divided by the total number of possible outcomes. The binomial distribution is a statistical model used to describe the probability of a certain number of successes in a fixed number of trials, where each trial has only two possible outcomes: success or failure. Easy methods for finding the mean and standard deviation of a binomial distribution are presented. Interpreting probability values is important to determine whether events are significantly low or high.', 'Given that there is a 0.85 probability that a randomly selected adult knows what Twitter is, use the binomial probability formula to find the probability that when five adults are randomly selected, exactly three of them know what Twitter is. The concept being explained here is the calculation of probabilities from percentages, which is a fundamental skill in statistics and probability theory.', 'Pop quiz! The lecture started with a pop quiz, where students had to guess the answers without any questions. The lecturer forgot to bring the questions, but still wanted students to participate. The quiz was meant to be fun and interactive, and students were encouraged to just make their guesses and then grade their papers.', \"The slide appears to be part of a quiz activity where students are asked to observe and compare theoretical probabilities with actual observed frequencies. The table shows the frequency of different events or outcomes, with two columns for 'Observed' and 'Theoretical.' The slide seems to be summarizing a statistical analysis or comparison between observed and theoretical probabilities for different events or outcomes, possibly within an educational context such as a lecture on probability theory or statistics.\", 'The concept of success as used here is arbitrary and does not necessarily represent something good. The probability of a binomial distribution should be consistent with the category being called a success. When using a binomial probability distribution, ensure that x and p are consistent and refer to the same category being called a success.', 'The lecture discusses developing a formula to find the probability of getting exactly 3 right answers out of 4 on a pop quiz. The formula involves calculating the probability of getting the first three right as (1/4)^(3) and the probability of getting the last seven wrong as (3/4)^(7). The outcome is calculated as (1/4)^(3) * (3/4)^(7), which equals approximately 0.00208.', 'The lecture discussed Binomial Probability Distribution, which models the number of successes in a fixed number of independent trials with a constant probability of success for each trial. The concept was explained through an example of calculating the probability of obtaining exactly 4 successes in 10 trials with a 50% chance of success for each trial. The importance of independence and replacement in the trials was highlighted, as well as the application of this distribution to real-world scenarios.', 'The lecture discussed the use of Twitter for educational purposes. It highlighted the benefits of using Twitter as a platform for sharing ideas, asking questions, and learning from others. The slide presented three scenarios: scenario 1 where a teacher uses Twitter to solve problems or discuss with others; scenario 2 where they search for information related to their problem; and scenario 3 where they share resources or knowledge with others. The lecture emphasized that Twitter can be used as a valuable tool for teachers to enhance their teaching practices and engage with students or colleagues in a more interactive way.', \"The lecture discussed binomial probability distributions, explaining how to calculate the probability of getting exactly x successes among n trials. The notation includes X representing a specific number of successes in n trials, p representing the probability of success in one trial, and q representing the probability of failure in one trial. The probability distribution is represented by P(X=k) = C(n, k) * p^k * (1-p)^(n-k), where 'C' represents the binomial coefficient, 'p' is the probability of success, and 'k' is the number of successes. The total number of possible outcomes for a binomial experiment with n trials and k successes is given by C(n, k).\", 'The lecture discussed methods for finding binomial probabilities, specifically focusing on the binomial probability formula (P(x) = Cm,x) p* qh ™). The formula calculates the probability of success in a binomial experiment. The lecturer mentioned that there are two main methods: formula 1 and formula 2, which involve multiplying the number of successes by the probability of success and relating to the binomial distribution respectively. The slide included a mathematical expression for the binomial probability formula, highlighting its importance in the lecture.', \"The lecture discussed how many students got right on a pop quiz and calculated the probability of getting that many right by chance, using the formula. The class observed that nobody got 6 right, so they compared theoretical probabilities to results. The slide showed a question prompt asking for the number of right answers one would get on a pop quiz if they got right on 8 out of 10 questions and used the 'right answer' strategy to find the correct answer in 6 out of 7 questions instead of using the 'chance' strategy.\", \"The lecture appears to be about a pop quiz or exam, featuring a humorous take on the challenges of taking a test. The slide includes a scenario where the person has forgotten their number and is trying to remember it. The lecturer's tone is light-hearted and relatable, acknowledging the stress and frustration students face during exams. The main points discussed include the importance of remembering one's number, the need for honesty when grading one's own paper, and the humorous approach taken by the lecturer to make the experience more enjoyable.\", 'The lecture discussed micronutrients, specifically vitamins. Vitamins are organic substances that primarily function as coenzymes, aiding in chemical reactions. Most vitamins cannot be synthesized by the body and must be obtained from food, except for Vitamin D which requires sunlight for synthesis. In regions with low sunlight, Vitamin D deficiency is more common, and supplementation is often recommended. The lecture highlighted the importance of vitamins for bodily functions and disease prevention.', 'The lecture discussed methods for finding binomial probabilities using technology. The slide presented an example of how to calculate the probability of a binomial event using a specific method, displaying the result on the screen as a table. The lecturer also mentioned Excel as their favorite tool for finding binomial probabilities.', 'The probability of getting exactly three adults who know Twitter among five randomly selected adults is 0.138. The solution involves using the binomial probability formula, where n=5, x=3, p=0.614128, and q=0.0225. The result is rounded to three significant digits.', 'The lecture discussed methods for finding binomial probabilities, specifically Method 2: Using Technology. Technologies can be used to find binomial probabilities, with examples provided on the slide. The screen displays a list of binomial probabilities for each display, showing the probability distribution as a table.', 'The lecture focused on binomial probability distribution and methods for finding probabilities. The focus of this section is the binomial probability distribution and methods for finding probabilities. Easy methods for finding the mean and standard deviation of a binomial distribution are also presented. As in other sections, we stress the importance of interpreting probability values to determine whether events are significantly low or significantly high.', 'The lecture discusses relative frequency and theoretical probabilities, presenting a table comparing observed and theoretical probabilities of six events. The lecturer highlights the importance of understanding these concepts, particularly in statistics and probability.', 'The lecture appears to be an interactive presentation that involves a quiz with multiple-choice questions. The slide asks learners to number their paper 1-10, with each question having four options. The presence of a quiz suggests an interactive element in the lecture, which could be used to engage the audience and assess their understanding of the topic being discussed.', \"The lecture discussed a recent class who did an experiment on cent class. The results showed that some students scored 0, while others scored 4 or 8. The lecturer mentioned that they've already done this experiment and will be discussing the main points. The slide contains tables and figures showing the frequency of scores and relative frequencies. The LLAVA output suggests that the slide is part of an academic lecture on cent class, with a title and subtitle indicating the topic. The main content area likely includes the main body of text and accompanying figures or diagrams.\", 'The lecture discussed Twitter, specifically a solution to determine whether each of 5 randomly selected adults knows what Twitter is or not. Each trial has two categories of outcomes: the selected person knows what Twitter is or that person does not know what Twitter is. The probability of knowing what Twitter is remains the same for each of the five selected people at 0.85.', 'The slide explains the binomial probability distribution, a statistical model used to predict the number of successes in a fixed number of independent trials with a constant probability of success for each trial. The procedure requires four conditions: each trial has a success or failure outcome, trials are independent, the probability of success is constant, and there is a fixed number of trials. The slide provides an example of a binomial distribution with four trials, where each trial has a 50% chance of success or failure. A graph represents the binomial probability distribution, showing the probability of obtaining a certain number of successes in a fixed number of independent trials.', \"When sampling without replacement and the sample size is no more than 5% of the population, treat the selections as being independent (even though they are actually dependent). This guideline is often referred to as the '6% guideline for cumbersome calculations.' The slide also discusses confidence intervals, including a 95% confidence interval and a 100% confidence interval. The lecture appears to be discussing statistical methods and the use of confidence intervals when dealing with dependent events.\", 'When an adult is randomly selected with replacement, there is a 0.85 probability that this person knows what Twitter is. The procedure aims to find the probability that exactly 3 of 5 randomly selected adults know what Twitter is. This procedure results in a binomial distribution. The values of n (number of trials), x (number of successes), p (probability of success), and q (probability of failure) are not explicitly stated, but the example illustrates how to calculate probabilities using conditional probability formulas.', 'The lecture discusses binomial probabilities to find the sum of all probabilities for each value of x from 252 through 460, using technology instead of the formula. The notation for binomial probabilities involves n = 460, p=0.5, and q=0.5. The solution is not practical with the formula, as it would require applying it 209 times. Instead, technology is used to find the sum of all probabilities.', 'The lecture discussed the probability of 252 or more successes using the cumulative version of the formula. The lecturer used Excel to calculate the probability, applying the complement rule to find the probability of 251 or fewer wins. The result was approximately 0.976, which means the probability of 252 or more wins is about 0.0224. The lecture also touched on a hypothetical scenario related to overtime rules in football, discussing possession and scores during different overtime periods.', 'Between 1974 and 2011, there were 460 NFL football games decided in overtime, with 252 of them won by the team that won the overtime coin toss. The lecture discusses whether this result is equivalent to random chance or significantly high. It finds the probability of 252 wins or more in 460 games, assuming wins and losses are equally likely.', 'The lecture discussed a pop quiz, focusing on probability theory. The slide presented a question about getting questions right by chance, using the formula to find P(6), the probability of getting 6 right. The lecturer emphasized the importance of understanding chance and how it affects test results.', nan, 'The lecture discussed probability theory, focusing on the comparison between theoretical probabilities and observed frequencies. The slide presented a table showing the relative frequency of different events or outcomes, with two columns for observed and theoretical probabilities. The lecturer emphasized the importance of understanding probability concepts to predict outcomes and highlighted the difference between theoretical and observed probabilities.', \"Pop quiz! The lecture appears to be an interactive educational activity designed to test students' understanding of a topic or concept. Students are asked to number their answers for 10 questions, each with four choices (A, B, C, or D). The main instruction is to arrange the numbers from 1-9 in a specific order for each question.\", 'The lecture discussed probability theory using Twitter as an example. The slide presented a mathematical problem to calculate the probability of getting exactly three adults among five selected adults who know Twitter, given values of x, p, and q. The formula used was P(x) = (n choose k) * p^k * q^(n-k), where n is the total number of adults, k is the number of adults selected, and p and q are the probabilities of selecting an adult or not. The probability calculated was 0.138.', \"The binomial probability distribution results from a procedure that meets four requirements: the procedure has a fixed number of trials, the trials must be independent, the outcome of any individual trial doesn't affect the probabilities in other trials, and the probability of success on each trial is constant. The slide explains how to calculate the probability of obtaining a certain number of successes in a fixed number of trials using the binomial distribution formula.\", 'The concept of success as used here is arbitrary and does not necessarily represent something good. Either of the two possible categories may be called the success S, as long as its probability is identified as p. CAUTION: When using a binomial probability distribution, always ensure that x and p are consistent in the sense that they both refer to the same category being called a success.', 'When sampling without replacement and the sample size is no more than 5% of the population, treat the selections as being independent (even though they are actually dependent). This guideline helps simplify cumbersome calculations by assuming that events are independent when they are not. The selection process can be treated as if it were independent, even though the actual events are dependent.', 'A binomial probability distribution results from a procedure that meets four requirements: each trial must have all outcomes classified into exactly two categories, commonly referred to as success and failure. The probability of a success remains the same in all trials. This distribution describes the number of successes in a fixed number of independent Bernoulli trials, where each trial has only two possible outcomes: success or failure. It provides a clear definition and context for understanding this distribution.', 'The lecture discusses Twitter data analysis, specifically a solution that satisfies the requirements for a binomial distribution. The procedure involves 5 independent trials, where the probability of an adult knowing Twitter is not affected by results from other selected adults.', 'The binomial probability formula P(x) = (nCx) * p^x * q^(n-x) calculates the probability of success in a binomial experiment. The number of trials (n), number of successes (x), probability of success (p), and probability of failure (q) are used to determine the probability. The formula works for any value of x from 0 to n, with p and q staying constant throughout the problem. The focus is on finding the probability of a specific number of successes among n trials.', 'The lecture focused on binomial probability distribution and methods for finding probabilities. Easy methods for finding the mean and standard deviation of a binomial distribution were presented. The importance of interpreting probability values to determine whether events are significantly low or high was stressed.', 'The lecture discussed how many students got right on a pop quiz, using the formula to find the probability of getting that many right by chance. The class observed results were compared to theoretical probabilities. The lecturer asked students to pause and try the problem, then come back to compare notes.', 'The slide presents the results of a recent class experiment, showing the scores of individual students with relative frequency. The lecturer discussed the performance of students in a particular class, highlighting the scores ranging from 6 to 9. No additional context or analysis was provided beyond the raw data presented in the table.', 'The lecture discusses a procedure that results in a binomial distribution, with values of n=5, x=3, p, and q. The example uses Twitter as a source of data, collecting information on the frequency of certain words or phrases. The equation θ = 1/n * sum(λ_i) is used to estimate parameters based on observed values. The lecture highlights the importance of identifying these values in statistical analysis.', 'When an adult is randomly selected (with replacement), there is a 0.85 probability that this person knows what Twitter is. Suppose that we want to find the probability that exactly three of five randomly selected adults know what Twitter is. This procedure results in a binomial distribution with n=5, x=3, p=0.85, and g=1.', 'The binomial distribution is used to model the number of successes in a fixed number of trials. The notation P(x) represents the probability of getting exactly x successes among n trials, where p is the probability of success and q is the probability of failure in one trial. The binomial distribution is discrete, meaning it only takes on integer values for k, and the sum of all probabilities from 0 to n equals 1. The mean (μ) and variance (σ^2) can be calculated using the formulas: μ = np and σ^2 = np(1 - p).', \"The lecture discussed probability theory, specifically the binomial distribution. The slide presented an equation related to the probability of getting exactly 3 right out of 10 trials with a certain probability of success for each trial. The equation includes variables such as 'n', 'k', and 'p'. The presenter explained that there are multiple ways to get 3 right, but the probability of this exact outcome is approximately 0.00208. The slide also included a visual aid, possibly a graph or chart, related to the binomial distribution.\", 'Again, it is very important to be sure that x and p both refer to the same concept of “success.” In this example, we use x to count the number of people who know what Twitter is, so p must be the probability that the selected person knows what Twitter is. Therefore, x and p do use the same concept of success: knowing what Twitter is. The slide emphasizes that Twitter can be used as an educational tool, suggesting it for sharing information, updates on assignments, and communication among students and instructors. It provides a visual representation of the Twitter interface, which includes the search bar, tweet composition box, user profile icon, and timeline of tweets.', 'The lecture discussed Binomial Probability Distribution, a statistical method used to predict the outcome of a series of independent trials. The procedure has a fixed number of trials, which must be independent. The lecturer gave an example of asking five adults if they have heard of Twitter, illustrating how this concept applies in real-life scenarios.', 'The lecture discussed Method 2: Using Technology to find binomial probabilities. It explained that technologies can be used to calculate binomial probabilities, using a formula that includes the binomial coefficient, probability of success (p), and probability of failure (q). The example provided showed how to calculate binomial probabilities for n=5 and p = 0.85, with a table demonstrating the calculation process.', \"The lecture discussed Method 2: Using Technology to find binomial probabilities. The presenter explained how to use Excel's formula, `binom.dist(x, n, p, false)`, to calculate a binomial probability. The inputs are X (number of successes), n (number of trials), and p (probability of success). The formula is used to calculate the probability of exactly X successes in n trials, without making it cumulative. If the `false` input is changed to `true`, the formula calculates the probability of X or fewer successes.\", \"The slide appears to be from an academic lecture discussing organizational behavior and human resources management. The lecture covers various concepts, including employee motivation, team development, organizational culture, job satisfaction, turnover, leadership styles, performance, and job stress. The correct answers are based on theories such as Maslow's Hierarchy of Needs, Tuckman's model of team development, Herzberg's Two-Factor Theory, the expectancy theory of motivation, the Job Demands-Resources (JD-R) model, and others.\", 'The lecture discussed a method for calculating the probability of getting certain results based on the number of correct answers from a quiz or test. The speaker asked students to find the probability of getting 6 right out of 8, using the formula and comparing it to the observed results in class.', 'This lecture focused on probability distributions, specifically binomial, Poisson, and normal distributions. Binomial distribution models the number of successes in a fixed number of trials, while Poisson distribution models the number of events occurring within a fixed interval of time or space. Normal distribution is symmetric about the mean and often used to model continuous data that are normally distributed.', nan, 'The lecture discussed binomial probability distributions, focusing on notation and examples. The slide introduced the concept of binomial probability distributions, using mathematical notation to represent the probability of a success or failure in each trial. The notation included P(X=k), p, n, q=1-p, and the binomial coefficient. The example provided was flipping a coin n times and finding the probability that exactly k heads appear. The slide also featured a visual aid showing the probabilities for different numbers of successes out of n trials.', \"When sampling without replacement and the sample size is no more than 5% of the population, treat the selections as being independent (even though they are actually dependent). This guideline suggests that there is a specific threshold for when it's acceptable to treat dependent events as independent in certain statistical analyses. The lecturer emphasized that even though technically they're not independent, picking out a person and then not putting them back doesn't really change the probability of selecting another person with similar characteristics.\", \"The word 'success' as used here is arbitrary and does not necessarily represent something good. Either of the two possible categories may be called the success category, as long as its probability is identified as p. CAUTION: When using a binomial probability distribution, always be sure that x and p are consistent in the sense that they both refer to the same category being called a success.\", 'The lecture discussed two methods for finding binomial probabilities: Method 1 uses the formula P(x) = (nCx) * p^x * q^(n-x), where n is the total number of trials, x is the number of successful outcomes, p is the probability of success in each trial, and q is the probability of failure. Method 2 is a shortcut for small values of x, using the approximation formula: p^x * q^(n-x) = (p + q)^n. The lecture also mentioned that there are n-choose x ways to choose x successful outcomes from n total trials.', 'The lecture discusses biomimetic probability distributions, which model the number of successes in a series of independent trials with two possible outcomes. The notation P(x; n, p) = (nCx) * p^x * (1 - p)^(n - x) represents the probability mass function of a binomial distribution, where X is the specific number of successes, n is the total number of trials, and p is the probability of success. The lecture also covers examples of using this notation to calculate probabilities, such as finding the probability of getting exactly three questions right.', 'The slide discusses Twitter as an example of probability theory. The probability of success (getting a person who knows what Twitter is) for one selection is 0.85, while the probability of failure (not getting someone who knows what Twitter is) is 0.15.', 'The lecture discusses the overtime rule in football, explaining that the probability of 252 or more wins in 460 games is low (less than 0.05). This suggests that it is unlikely to get 252 or more wins by chance, and therefore, the team winning the overtime coin toss has a better chance of winning the game.', \"The binomial probability distribution results from a procedure that meets four requirements: each trial must have all outcomes classified into exactly two categories, commonly referred to as success and failure. The probability of a success remains the same in all trials. A binomial probability distribution is used to predict the outcome of an event that can result in either success or failure. It's based on the binomial theorem and is commonly used in fields like finance, marketing, and quality control.\", 'The lecture discussed a hypothetical scenario or problem set related to Twitter, possibly in the context of statistics, research methodology, or data analysis. The solution involves a binomial distribution and independent trials, with certain conditions specified for the number of trials and the independence of the results from other selected adults. The procedure satisfies the requirements for a binomial distribution, as shown below.', 'A binomial probability distribution results from a procedure that meets four requirements: a fixed number of trials, independent trials, a constant probability of success on each trial, and the outcome of any individual trial does not affect the probabilities in other trials. The distribution is characterized by two parameters: n (the number of trials) and p (the probability of success on each trial). It results in a discrete distribution, meaning that the outcomes are countable. The binomial distribution can be applied to real-world scenarios, such as a biomolecular assay with a 95% success rate.', 'When sampling without replacement and the sample size is no more than 5% of the population, treat the selections as being independent (even though they are actually dependent). This guideline applies to cumbersome calculations and ensures that the sample size is treated as exactly the same as the selection rate, despite their actual dependence.', \"The lecture discussed the concept of a 'Pop quiz!' and highlighted the importance of understanding certain concepts. The slide presented a question asking students to identify the difference between two blank spaces, suggesting an educational session where students are being tested on their knowledge. The lecturer emphasized the significance of grasping key ideas and concepts, but the specific context and content of the question were not visible in the provided image.\", 'The slide compares pop quizzes observed versus theoretical probabilities. The left column lists various numbers representing correct answers on a pop quiz, while the right column shows corresponding theoretical probabilities. The comparison may be used to evaluate the accuracy of theories or models and understand discrepancies between observed data and theoretical probabilities.', 'The slide presents a mathematical problem related to probability and combinatorics, illustrating how these concepts can be applied to understand the likelihood of certain outcomes in a given scenario, such as selecting a specific number of adults from a group of individuals on Twitter. The problem involves using the binomial probability formula to calculate the probability of getting exactly three adults among five randomly selected individuals. The solution is 0.138, indicating that the probability of this outcome is approximately 13.8%. The slide also references a paper or article discussing the application of combinatorial mathematics in real-world scenarios, specifically in the context of social media usage for scientific dissemination.', 'The results of a recent class who did this experiment show that 3 students got zero right, 4 students got one right, 9 students got two right, 5 students got three right, and 3 students got four or five right. The distribution appears to be binomial. The lecturer discussed the importance of understanding frequency distributions and how they can be used to analyze data.', \"The slide announces a pop quiz with 10 questions, each with four choices (A, B, C, or D). The quiz will be structured so that students must number their answers from 1 to 10. The figure on the slide appears to be a flowchart or decision-making process guiding the viewer through a series of steps or decisions. The lecture does not provide specific information about the content of the questions or the flowchart's decision points, but rather provides general information about the quiz structure.\", 'The slide presents a comparison between observed and theoretical probabilities for various demographic variables such as student number, gender, and age group. This type of analysis is commonly used in statistical studies to evaluate the accuracy of predictions made about certain populations based on observed data. The slide seems to be part of an educational presentation or lecture, possibly discussing concepts like hypothesis testing, chi-squared tests for goodness of fit, or other statistical methods that compare observed and expected frequencies.', 'When sampling without replacement and the sample size is no more than 5% of the size of the population, treat the selections as being independent (even though they are actually dependent). This guideline helps to provide a more accurate representation of the population by considering small samples or sampling without replacement. The concept of treating dependent events as independent can be applied in certain statistical contexts.', \"The concept of success as used here is arbitrary and does not necessarily represent something good. The binomial probability distribution is a statistical model used to describe the probability of obtaining a certain number of successes in a fixed number of independent trials, where each trial has only two possible outcomes: success or failure. When using this distribution, it's crucial to ensure that X and P are consistent throughout the problem, with X representing the number of successes and P being the probability of success. The lecture also highlights the importance of sticking to a specific category of outcomes and not switching between them. Additionally, the binomial distribution can be used to calculate probabilities for real-world scenarios.\", 'The lecture discusses a binomial distribution problem where an adult is randomly selected with replacement to find the probability that exactly three of five adults know what Twitter is. The procedure results in a binomial distribution, with n=5, x=3, p=0.85 (probability of success), and q=0.15 (probability of failure).', 'The lecture discussed binomial probability distributions, focusing on notation and formulas. The binomial distribution models the number of successes in a fixed number of independent Bernoulli trials, where each trial results in one of two possible outcomes: success or failure. The probability mass function (PMF) is given by the formula P(X=k) = (nCk) * p^k * (1-p)^(n-k), where n represents the number of trials, k represents the number of successes, and p represents the probability of success. The lecture also touched on the importance of notation, using P for the probability of success and Q for the probability of failure, with P + Q = 1.', 'The slide presents a quiz on observed vs theoretical probabilities, comparing actual frequencies with expected values. The lecturer discussed how to analyze and interpret data related to probability theory, highlighting the importance of understanding both observed and expected values. The main points include: 0.056 is the probability of getting non-right answers, 0.188 is the probability of getting one right answer, and there are differences between observed and expected probabilities.', 'The lecture appears to be an assessment of understanding on a particular topic or subject matter. The lecturer asked the class to answer multiple-choice questions, with options A, B, C, and D. The answers were not provided, but the lecturer asked the class to share how they did and counted the number of people who got zero right, one right, two right, etc.', 'The lecture discussed how many students got right on a pop quiz, finding the probability of getting that many right by chance using the formula. Theoretical probabilities were compared to observed results in class. The slide presented a method or strategy for improving performance on pop quizzes, emphasizing the importance of identifying problems and using the right approach.', \"The binomial probability distribution results from a procedure that meets four requirements: the procedure has a fixed number of trials, the trials must be independent, the outcome of any individual trial doesn't affect the probabilities in other trials, and the probability of success for each trial remains constant. The procedure is used to calculate the probability of obtaining a certain number of successes (or failures) in a series of independent trials. The binomial distribution is a discrete probability distribution that models the number of successes in a fixed number of trials with constant probability of success for each trial.\", 'The lecture discussed calculators and mathematical calculations. The presenter used a calculator to demonstrate how to calculate the probability of exactly 3 out of 5 adults having heard of Twitter. The calculation involved raising 0.85 to the power of 3, multiplying by 0.15 squared, and then subtracting 3 from 5. The result was approximately 0.138. The lecture likely focused on calculators or mathematical computations, possibly teaching mathematical concepts.', 'Pop quiz! The lecture appears to be an academic presentation discussing a pop quiz with 10 questions, each with four multiple-choice answers. The quiz requires students to number their papers from 1-10 and answer the questions. The slide does not provide specific details about the content of the quiz or the correct answers.', \"The probability of 252 or more wins in 460 overtime games is 0.0224 (rounded), which is low, indicating that it's unlikely to get 252 or more wins by chance. This suggests that the team winning the overtime coin toss has a better chance of winning the game. The working definition of an unusual event is anything with a probability of 0.05 or less, and since this probability is less than 0.05, we can conclude that 252 is unusually high. This may indicate that my assumption that wins and losses are equally likely was wrong, and maybe it's true that the team winning the overtime coin toss has an advantage in actually winning the game.\", 'The lecture discussed NFL football games decided in overtime between 1974 and 2011. It was found that 252 of these games were won by the team that won the overtime coin toss, which raises the question of whether this result is equivalent to random chance or significantly high. Assuming wins and losses are equally likely, the probability of 252 wins or more in 460 games was calculated.']\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T13:14:21.509927Z",
     "start_time": "2024-07-11T13:14:21.297832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get ocr_only\n",
    "# Since ocr_only embeddings can't be mapped to floats due to e-02, e-01, we're generating new embeddings \n",
    "ocr_only = df_data_extensive.iloc[3].to_dict().values()\n",
    "\n",
    "# convert to list\n",
    "ocr_only = list(ocr_only)\n",
    "ocr_only = ocr_only[1:]\n",
    "logger.info(ocr_only)"
   ],
   "id": "11272fdcf7b8bc3b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-07-11 15:14:21.500\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m8\u001B[0m - \u001B[1m['Method 2: Using Technology\\n\\nTechnologies can be used to find binomial probabilities. The\\nscreen displays on the next slide list binomial probabilities for\\nn=5 and p = 0.85, as in the previous example. Notice that in\\neach display, the probability distribution is given as a table.\\n\\nCopyright © 2038, 2014, 2012 Pearton Education,\\n\\n', 'be any whole number between 0 and n, inclusive\\nPp - probability of success in one of the n trials\\n\\nq- probability of failure in one of the n trials\\n\\nP(x) - probability of getting exactly x successes among\\n\\nthe n trials\\n\\nCCopyiht © 2048, 2014, 2012 Pearson Education, Ine. Al Rights Reserved\\n', 'The word success as used here is arbitrary and does\\nnot necessarily represent something good. Either of the\\ntwo possible categories may be called the success S as\\nlong as its probability is identified as p.\\n\\nCAUTION When using a binomial probability distribution,\\nalways be sure that x and p are consistent in the sense\\n\\nthat they both refer to the same category being called a\\nsuccess.\\n\\nCCopyrit © 2038, 2014, 2012 Pearson Edueation, Ine, Al Rights Reserved\\n\\n', 'Solution\\n\\nb. Having concluded that the given procedure does\\nresult in a binomial distribution, we now proceed to\\nidentify the values of n, x, p, and q\\n\\n1. With five randomly selected adults, we have n= 5.\\n\\n2. We want the probability of exactly three who know what\\nTwitter is, so x = 3.\\n\\n‘Copy © 2048, 2014, 2012 Pearson Education, Ine. Al Rights Reserved Oran\\n', \"* Binomial Probability Distribution BS\\n—Abinomial probability distribution results from a\\nprocedure that meets these four requirements:\\nThe procedure has a fixed number of trials. (A\\ntrial is a single observation.)\\n\\n2. The trials must be independent, meaning that the\\n‘outcome of any individual trial doesn't affect the\\nprobabilities in the other trials.\\n\\n‘Copy © 2048, 2014, 2012 Pearson Education, Inc. Al Rights Reserved\\n\", 'ple:\\n\\nSolution\\n\\nAgain, it is very important to be sure that x and p both refer\\nto the same concept of “success.” In this example, we use x\\nto count the number of people who know what Twitter is, so\\np must be the probability that the selected person knows\\nwhat Twitter is. Therefore, x and p do use the same concept\\nof success: knowing what Twitter is.\\n\\nCcopyiht © 2088, 2014, 2012 Pearson Education,\\n', \"Let’s develop the fo\\n\\ni\\n\\n+ On the pop quiz you took earlier, what is the probability of getting et\\nexactly 3 right?\\n\\n+ One way to get three right is RRRWWWWWWW (R = right, W =\\nwrong)\\n\\n+ The probability of this exact outcome is (2) (2) ~ 00208\\n\\n* But this isn't the only way to get three right. There are (10,3)\\n120 different ways to get 3 right (choose 3 spots for the R's)\\n\\nCopyright © 2038, 2014, 2012 Pearson Education, In. All Rights Reserved Orin\\n\", 'Key Concept\\n\\nThe focus of this section is the binomial probability\\ndistribution and methods for finding probabilities.\\n\\nEasy methods for finding the mean and standard\\ndeviation of a binomial distribution are also presented.\\n\\nAs in other sections, we stress the importance of\\ninterpreting probability values to determine whether\\nevents are significantly low or significantly high.\\n\\n', 'Example: Twitter (7 or\\n\\nGiven that there is a 0.85 probability that a randomly\\nselected adult knows what Twitter is, use the binomial\\nprobability formula to find the probability that when five\\nadults are randomly selected, exactly three of them know\\nwhat Twitter is. That is, apply the previous formula to find\\nP(3) given that n = 5, x = 3, p = 0.85, and q=0.15.\\n\\n2018, 2014, 2012 Pearson Edueation, Ine. All\\n\\n', \"Pop quiz!\\n\\n» Number your paper 1-10. There will be 10\\nquestions, each with four choices (A, B, C, or D).\\n\\n* Oops! | forgot to bring the questions. But we\\nhave to have the quiz today, so you'll just have to\\nguess, Aaaaand GO!\\n\\n\", '4\\nX=number Frequency Relative req. Theoretical -\\ntaht prob,\\n\\n0 a a 056\\n\\n1 4 148 128\\n\\n2 9 333 282\\n\\n3 5 195 250\\n\\n4 3 i\" 146\\n\\n5 a 1 058\\n\\n6 Q 000 a6\\n\\n7 o 00 as\\n\\n8 9 60 004\\n\\n9 0 000 00003\\n\\n10 0 000 00004\\n\\nCopyright © 2018, 2014, 2012 Pearson Edveation, In, Al Rights Reserved\\n\\n', 'The word success as used here is arbitrary and does\\nnot necessarily represent something good. Either of the\\ntwo possible categories may be called the success S as\\nlong as its probability is identified as p.\\n\\nCAUTION When using a binomial probability distribution,\\nalways be sure that x and p are consistent in the sense\\n\\nthat they both refer to the same category being called a\\nsuccess.\\n\\n© 2018, 2018, 2012 Pearson Education, Inc. Al Rights Reserves\\n\\n', \"'s develop t mula\\n\\n+ On the pop quiz you took earlier, what is the probability of getting\\nexactly 3 right?\\n\\n+ One way to get three right is RRRWWWWWWW (R = right, W =\\nwrong)\\n\\n+ The probability of this exact outcome is (2) (2) ~ .00208\\n\\nCopyright © 2038, 2014, 2012 Pearson Education, Inc.All Rights Reserved Orann\\n\", 'Proba\\n\\n* Binomial Probability Distribution\\n—Abinomial probability distribution results from a\\n\\ncopyiht\\n\\nprocedure that meets these four requirements:\\n\\n3. Each trial must have all outcomes classified into\\nexactly two categories, commonly referred to as\\nsuccess and failure.\\n\\n4. The probability of a success remains the same in\\nall trials.\\n\\n', 'Solution\\n\\nAgain, it is very important to be sure that x and p both refer\\nto the same concept of “success.” In this example, we use x\\nto count the number of people who know what Twitter is, so\\np must be the probability that the selected person knows\\nwhat Twitter is. Therefore, x and p do use the same concept\\nof success: knowing what Twitter is\\n\\nCopyright © 2038, 2014, 2012 Pearson Education, Inc, All Rights Reserved Orne\\n', 'X-a specific number of successes in n trials, so x can\\nbe any whole number between 0 and n, inclusive\\n\\np- probability of success in one of the n trials\\nq- probability of failure in one of the n trials\\n\\nP(x) - probability of getting exactly x successes among\\nthe n trials\\n\\nCCopyiht © 2088, 2014, 2012 Pearson Education, Inc. Al Rights Reserved @ arson\\n', 'Method 1: Binomial Probability Formula\\n\\nP(x) = Cm, x) p* qh ™\\nforx=0,1,2,...,n\\nwhere\\nn= number of trials\\nx = number of successes among m trials\\nPp = probability of success in any one trial\\nq = probability of failure in any one trial (q = 1 - p)\\n\\nCopyright © 2038, 2014, 2012 Pearson Education, In. Al Rights Reserved Oranwn\\n', \"+ How many did you get right on the pop quiz? Find the\\nprobability of getting that many right by chance, using the\\nformula. If you got three right, we already did that\\nproblem, so find P(6) instead, the probability of getting 6\\nright. We'll compare these theoretical probabilities to the\\nresults we observed in our class.\\n\\nCopyright © 2038, 2014, 2012 Pearson Edueation, Inc.All Rights Reserved pearson\\n\", \"Pop quiz! Ee\\n\\n» Number your paper 1-10. There will be 10 4\\nquestions, each with four choices (A, B, C, or D).\\n\\n* Oops! | forgot to bring the questions. But we\\nhave to have the quiz today, so you'll just have to\\nguess, Aaaaand GO!\\n\\n+ Alldone? | feel bad about that “forgot the\\nquestions’ thing, so I'll let you grade your own\\npaper. (Be honest!) Here are the answers..\\n\\nCCopyrit © 2038, 2014, 2012 Pearson Eaueation, Inc.All Rights Reserved rare\\n\", nan, 'Metr\\n\\nrob\\n\\nMethod 2: Using Technology\\n\\nTechnologies can be used to find binomial probabilities. The\\nscreen displays on the next slide list binomial probabilities for\\nn=5 and p = 0.85, as in the previous example. Notice that in\\neach display, the probability distribution is given as a table.\\n\\nCopyright © 2038, 2014, 2012 PeartonEdueation, Oran\\n\\n', 'Solution\\n\\nUsing the given values of n, x, p, and q in the binomial\\nprobability formula, we get\\n\\n5!\\nP(3)=\\n= Gaya\\n\\n85°.0.15°*\\n\\n= 2! .0.614128-0.0225\\n2131\\n\\n= (10)(0.614125)(0.0225)\\n= 0.138178\\n= 0.138 (round to three significant digits)\\nThe probability of getting exactly three adults who know\\n\\nTwitter among five randomly selected adults is 0.138.\\n\\nAll RightsReserved parse,\\n\\n', 'omial\\n\\nMethod 2: Using Technology\\n\\nTechnologies can be used to find binomial probabilities. The\\nscreen displays on the next slide list binomial probabilities for\\nn=5 and p = 0.85, as in the previous example. Notice that in\\neach display, the probability distribution is given as a table.\\n\\nCopyright © 2038, 2014, 2012 Pearson Edveation, Inc.All Rights Reserved Oranen\\n', 'Key Concept\\n\\nil\\n\\nThe focus of this section is the binomial probability\\ndistribution and methods for finding probabilities.\\n\\nEasy methods for finding the mean and standard\\ndeviation of a binomial distribution are also presented.\\n\\nAs in other sections, we stress the importance of\\ninterpreting probability values to determine whether\\nevents are significantly low or significantly high.\\n\\nCopyright © 2038, 2014, 2012 Pearson Edueation, In. Al Rights Reserved Orr\\n', 'Relative freq. Theoretical\\nprob.\\n\\n0 3 att 056\\n\\n1 4 148 188\\n\\n2 9 333 282\\n\\n3 5 185 250\\n\\n4 3 itt 446\\n\\n5 3 oa 058\\n\\n6 0 (000 016\\n\\n7 0 000 003\\n\\n8 ° ‘000 (0004\\n\\n9 0 000 00003\\n\\n10 0 000 (000001\\n\\nCopyright © 2038, 2014, 2012 Pearson Edueaion, In, Al Rights Reserved @Psrwn\\n', 'Pop quiz! =_\\n\\n+ Number your paper 1-10. There will be 10\\nquestions, each with four choices (A, B, C, or D).\\n\\n2018, 2018, 2012 Pearson Ecucation, Ine. Al Rights Reserved Oranen\\n\\n', 'cent class\\n\\n+ Here are the results for a recent class who did this experiment. The =\\nnumber of students with each score is given, along with the relative\\n\\nf\\nrequency. “x= number right Frequency Relative freq.\\n\\n0 3 Tr\\n148\\n333\\n185\\n44\\n41\\n(000\\n.000\\n(000\\n000\\n(000\\n\\n4\\n8\\n5\\n3\\n3\\n0\\n0\\n0\\n°\\no\\n\\n0\\n\\nCCopyiat © 2048, 2014, 2012 Pearson Education,\\n', 'le: Twitter\\n\\nSolution\\n\\n3. Each of the 5 trials has two categories of outcomes:\\nThe selected person knows what Twitter is or that\\nperson does not know what Twitter is.\\n\\n4. For each randomly selected adult, there is a 0.85\\nprobability that this person knows what Twitter is, and\\nthat probability remains the same for each of the five\\nselected people.\\n\\nCopyright © 2038, 2014, 2012 Pearson Education, Inc.All RightsReserved Oranen\\n', '| Probabi\\n\\n* Binomial Probability Distribution\\n\\n—Abinomial probability distribution results from a\\nprocedure that meets these four requirements:\\n\\n3. Each trial must have all outcomes classified into\\nexactly two categories, commonly referred to as\\nsuccess and failure.\\n\\n4. The probability of a success remains the same in\\nall trials.\\n\\n‘Copy © 2038, 2014, 2012 Pearson Education, Inc. Al Rights Reserved Orinn\\n', '5% Guideline for Cumbersome Calculations\\n\\nWhen sampling without replacement and the sample\\nsize is no more than 5% of the size of the population,\\ntreat the selections as being independent (even though\\nthey are actually dependent).\\n\\nCCopyiht © 2088, 2014, 2012 Pearson Education, Ine. Al Rights Reserved\\n\\n', 'Twit\\n\\nTter (1 of\\n\\nWhen an adult is randomly selected (with replacement), [ug\\nthere is a 0.85 probability that this person knows what\\n‘Twitter is (based on results from a Pew Research\\n\\nCenter survey). Suppose that we want to find the\\n\\nprobability that exactly three of five randomly selected\\nadults know what Twitter is.\\n\\na. Does this procedure result in a binomial distribution?\\n\\nb. If this procedure does result in a binomial distribution,\\nidentify the values of n, x, p, and g.\\n\\ncopyright © 2038, 2014, 2012 Pearson Education, I\\n\\nAl Rights Reserves rere\\n', \"Solution ‘\\n\\nUsing the notation for binomial probabilities, we have n = 460,\\np=0.5, q=0.5, and we want to find the sum of all\\nprobabilities for each value of x from 252 through 460. The\\nformula is not practical here, because we would need to apply\\nit 209 times—we don't want to go there. Table A-1 (Binomial\\nProbabilities) doesn't apply because n = 460, which is way\\nbeyond the scope of that table. Instead, we wisely choose to\\nuse technology.\\n\\nCopyright © 2038, 2014, 2012 Pearson Eeuca\\n\\n\", '.S77S7AOE] puting \"tue\" atthe end gives P25 or fewer wins)\\n0,022428837Thsisthe probably ofthe complement, 252 or more\\n\\nCopyright © 2038, 2014, 2012 Pearson Education, In, All Rights Reserved Oranen\\n', 'Foo =\\nWe previously noted that between 1974 and 2011, there\\nwere 460 NFL football games decided in overtime, and\\n252 of them were won by the team that won the\\novertime coin toss. Is the result of 252 wins in the 460\\ngames equivalent to random chance, or is 252 wins\\nsignificantly high? We can answer that question by\\nfinding the probability of 252 wins or more in 460\\ngames, assuming that wins and losses are equally\\n\\nlikely.\\n\\n* © 2018, 2018, 2012 Pearson Edueaton Ine.\\n\\nAl Rights Reserve Oranwn\\n', \"pop\\noF\\n\\n+ How many did you get right on the pop quiz? Find the\\nprobability of getting that many right by chance, using the\\nformula. If you got three right, we already did that\\nproblem, so find P(6) instead, the probability of getting 6\\nright. We'll compare these theoretical probabilities to the\\nresults we observed in our class.\\n\\nCopyright © 2038, 2014, 2012 Pearton Eda,\\n\\n\", 'The Answers — how did you do?\\n\\n', '1 vs. theoretical\\n\\nRelative freq. Theoretical\\nprob.\\n\\n0 3 it 056\\n\\n1 4 148 188\\n\\n2 9 333 282\\n\\n3 5 185 250\\n\\n4 3 itt 446\\n\\n5 3 oa) 058\\n\\n6 0 000 016\\n\\n7 ° 000 003\\n\\n8 ° ‘000 (0004\\n\\n9 0 000 00003\\n\\n10 0 (000 (000001\\n\\nCCopyiht © 2048, 2014, 2012 Pearson Education, Inc, Al Rights Reserved\\n\\n', 'Pop quiz! =\\n\\nNumber your paper 1-10. There will be 10\\nquestions, each with four choices (A, B, C, or D).\\n\\nI Righe Reserves Oran\\n', 'Example: Twitter (ors =\\n\\nSolution\\nUsing the given values of n, x, p, and q in the binomial\\nprobability formula, we get\\n\\n!\\nP(3) => 85°.0.15°°\\n6-331\\n\\n= 2! .0.614128-0.0225\\n2131\\n\\n= (10)(0.614125)(0.0225)\\n= 0.138178\\n= 0.138 (round to three significant digits)\\n\\nThe probability of getting exactly three adults who know\\nTwitter among five randomly selected adults is 0.138.\\n\\n', \"* Binomial Probability Distribution\\n—Abinomial probability distribution results from a\\nprocedure that meets these four requirements:\\n\\nThe procedure has a fixed number of trials. (A\\ntrial is a single observation.)\\n\\n2. The trials must be independent, meaning that the\\noutcome of any individual trial doesn't affect the\\nprobabilities in the other trials.\\n\\nCopyright © 2038, 2014, 2012 PeartonEdeation,\\n\\n\", 'The word success as used here is arbitrary and does\\nnot necessarily represent something good. Either of the\\ntwo possible categories may be called the success S as\\nlong as its probability is identified as p.\\n\\nCAUTION When using a binomial probability distribution,\\nalways be sure that x and p are consistent in the sense\\n\\nthat they both refer to the same category being called a\\nsuccess.\\n\\nCopyright © 2038, 2014, 2012 Pearson Education, I\\n\\n', '5% Guideline for Cumbersome Calculations\\n\\nWhen sampling without replacement and the sample\\nsize is no more than 5% of the size of the population,\\ntreat the selections as being independent (even though\\nthey are actually dependent).\\n\\nCopyright © 2038, 2014, 2012 Pearson Edueation, Inc.All Rights Reserved Oran\\n', 'lal Pro\\n\\n* Binomial Probability Distribution\\n\\n— Abinomial probability distribution results from a\\nprocedure that meets these four requirements:\\n3. Each trial must have all outcomes classified into\\nexactly two categories, commonly referred to as.\\nsuccess and failure.\\n\\n4. The probability of a success remains the same in\\nall trials.\\n\\nCopyright © 2038, 2014, 2012 Pearton Education, Oran\\n\\n', 'Solution\\n\\na. This procedure does satisfy the requirements for a\\nbinomial distribution, as shown below.\\n\\n1, The number of trials (5) is fixed\\n\\n2. The 5 trials are independent because the probability of\\nany adult knowing Twitter is not affected by results from\\nother selected adults.\\n\\nOrearson\\n', 'Method 1: Binomial Probability Formula\\n\\nP(x) = C(m, x) p* qh ™\\nforx=0,1,2,...,n\\nwhere\\nn= number of trials\\nx = number of successes among n trials\\nPp = probability of success in any one trial\\nq = probability of failure in any one trial (q = 1 - p)\\n\\nCopyright © 2038, 2014, 2012 Pearson Education, In. Al Rights Reserved\\n', 'Key Concept =\\n\\nThe focus of this section is the binomial probability\\ndistribution and methods for finding probabilities.\\n\\nEasy methods for finding the mean and standard\\ndeviation of a binomial distribution are also presented.\\n\\nAs in other sections, we stress the importance of\\ninterpreting probability values to determine whether\\nevents are significantly low or significantly high.\\n\\nCopyright © 2038, 2014, 2012 Pearson Edveation, Inc.All Rights Reserved rar\\n', \"+ How many did you get right on the pop quiz? Find the\\nprobability of getting that many right by chance, using the\\nformula. If you got three right, we already did that\\nproblem, so find P(6) instead, the probability of getting 6\\nright. We'll compare these theoretical probabilities to the\\nresults we observed in our class.\\n\\nCCopyiht © 2088, 2014, 2012 Pearson Education, Ine, Al Rights Reserved Oran\\n\", 'Results for a recent class\\n\\n+ Here are the results for a recent class who did this experiment. The\\nnumber of students with each score is given, along with the relative\\n\\nfrequen i\\neauency. “x= numberright Frequency Relative freq.\\n\\n) 3 Ta\\n148\\n333\\n185\\n44\\na1\\n(000\\n.000\\n(000\\n.000\\n(000\\n\\n4\\n8\\n5\\n3\\n3\\n)\\n0\\n0\\n0\\nO\\n\\n', 'Solution\\n\\nb. Having concluded that the given procedure does\\nresult in a binomial distribution, we now proceed to\\nidentify the values of n, x, p, and q\\n\\n1. With five randomly selected adults, we have n= 5.\\n\\n2. We want the probability of exactly three who know what\\nTwitter is, so x = 3.\\n\\nCopyright © 2038, 2014, 2012 Pearson Education, Inc.All Rights Reserved Oran\\n', 'When an adult is randomly selected (with replacement),\\nthere is a 0.85 probability that this person knows what\\nTwitter is (based on results from a Pew Research\\nCenter survey). Suppose that we want to find the\\nprobability that exactly three of five randomly selected\\nadults know what Twitter is.\\n\\na. Does this procedure result in a binomial distribution?\\n\\nb. If this procedure does result in a binomial distribution,\\nidentify the values of n, x, p, and g.\\n\\nCopyright © 2038, 2014, 2012 Pearson Edueation, In, Al Rights Reserved Oranwn\\n', 'X - a specific number of successes in n trials, so x can\\nbe any whole number between 0 and n, inclusive\\n\\np- probability of success in one of the n trials\\nq- probability of failure in one of the n trials\\n\\nP(x) - probability of getting exactly x successes among\\nthe n trials\\n\\ncopyright © 2038, 2014, 2012 Pearson Education, In. Al\\n\\n', \"Copyright © 2038, 2014, 2012 Pearton Eda,\\n\\nOn the pop quiz you took earrier, what is the probability of getting\\nexactly 3 right?\\n\\n(One way to get three right is RRRWWWWWWW (R = right, W =\\nwrong)\\n\\nThe probability of this exact outcome is (*) (2) ~.00208,\\n\\nBut this isn't the only way to get three right. There are C(10,3) =\\n120 different ways to get 3 right (choose 3 spots for the R's)\\n\\nAl RightsReserved raven\\n\", 'Example: Twitter «\\n\\nSolution\\n\\nAgain, it is very important to be sure that x and p both refer\\nto the same concept of “success.” In this example, we use x\\nto count the number of people who know what Twitter is, so\\np must be the probability that the selected person knows\\nwhat Twitter is. Therefore, x and p do use the same concept\\nof success: knowing what Twitter is.\\n\\nCopyright © 2038, 2014, 2012 Pearson Education, Inc.All Rights Reserved rare\\n', '1a\\n\\n* Binomial Probability Distribution\\n—Abinomial probability distribution results from a\\nprocedure that meets these four requirements:\\nThe procedure has a fixed number of trials. (A\\ntrial is a single observation.)\\n\\n2. The trials must be independent, meaning that the\\noutcome of any individual trial doesn’t affect the\\nprobabilities in the other trials.\\n\\nCCopyiht © 2048, 2014, 2012 Pearson Education, Ine. Al Rights Reserved\\n\\n', 'Method 2: Using Technology\\n\\nTechnologies can be used to find binomial probabilities. The\\nscreen displays on the next slide list binomial probabilities for\\nn=5 and p = 0.85, as in the previous example. Notice that in\\neach display, the probability distribution is given as a table.\\n\\n‘Copy © 2088, 2014, 2012 Pearson Education,\\n\\n', 'Method 2: Using Technology Ye\\n\\n7189/84 Plus CE Excel\\nPte)\\n7386.05\\n\\nx Hi] =binom.dist(x, n, p, false)\\n\\nCCopyriht © 2038, 2014, 2012 Pearson Education, I\\n\\nOversee\\n', 'The Answers — how did you do?\\n\\n‘\\n8\\nD\\n8\\n\\n5.8\\n\\n6.0\\nD\\nc\\n\\n9.¢\\n\\n0.8\\n\\n', \"+ How many did you get right on the pop quiz? Find the\\nprobability of getting that many right by chance, using the\\nformula. If you got three right, we already did that\\nproblem, so find P(6) instead, the probability of getting 6\\nright. We'll compare these theoretical probabilities to the\\nresults we observed in our class.\\n\\ncopy © 2088, 2014, 2012 Pearson Education,\\n\\n\", 'Proba\\n\\n5-1 Probability Distributions\\n5-2 Binomial Probability Distributions\\n5-3 Poisson Probability Distributions\\n\\n2018, 2014, 2012 Pearzon Edveation, ne Al RightsReserved\\n\\ncopyriht\\n', nan, 'ONS (1 of 3\\n\\nSand F (success and failure) denote the two\\npossible categories of all outcomes.\\n\\nP(S)=p (p = probability of a success)\\nP(F)=1-p=q (q= probability of a failure)\\n\\nn the fixed number of trials\\n\\nCCopyrit © 2038, 2014, 2012 Pearson Edueation, In. Al Rights Reserved\\n\\nOrearson,\\n', '5% Guideline for Cumbersome Calculations\\n\\nWhen sampling without replacement and the sample\\nsize is no more than 5% of the size of the population,\\ntreat the selections as being independent (even though\\nthey are actually dependent).\\n\\n', 'The word success as used here is arbitrary and does\\nnot necessarily represent something good. Either of the\\ntwo possible categories may be called the success S as\\nlong as its probability is identified as p.\\n\\nCAUTION When using a binomial probability distribution,\\nalways be sure that x and p are consistent in the sense\\n\\nthat they both refer to the same category being called a\\nsuccess.\\n\\ncopyiht\\n\\n2018, 2014, 2012 Parzen Edveaton, Ine. Al RightsReserved Oranen\\n', 'Method 1: Binomial Probability Formula\\n\\nP(x) = C(m, x) p* qh ™\\nforx=0,1,2,...,n\\nwhere\\nn= number of trials\\nx = number of successes among n trials\\nPp = probability of success in any one trial\\nq = probability of failure in any one trial (q = 1 - p)\\n\\nCopyright © 2038, 2014, 2012 Pearson Education, Ine, Al Rights Reserved\\n', 'nomial Probab\\n\\non for B\\n\\nIDUTIONS (2 of 3)\\n\\nX - a specific number of successes in n trials, so x can\\nbe any whole number between 0 and n, inclusive\\n\\nPp - probability of success in one of the n trials\\n\\nq - probability of failure in one of the n trials\\n\\nP(x) - probability of getting exactly x successes among\\nthe n trials\\n\\n‘copyit © 2048, 2014, 2012 Pearson Education, Ine. Al Rights Reserved\\n', 'iple\\n\\nSolution\\n3. The probability of success (getting a person who knows\\nwhat Twitter is) for one selection is 0.85, so p = 0.85.\\n\\n4. The probability of failure (not getting someone who\\nknows what Twitter is) is 0.15, so q = 0.15.\\n\\nCopyright © 2038, 2014, 2012 Pearson Education, Inc, All Rights Reserved Oranwn\\n', 'Football «. z\\n\\nSolution\\n\\nThe Excel display on the next page shows that the probability\\nof 252 or more wins in 460 overtime games is 0.0224\\n(rounded), which is low (such as less than 0.05). This shows\\nthat it is unlikely that we would get 252 or more wins by\\nchance. If we effectively rule out chance, we are left with the\\nmore reasonable explanation that the team winning the\\novertime coin toss has a better chance of winning the game.\\n\\nCCopyiht © 2038, 2014, 2012 Pearson Education, Oran\\n\\n', '* Binomial Probability Distribution\\n—Abinomial probability distribution results from a\\nprocedure that meets these four requirements:\\n3. Each trial must have all outcomes classified into\\nexactly two categories, commonly referred to as\\nsuccess and failure.\\n\\n4. The probability of a success remains the same in\\nall trials.\\n\\nCopyright © 2038, 2014, 2012 Pearson Education, Ine. Al Rights Reserved\\n', 'ple:\\n\\nSolution\\n\\na. This procedure does satisfy the requirements for a\\nbinomial distribution, as shown below.\\n\\n1. The number of trials (5) is fixed\\n\\n2. The 5 trials are independent because the probability of\\nany adult knowing Twitter is not affected by results from\\nother selected adults.\\n\\n‘Copy © 2048, 2014, 2012 Pearson Education,\\n', \"+ Binomial Probability Distribution\\n—Abinomial probability distribution results from a\\nprocedure that meets these four requirements:\\n\\nThe procedure has a fixed number of trials. (A\\ntrial is a single observation.)\\n\\n2. The trials must be independent, meaning that the\\n‘outcome of any individual trial doesn't affect the\\nprobabilities in the other trials.\\n\\n‘Copyiht © 2038, 2014, 2012 Pearson Education, Inc. Al Rights Reserved Oranon\\n\", '5% Guideline for Cumbersome Calculations\\n\\nWhen sampling without replacement and the sample\\nsize is no more than 5% of the size of the population,\\ntreat the selections as being independent (even though\\nthey are actually dependent).\\n\\nCcopyit © 2048, 2014, 2012 Pearson Education, Ine. Al Rights Reserved\\n\\n', 'Pop quiz!\\n\\n', 'X=number Frequency Relative freq. Theoretical\\n\\nright prob.\\n0 3 wi 056\\n\\n1 4 148 188\\n\\n2 9 333 282\\n\\n3 5 185 250\\n\\n4 3 it 146\\n\\n5 3 a 088\\n\\n6 0 000 016,\\n\\n7 ° 000 003\\n\\n8 ° 000 (0004\\n8 ° 000 (00003\\n10 0 ‘000 (000001\\n\\nCCopyriht © 2038, 2014, 2012 Pearson Edveation, Inc.All Rights Reserved\\n\\n', 'Example: Twitter ors\\n\\nSolution\\nUsing the given values of n, x, p, and q in the binomial\\nprobability formula, we get\\n\\n!\\nP(3)=—> 85°.0.15°°\\n6-331\\n\\n= ©! .0.614128-0.0225\\n2131\\n\\n= (10)(0.614125)(0.0225)\\n= 0.138178\\n= 0.138 (round to three significant digits)\\n\\nThe probability of getting exactly three adults who know\\nTwitter among five randomly selected adults is 0.138.\\n\\n', 'Results for a re\\n\\n+ Here are the results for a recent class who did this experiment. The\\n\\nnumber of students with each score is given, along with the relative\\n\\nfrequen\\nrequency. “x= number right Frequency Relative freq.\\n\\n0 3 Tal\\n148\\n333\\n185\\n44\\n11\\n(000\\n.000\\n000\\n.000\\n(000\\n\\n4\\n8\\n5\\n3\\n3\\n0\\n0\\n0\\n0\\n0\\n\\n0\\n\\nCopyright © 2038, 2014, 2012 Pearson Education, Inc. Al Rights Reserved\\n', 'Pop quiz! —\\n\\n* Number your paper 1-10. There will be 10 vs\\nquestions, each with four choices (A, B, C, or D).\\n\\nCopyright © 2038, 2014, 2012 Pearson Edueation, Ine, Al Rights Reserved rear\\n', 'Relative freq. Theoretical\\nprob.\\n\\no 3 ii 056\\n\\n1 4 148 188\\n\\n2 9 333 282\\n\\n3 5 185 250\\n\\n4 3 11 146\\n\\n5 3 a1 088\\n\\n6 0 000 016\\n\\n7 ° 000 003\\n\\n8 ° ‘000 (0004\\n\\n9 ° 000 (00003\\n\\n10 0 000 (000001\\n\\nCopyright © 2038, 2014, 2012 Pearson Edueaion, In, Al Rights Reserved @rsrwn\\n', '5% Guideline for Cumbersome Calculations\\n\\nWhen sampling without replacement and the sample\\nsize is no more than 5% of the size of the population,\\ntreat the selections as being independent (even though\\nthey are actually dependent).\\n\\nCopyright © 2038, 2014, 2012 Pearson Edueation, Inc.All Rights Reserved Oran\\n', 'The word success as used here is arbitrary and does\\nnot necessarily represent something good. Either of the\\ntwo possible categories may be called the success S as\\nlong as its probability is identified as p.\\n\\nCAUTION When using a binomial probability distribution,\\nalways be sure that x and p are consistent in the sense\\n\\nthat they both refer to the same category being called a\\nsuccess.\\n\\nCopyright © 2038, 2014, 2012 Pearson Edueation, Ine,\\n\\nAl Rights Reserves Oranwn\\n', '®\\n\\nple:\\n\\nWhen an adult is randomly selected (with replacement),\\nthere is a 0.85 probability that this person knows what\\n‘Twitter is (based on results from a Pew Research\\nCenter survey). Suppose that we want to find the\\nprobability that exactly three of five randomly selected\\nadults know what Twitter is.\\n\\na. Does this procedure result in a binomial distribution?\\n\\nb. If this procedure does result in a binomial distribution,\\nidentify the values of n, x, p, and g.\\n\\nCopyright © 2038, 2014, 2012 Pearson Edueation, Ine.\\n\\nA Rights Reserved Oran\\n', 'Sand F (success and failure) denote the two\\npossible categories of all outcomes.\\n\\nP(S)=p (p = probability of a success)\\nP(F)=1-p=q (q= probability of a failure)\\nn the fixed number of trials\\n\\nCopyright © 2038, 2014, 2012 Pearson Edveation, Inc.All Rights Reserved\\n\\n', 'X=number Frequency Relative freq. Theoretical “\\nright prob.\\n0 3 ra 056\\n\\n1 4 148 188\\n\\n2 9 333 282\\n\\n3 5 485 250\\n\\n4 3 11 146\\n\\n5 3 a1 088\\n\\n6 ° ‘000 016\\n\\n7 0 000 003\\n\\n8 ° ‘000 (0004\\n9 ° 000 (00003\\n40 0 000 000001\\n\\n', 'The Answers — how did you do?\\n\\n', \"2\\n\\n+ How many did you get right on the pop quiz? Find the\\nprobability of getting that many right by chance, using the\\nformula. If you got three right, we already did that\\nproblem, so find P(6) instead, the probability of getting 6\\nright. We'll compare these theoretical probabilities to the\\nresults we observed in our class.\\n\\ncopyright © 2038, 2014, 2012 Pearson Education, In. Al Rights Reserved Oren\\n\", \"ab\\n\\n* Binomial Probability Distribution\\n—Abinomial probability distribution results from a\\nprocedure that meets these four requirements:\\nThe procedure has a fixed number of trials. (A\\ntrial is a single observation.)\\n2. The trials must be independent, meaning that the\\n\\n‘outcome of any individual trial doesn't affect the\\nprobabilities in the other trials.\\n\\nCopyright © 2038, 2014, 2012 Pearson Education,\\n\\n\", nan, 'Pop quiz! i\\n\\n* Number your paper 1-10. There will be 10\\nquestions, each with four choices (A, B, C, or D).\\n\\nCopyright © 2038, 2014, 2012 PeartanEdueation, In. Al Rights Reserved ran\\n', 'Solution\\n\\nThe Excel display on the next page shows that the probability\\nof 252 or more wins in 460 overtime games is 0.0224\\n(rounded), which is low (such as less than 0.05). This shows\\nthat it is unlikely that we would get 252 or more wins by\\nchance. If we effectively rule out chance, we are left with the\\nmore reasonable explanation that the team winning the\\novertime coin toss has a better chance of winning the game.\\n\\nCopyright © 2038, 2014, 2012 Pearson Education, Ine, Al Rights Reserved Orne\\n', 'We previously noted that between 1974 and 2011, there\\nwere 460 NFL football games decided in overtime, and\\n252 of them were won by the team that won the\\novertime coin toss. Is:the result of 252 wins in the 460\\ngames equivalent to random chance, or is 252 wins\\nsignificantly high? We can answer that question by\\nfinding the probability of 252 wins or more in 460\\ngames, assuming that wins and losses are equally\\n\\nlikely.\\n\\nCopyright © 2038, 2014, 2012 Pearson Edueation, Ine.\\n\\nAll Rights Reserved Orearso0,\\n']\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T13:14:22.633864Z",
     "start_time": "2024-07-11T13:14:22.414291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get ocr_lava \n",
    "lava_only = df_data_extensive.iloc[4].to_dict().values()\n",
    "\n",
    "lava_only = list(lava_only)\n",
    "\n",
    "lava_only = lava_only[1:]\n",
    "\n",
    "concat_result = []\n",
    "\n",
    "# list to a list of strings\n",
    "ocr_only = [str(i) for i in ocr_only]\n",
    "\n",
    "lava_only = [str(i) for i in lava_only]\n",
    "\n",
    "for i in range(len(ocr_only)):\n",
    "    concat_result.append(str(ocr_only[i]) + str(lava_only[i]))\n"
   ],
   "id": "370a8f17965b5465",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T13:14:24.251694Z",
     "start_time": "2024-07-11T13:14:24.035750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get ocr_transcriptions\n",
    "transcriptions_only = df_data_extensive.iloc[2].to_dict().values()\n",
    "ocr_only = df_data_extensive.iloc[3].to_dict().values()\n",
    "\n",
    "ocr_only = list(ocr_only)\n",
    "ocr_only = ocr_only[1:]\n",
    "\n",
    "transcriptions_only = list(transcriptions_only)\n",
    "transcriptions_only = transcriptions_only[1:]\n",
    "\n",
    "ocr_transcriptions = []\n",
    "# convert to list\n",
    "for i in range(len(ocr_only)):\n",
    "    ocr_transcriptions.append(str(ocr_only[i]) + str(transcriptions_only[i]))"
   ],
   "id": "1f0ebf7df19a8809",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "",
   "id": "4edda4110867169d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b247ca425b7be9e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Embedd with LLM long summary",
   "id": "12f6e476c9e49a24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T13:14:36.595072Z",
     "start_time": "2024-07-11T13:14:26.996445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Embedd with LLM long summary\n",
    "logger.info(f\"Embedd with LLM long summary\")\n",
    "\n",
    "result = []\n",
    "\n",
    "embedding_model = EmbeddingsModel()\n",
    "\n",
    "embedding_model.text_embeddings = None\n",
    "\n",
    "embedding_model.img_paths = None\n",
    "\n",
    "embedding_model.img_paths = img_path\n",
    "\n",
    "embeddings = embedding_model.generate_dataset_embeddings_standard_tokenizer(llm_long_summary)\n",
    "\n",
    "embedding_model.text_embeddings = embeddings\n",
    "\n",
    "logger.info(f\"Embedding Model.text_embeddings: {embedding_model.text_embeddings}\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "rows = get_results(df)\n",
    "\n",
    "df_extensive_summary = pd.DataFrame(rows, columns=['Prompt', 'GT_Keyframe', 'Top_1', 'Top_2', 'Top_3'])\n",
    "\n",
    "# Save dataframe to CSV\n",
    "df_extensive_summary.to_csv('df_standard_llm_long_summary_math.csv', index=False)\n"
   ],
   "id": "9c8f865ed02fb866",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-07-11 15:14:27.295\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m2\u001B[0m - \u001B[1mEmbedd with LLM long summary\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:35.933\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m18\u001B[0m - \u001B[1mEmbedding Model.text_embeddings: tensor([[-0.1807,  0.0187, -0.0795,  ..., -0.0288, -0.0470,  0.1070],\n",
      "        [-0.0751, -0.1122, -0.1110,  ...,  0.1050,  0.0080, -0.0782],\n",
      "        [ 0.1494, -0.0069, -0.1828,  ...,  0.1257, -0.1049,  0.2026],\n",
      "        ...,\n",
      "        [ 0.0975,  0.2250,  0.0211,  ...,  0.3876, -0.1169,  0.2771],\n",
      "        [ 0.1336, -0.2133, -0.2561,  ...,  0.2625, -0.0250, -0.1052],\n",
      "        [ 0.0451, -0.1206, -0.2157,  ...,  0.3979, -0.0515,  0.0212]])\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:35.933\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mwhat is a binomial probability distribution?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:35.980\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8725, 0.7878, 0.7841]),\n",
      "indices=tensor([ 7,  4, 69])) - GT is keyframe number 18\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:35.980\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:35.980\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:35.980\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 7 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-002-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:35.980\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:35.980\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 4 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-034-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:35.980\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:35.996\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 69 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-033-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:35.996\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mx is a specific number of successes in n trials\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.043\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.6408, 0.6305, 0.6106]),\n",
      "indices=tensor([15,  1, 44])) - GT is keyframe number 25\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.043\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.043\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.043\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 15 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-024-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.050\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.050\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 1 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-026-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.050\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.053\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 44 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-060-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.053\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mP(F) = 1 -p \u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.090\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.4671, 0.4343, 0.4326]),\n",
      "indices=tensor([50, 64,  1])) - GT is keyframe number 23\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.090\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.090\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.090\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 50 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-027-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.090\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.090\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 64 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-025-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.090\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.090\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 1 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-026-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.106\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mwhat procedures does the binomial probability distribution results from?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.137\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8385, 0.8266, 0.8251]),\n",
      "indices=tensor([84,  4, 69])) - GT is keyframe number 29\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.151\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.151\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.153\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 84 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-019-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.153\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.153\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 4 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-034-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.153\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.153\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 69 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-033-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.153\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the binomial probability formula?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.200\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7823, 0.7717, 0.7590]),\n",
      "indices=tensor([31, 44, 16])) - GT is keyframe number 58\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.200\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.200\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.200\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 31 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-086-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.200\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.200\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 44 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-060-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.200\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.200\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 16 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-059-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.200\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the method 2 for finding the binomial probabilities?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.251\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7988, 0.7964, 0.7839]),\n",
      "indices=tensor([16, 54, 63])) - GT is keyframe number 80\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.251\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.251\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.258\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 16 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-059-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.258\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.258\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.258\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.258\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 63 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-058-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.263\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mHow many NFL Football games betweem 1974 and 2011 there is?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.295\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7546, 0.7020, 0.4718]),\n",
      "indices=tensor([33, 88, 66])) - GT is keyframe number 85\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.295\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.295\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.295\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 33 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-084-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.295\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.295\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 88 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-085-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.295\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.311\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 66 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-087-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.311\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat are the key concepts of the lecture\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.342\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7331, 0.7164, 0.6883]),\n",
      "indices=tensor([82, 18, 25])) - GT is keyframe number 3\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.342\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.351\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.351\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 82 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-015-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.351\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.351\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 18 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-012-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.351\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.358\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 25 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-008-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.358\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the probability of failure in the twitter example?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.389\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8605, 0.7708, 0.7092]),\n",
      "indices=tensor([65, 30,  8])) - GT is keyframe number 46\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.389\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.389\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.405\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 65 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-046-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.405\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.405\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 30 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-032-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.405\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.405\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 8 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-061-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.405\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mUsing the given values of n x and q\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.452\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.4622, 0.4537, 0.4492]),\n",
      "indices=tensor([44, 63, 48])) - GT is keyframe number 65\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.452\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.452\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.452\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 44 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-060-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.452\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.452\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 63 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-058-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.452\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.452\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 48 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-044-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.462\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mprobability of success remains the same in all trials\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.500\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.6307, 0.6236, 0.6207]),\n",
      "indices=tensor([42, 67, 13])) - GT is keyframe number 22\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.500\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.500\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.500\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 42 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-022-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.500\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.500\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 67 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-021-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.510\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:36.510\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 13 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-036-01.jpg\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Embedd with OCR Only ",
   "id": "a60d4be1d51b4611"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T13:14:44.620166Z",
     "start_time": "2024-07-11T13:14:36.595072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Embedd with OCR ONLY \n",
    "logger.info(f\"Embedd with OCR ONLY \")\n",
    "\n",
    "result = []\n",
    "\n",
    "embedding_model = EmbeddingsModel()\n",
    "\n",
    "embedding_model.text_embeddings = None\n",
    "\n",
    "embedding_model.img_paths = None\n",
    "\n",
    "embedding_model.img_paths = img_path\n",
    "\n",
    "\n",
    "# need to be embedded\n",
    "\n",
    "embeddings = embedding_model.generate_dataset_embeddings_standard_tokenizer(ocr_only)\n",
    "\n",
    "embedding_model.text_embeddings = embeddings\n",
    "\n",
    "rows = []\n",
    "\n",
    "rows = get_results(df)\n",
    "\n",
    "df_ocr_only = pd.DataFrame(rows, columns=['Prompt', 'GT_Keyframe', 'Top_1', 'Top_2', 'Top_3'])\n",
    "\n",
    "# Save dataframe to CSV\n",
    "df_ocr_only.to_csv('df_standard_ocr_only_math.csv', index=False)\n",
    "logger.info('Saved df_standard_ocr_only_math.csv')"
   ],
   "id": "fe5c14edaf32d616",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-07-11 15:14:36.906\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m2\u001B[0m - \u001B[1mEmbedd with OCR ONLY \u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:43.936\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mwhat is a binomial probability distribution?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:43.983\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7391, 0.7355, 0.7067]),\n",
      "indices=tensor([54,  0, 31])) - GT is keyframe number 18\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:43.983\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:43.983\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:43.983\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:43.983\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:43.999\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 0 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-080-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:43.999\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:43.999\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 31 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-086-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:43.999\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mx is a specific number of successes in n trials\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.046\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8626, 0.8490, 0.7650]),\n",
      "indices=tensor([50, 15, 64])) - GT is keyframe number 25\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.046\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.046\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.046\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 50 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-027-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.046\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.061\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 15 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-024-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.063\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.063\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 64 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-025-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.063\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mP(F) = 1 -p \u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.109\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.4772, 0.4752, 0.4730]),\n",
      "indices=tensor([44, 16, 63])) - GT is keyframe number 23\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.109\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.109\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.109\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 44 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-060-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.109\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.109\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 16 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-059-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.109\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.109\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 63 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-058-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.125\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mwhat procedures does the binomial probability distribution results from?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.172\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7642, 0.7612, 0.7514]),\n",
      "indices=tensor([54,  0,  4])) - GT is keyframe number 29\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.172\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.172\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.172\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.172\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.172\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 0 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-080-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.172\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.172\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 4 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-034-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.172\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the binomial probability formula?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.225\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7726, 0.7385, 0.7307]),\n",
      "indices=tensor([31, 54,  0])) - GT is keyframe number 58\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.225\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.225\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.225\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 31 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-086-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.225\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.240\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.240\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.240\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 0 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-080-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.240\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the method 2 for finding the binomial probabilities?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.292\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8205, 0.8190, 0.7780]),\n",
      "indices=tensor([54,  0, 20])) - GT is keyframe number 80\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.292\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.292\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.304\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.304\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.304\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 0 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-080-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.304\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.304\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 20 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-082-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.304\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mHow many NFL Football games betweem 1974 and 2011 there is?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.363\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7581, 0.7421, 0.4597]),\n",
      "indices=tensor([88, 33, 66])) - GT is keyframe number 85\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.367\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.367\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.367\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 88 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-085-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.367\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.367\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 33 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-084-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.367\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.367\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 66 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-087-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.367\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat are the key concepts of the lecture\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.414\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.3661, 0.3357, 0.3162]),\n",
      "indices=tensor([ 7, 45, 23])) - GT is keyframe number 3\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.414\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.414\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.414\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 7 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-002-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.429\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.429\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 45 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-003-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.429\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.429\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 23 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-004-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.429\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the probability of failure in the twitter example?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.480\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8505, 0.7551, 0.7091]),\n",
      "indices=tensor([65, 27, 38])) - GT is keyframe number 46\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.480\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.480\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.480\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 65 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-046-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.480\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.480\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 27 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-043-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.480\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.491\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 38 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-065-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.491\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mUsing the given values of n x and q\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.528\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.5318, 0.5165, 0.5152]),\n",
      "indices=tensor([50, 15, 31])) - GT is keyframe number 65\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.528\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.528\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.528\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 50 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-027-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.528\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.543\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 15 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-024-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.543\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.543\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 31 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-086-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.543\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mprobability of success remains the same in all trials\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.592\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.6824, 0.6684, 0.6588]),\n",
      "indices=tensor([ 1, 15, 50])) - GT is keyframe number 22\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.592\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.593\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.594\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 1 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-026-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.596\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.596\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 15 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-024-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.596\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.596\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 50 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-027-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:44.596\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m29\u001B[0m - \u001B[1mSaved df_standard_ocr_only_math.csv\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Embedd with OCR TRANSCRIPTIONS",
   "id": "b6ba852b70d9c007"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T13:14:53.592748Z",
     "start_time": "2024-07-11T13:14:44.620166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Embedd with OCR TRANSCRIPTIONS\n",
    "# TODO: Doesn't work since transcriptions are nans\n",
    "logger.info(f\"Embedd with TRANSCRIPTIONS\")\n",
    "\n",
    "result = []\n",
    "\n",
    "embedding_model = EmbeddingsModel()\n",
    "\n",
    "embedding_model.text_embeddings = None\n",
    "\n",
    "embedding_model.img_paths = None\n",
    "\n",
    "embedding_model.img_paths = img_path\n",
    "\n",
    "embeddings = embedding_model.generate_dataset_embeddings_standard_tokenizer(ocr_transcriptions)\n",
    "\n",
    "embedding_model.text_embeddings = embeddings\n",
    "\n",
    "logger.info(f\"Embedding Model.text_embeddings: {embedding_model.text_embeddings}\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "rows = get_results(df)\n",
    "\n",
    "df_ocr_transcriptions = pd.DataFrame(rows, columns=['Prompt', 'GT_Keyframe', 'Top_1', 'Top_2', 'Top_3'])\n",
    "\n",
    "# Save dataframe to CSV\n",
    "df_ocr_transcriptions.to_csv('df_standard_df_ocr_transcriptions_math.csv', index=False)"
   ],
   "id": "547f01970c56eff2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-07-11 15:14:44.978\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m3\u001B[0m - \u001B[1mEmbedd with TRANSCRIPTIONS\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.006\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m19\u001B[0m - \u001B[1mEmbedding Model.text_embeddings: tensor([[-0.1558, -0.0281, -0.0629,  ..., -0.0501, -0.1999,  0.0217],\n",
      "        [-0.0288, -0.0639, -0.1174,  ...,  0.2123,  0.0999, -0.0971],\n",
      "        [ 0.0047, -0.1774, -0.1902,  ...,  0.1141,  0.0542,  0.1336],\n",
      "        ...,\n",
      "        [-0.1746,  0.2062,  0.1619,  ...,  0.2807, -0.0483,  0.2825],\n",
      "        [ 0.1472, -0.0332, -0.2890,  ...,  0.1943,  0.0194, -0.0999],\n",
      "        [ 0.0034, -0.1747, -0.1204,  ...,  0.2931,  0.0011, -0.0896]])\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.006\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mwhat is a binomial probability distribution?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.054\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7256, 0.7189, 0.7067]),\n",
      "indices=tensor([ 0, 54, 31])) - GT is keyframe number 18\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.054\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.054\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.054\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 0 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-080-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.054\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.054\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.054\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.054\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 31 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-086-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.054\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mx is a specific number of successes in n trials\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.103\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8476, 0.8266, 0.7559]),\n",
      "indices=tensor([15, 50, 64])) - GT is keyframe number 25\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.103\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.103\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.103\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 15 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-024-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.103\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.103\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 50 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-027-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.103\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.103\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 64 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-025-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.119\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mP(F) = 1 -p \u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.159\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.4860, 0.4736, 0.4711]),\n",
      "indices=tensor([ 1, 64, 24])) - GT is keyframe number 23\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.159\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.159\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.159\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 1 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-026-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.159\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.159\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 64 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-025-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.159\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.159\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 24 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-075-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.159\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mwhat procedures does the binomial probability distribution results from?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.207\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7491, 0.7481, 0.7468]),\n",
      "indices=tensor([ 0, 28, 39])) - GT is keyframe number 29\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.207\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.207\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.207\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 0 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-080-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.207\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.207\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 28 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-020-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.207\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.207\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 39 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-018-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.222\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the binomial probability formula?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.254\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7726, 0.7272, 0.7214]),\n",
      "indices=tensor([31,  0, 54])) - GT is keyframe number 58\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.254\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.254\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.254\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 31 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-086-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.254\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.270\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 0 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-080-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.270\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.270\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.270\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the method 2 for finding the binomial probabilities?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.316\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8306, 0.7804, 0.7728]),\n",
      "indices=tensor([ 0, 54, 22])) - GT is keyframe number 80\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.316\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.316\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.316\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 0 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-080-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.316\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.316\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.316\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.316\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 22 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-079-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.316\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mHow many NFL Football games betweem 1974 and 2011 there is?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.363\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7581, 0.7421, 0.4554]),\n",
      "indices=tensor([88, 33, 66])) - GT is keyframe number 85\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.363\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.363\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.363\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 88 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-085-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.363\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.363\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 33 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-084-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.363\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.363\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 66 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-087-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.363\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat are the key concepts of the lecture\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.410\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.3465, 0.3417, 0.3376]),\n",
      "indices=tensor([82, 45,  7])) - GT is keyframe number 3\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.410\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.410\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.410\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 82 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-015-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.410\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.426\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 45 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-003-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.426\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.426\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 7 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-002-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.426\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the probability of failure in the twitter example?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.457\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8425, 0.7883, 0.7065]),\n",
      "indices=tensor([65, 27,  8])) - GT is keyframe number 46\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.457\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.473\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.473\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 65 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-046-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.473\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.473\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 27 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-043-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.478\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.478\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 8 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-061-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.478\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mUsing the given values of n x and q\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.505\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.5152, 0.5062, 0.4966]),\n",
      "indices=tensor([31, 64, 15])) - GT is keyframe number 65\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.505\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.520\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.520\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 31 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-086-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.520\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.520\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 64 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-025-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.520\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.520\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 15 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-024-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.520\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mprobability of success remains the same in all trials\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.568\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.6748, 0.6686, 0.6488]),\n",
      "indices=tensor([15, 50,  1])) - GT is keyframe number 22\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.568\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.568\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.568\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 15 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-024-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.568\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.568\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 50 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-027-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.568\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:14:53.568\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 1 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-026-01.jpg\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Embedd with OCR Lava",
   "id": "7b01e7b31bf89702"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T13:15:06.785882Z",
     "start_time": "2024-07-11T13:14:53.592748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Embedd with OCR LAVA\n",
    "logger.info(f\"Embedd with OCR LAVA\")\n",
    "\n",
    "result = []\n",
    "\n",
    "embedding_model = EmbeddingsModel()\n",
    "\n",
    "embedding_model.text_embeddings = None\n",
    "\n",
    "embedding_model.img_paths = None\n",
    "\n",
    "embedding_model.img_paths = img_path\n",
    "\n",
    "# get the embedder model\n",
    "embedder_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "concat_result_embeddings = text_to_embedding_transformer(concat_result, embedder_model)\n",
    "\n",
    "embedding_model.text_embeddings = concat_result_embeddings\n",
    "\n",
    "logger.info(embedding_model.text_embeddings)\n",
    "\n",
    "rows = []\n",
    "\n",
    "rows = get_results(df)\n",
    "\n",
    "df_ocr_lava = pd.DataFrame(rows, columns=['Prompt', 'GT_Keyframe', 'Top_1', 'Top_2', 'Top_3'])\n",
    "\n",
    "# Save dataframe to CSV\n",
    "df_ocr_lava.to_csv('df_standard_ocr_lava_math.csv', index=False)"
   ],
   "id": "1ffe907012ae084f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-07-11 15:14:53.959\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m2\u001B[0m - \u001B[1mEmbedd with OCR LAVA\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.195\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m21\u001B[0m - \u001B[1mtensor([[-0.1732, -0.0575, -0.0450,  ...,  0.0386, -0.1806,  0.0313],\n",
      "        [-0.0026, -0.0693, -0.0752,  ...,  0.2555,  0.0476, -0.0912],\n",
      "        [ 0.0449, -0.1822, -0.2032,  ...,  0.1478,  0.0116,  0.1369],\n",
      "        ...,\n",
      "        [-0.1330,  0.0448,  0.2359,  ...,  0.3798, -0.0514,  0.2481],\n",
      "        [ 0.1561, -0.0200, -0.2794,  ...,  0.1811,  0.0110, -0.0934],\n",
      "        [ 0.0034, -0.1747, -0.1204,  ...,  0.2931,  0.0011, -0.0896]])\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.195\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mwhat is a binomial probability distribution?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.234\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7246, 0.7208, 0.7160]),\n",
      "indices=tensor([28, 42, 54])) - GT is keyframe number 18\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.234\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.234\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.234\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 28 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-020-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.234\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.250\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 42 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-022-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.250\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 18#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.250\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.250\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mx is a specific number of successes in n trials\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.281\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8463, 0.8440, 0.7461]),\n",
      "indices=tensor([50, 15, 64])) - GT is keyframe number 25\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.281\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.296\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.297\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 50 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-027-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.297\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.297\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 15 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-024-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.297\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 25#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.297\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 64 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-025-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.297\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mP(F) = 1 -p \u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.325\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.4704, 0.4644, 0.4641]),\n",
      "indices=tensor([16,  1, 63])) - GT is keyframe number 23\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.325\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.341\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.341\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 16 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-059-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.341\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.341\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 1 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-026-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.341\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 23#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.341\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 63 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-058-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.341\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mwhat procedures does the binomial probability distribution results from?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.388\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7686, 0.7662, 0.7572]),\n",
      "indices=tensor([28, 67, 42])) - GT is keyframe number 29\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.388\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.388\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.388\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 28 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-020-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.396\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.396\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 67 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-021-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.396\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 29#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.396\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 42 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-022-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.396\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the binomial probability formula?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.436\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7726, 0.7284, 0.7167]),\n",
      "indices=tensor([31, 44, 54])) - GT is keyframe number 58\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.436\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.436\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.436\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 31 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-086-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.436\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.436\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 44 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-060-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.436\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 58#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.436\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.451\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the method 2 for finding the binomial probabilities?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.482\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8077, 0.7951, 0.7772]),\n",
      "indices=tensor([54,  0, 22])) - GT is keyframe number 80\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.482\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.482\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.496\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 54 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-081-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.496\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.499\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 0 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-080-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.499\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 80#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.499\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 22 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-079-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.499\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mHow many NFL Football games betweem 1974 and 2011 there is?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.546\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.7581, 0.7421, 0.4534]),\n",
      "indices=tensor([88, 33, 66])) - GT is keyframe number 85\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.546\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.546\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.546\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 88 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-085-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.546\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.546\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 33 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-084-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.546\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 85#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.546\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 66 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-087-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.546\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat are the key concepts of the lecture\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.596\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.4638, 0.4502, 0.4436]),\n",
      "indices=tensor([19, 59, 85])) - GT is keyframe number 3\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.596\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.596\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.596\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 19 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-063-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.596\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.596\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 59 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-062-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.596\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 3#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.596\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 85 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-064-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.596\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mWhat is the probability of failure in the twitter example?\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.640\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.8801, 0.7663, 0.7081]),\n",
      "indices=tensor([65, 27,  8])) - GT is keyframe number 46\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.640\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.640\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.640\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 65 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-046-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 27 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-043-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 46#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 8 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-061-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mUsing the given values of n x and q\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.703\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.5152, 0.5104, 0.4797]),\n",
      "indices=tensor([31, 50, 16])) - GT is keyframe number 65\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.704\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.706\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.707\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 31 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-086-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.708\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.710\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 50 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-027-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.710\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 65#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.710\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 16 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-059-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.710\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mget_results\u001B[0m:\u001B[36m15\u001B[0m - \u001B[1mprobability of success remains the same in all trials\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.752\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m175\u001B[0m - \u001B[1mTop 3 Similarity scores: torch.return_types.topk(\n",
      "values=tensor([0.6666, 0.6628, 0.6527]),\n",
      "indices=tensor([15, 50,  1])) - GT is keyframe number 22\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.752\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m177\u001B[0m - \u001B[1mLength of img paths: 89\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.752\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.752\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 15 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-024-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.752\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.752\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 50 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-027-01.jpg\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.752\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m185\u001B[0m - \u001B[1m#####GT is keyframe number 22#####\u001B[0m\n",
      "\u001B[32m2024-07-11 15:15:06.752\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.text_embedder.embedder\u001B[0m:\u001B[36msearch_similar_images_top_k\u001B[0m:\u001B[36m186\u001B[0m - \u001B[1mMax similarity for index 1 is the keyframe /Users/magic-rabbit/Documents/AFM/afm-vlm/data/raw/math_1/extracted_keyframes/math_1-Scene-026-01.jpg\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4ae21bed69a3c404"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
